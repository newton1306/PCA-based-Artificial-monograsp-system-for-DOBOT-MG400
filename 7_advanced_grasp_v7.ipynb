{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ Advanced Grasp Detection v7\n",
                "\n",
                "## New in v7\n",
                "| Feature | Description |\n",
                "|---------|-------------|\n",
                "| **üìè Camera Height Calibration** | ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠ depth ‡πÅ‡∏°‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô |\n",
                "| **üî¨ Multi-Object Depth Calibration** | Calibrate ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏¥‡πâ‡∏ô |\n",
                "| **üìê Frame Grid + Object Grid** | Grid ‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏ü‡∏£‡∏° + Grid ‡∏ö‡∏ô‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏¥‡πâ‡∏ô |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch: 2.9.1+cpu\n",
                        "CUDA: False\n",
                        "‚úì Imports loaded\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import cv2\n",
                "import numpy as np\n",
                "import time\n",
                "import socket\n",
                "import serial\n",
                "import torch\n",
                "from collections import deque\n",
                "from ultralytics import YOLO\n",
                "\n",
                "sys.path.append('Depth-Anything-V2')\n",
                "\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "print(\"‚úì Imports loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Hardware Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Hardware config\n"
                    ]
                }
            ],
            "source": [
                "ROBOT_IP = '192.168.1.6'\n",
                "ESP32_PORT = 'COM9'\n",
                "ESP32_BAUDRATE = 115200\n",
                "CAMERA_ID = 2\n",
                "\n",
                "HOMOGRAPHY_MATRIX = np.array([\n",
                "    [0.005703976266962427, -0.3265299161278153, 88.58634169557483],\n",
                "    [-0.47704058225560797, 0.015355046930804153, 172.0941543570439],\n",
                "    [-0.00029949919510557677, 0.00018728182448344945, 1.0],\n",
                "], dtype=np.float32)\n",
                "\n",
                "print(\"‚úì Hardware config\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üîß CALIBRATION SECTION\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìê Calibration 1: PIXELS_PER_MM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Distance: 201.0 px\n",
                        "Distance: 200.0 px\n",
                        "PIXELS_PER_MM = 2.2222\n"
                    ]
                }
            ],
            "source": [
                "# Uncomment ‡πÄ‡∏û‡∏∑‡πà‡∏≠ calibrate\n",
                "# ‡∏•‡∏≤‡∏Å‡πÄ‡∏™‡πâ‡∏ô‡∏ö‡∏ô‡πÑ‡∏°‡πâ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î ‚Üí ENTER ‚Üí ‡πÉ‡∏™‡πà‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏£‡∏¥‡∏á (mm)\n",
                "\n",
                "drawing = False\n",
                "start_pt, end_pt = None, None\n",
                "px_dist = 0\n",
                "\n",
                "def cb(event, x, y, flags, param):\n",
                "    global drawing, start_pt, end_pt, px_dist\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        drawing, start_pt = True, (x, y)\n",
                "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
                "        end_pt = (x, y)\n",
                "    elif event == cv2.EVENT_LBUTTONUP:\n",
                "        drawing, end_pt = False, (x, y)\n",
                "        px_dist = np.sqrt((end_pt[0]-start_pt[0])**2 + (end_pt[1]-start_pt[1])**2)\n",
                "        print(f\"Distance: {px_dist:.1f} px\")\n",
                "\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Pixel Cal')\n",
                "cv2.setMouseCallback('Pixel Cal', cb)\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    if start_pt and end_pt: cv2.line(frame, start_pt, end_pt, (0,255,0), 2)\n",
                "    cv2.imshow('Pixel Cal', frame)\n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == 13 and px_dist > 0:\n",
                "        mm = float(input(\"Real size (mm): \"))\n",
                "        print(f\"PIXELS_PER_MM = {px_dist/mm:.4f}\")\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìè Calibration 2: Camera Height & Depth Scale\n",
                "\n",
                "**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:**\n",
                "1. ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô (mm) ‚Üí ‡πÉ‡∏™‡πà `CAMERA_HEIGHT_MM`\n",
                "2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ 2-3 ‡∏ä‡∏¥‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á\n",
                "3. Run cell ‚Üí ‡∏Å‡∏î C calibrate ‡∏û‡∏∑‡πâ‡∏ô\n",
                "4. ‡∏ß‡∏≤‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ ‚Üí ‡∏Ñ‡∏•‡∏¥‡∏Å ‚Üí ‡πÉ‡∏™‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏à‡∏£‡∏¥‡∏á\n",
                "5. ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏≠‡∏∑‡πà‡∏ô ‚Üí ‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏≤ DEPTH_Z_SCALE ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Camera height: 630mm\n",
                        "Run depth calibration after loading models...\n"
                    ]
                }
            ],
            "source": [
                "# === ADVANCED DEPTH CALIBRATION ===\n",
                "# Run ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Load Depth Model (Section 4)\n",
                "\n",
                "# ‚ö†Ô∏è ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô (mm)\n",
                "CAMERA_HEIGHT_MM = 630  # üî¥ ‡πÅ‡∏Å‡πâ‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ!\n",
                "\n",
                "print(f\"Camera height: {CAMERA_HEIGHT_MM}mm\")\n",
                "print(\"Run depth calibration after loading models...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ü¶æ Calibration 3: Gripper Test"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3Ô∏è‚É£ Configuration\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Configuration loaded\n",
                        "  Camera height: 630mm\n",
                        "  Frame grid: 20mm, Object grid: 5mm\n"
                    ]
                }
            ],
            "source": [
                "# === CALIBRATED VALUES ===\n",
                "PIXELS_PER_MM = 2.222\n",
                "DEPTH_Z_SCALE = 26.1660\n",
                "CAMERA_HEIGHT_MM = 630  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô\n",
                "\n",
                "# === Z Heights ===\n",
                "Z_FLOOR = -64\n",
                "Z_SAFE = -40\n",
                "Z_APPROACH = -55\n",
                "\n",
                "# === Drop Position ===\n",
                "DROP_POS = (-253.07, 115.17, -17.07, -62.78)\n",
                "\n",
                "# === Gripper (NO MARGIN) ===\n",
                "GRIPPER_SERVO_OPEN_ANGLE = 22\n",
                "GRIPPER_SERVO_CLOSE_ANGLE = 96\n",
                "GRIPPER_MAX_WIDTH_MM = 54\n",
                "GRIPPER_MIN_WIDTH_MM = 0\n",
                "GRIPPER_OPEN_MARGIN_MM = 5\n",
                "GRIPPER_GRIP_MARGIN_MM = 0\n",
                "\n",
                "# === Detection ===\n",
                "MIN_OBJECT_AREA = 1000\n",
                "YOLO_CONFIDENCE = 0.25\n",
                "\n",
                "# === Depth Model ===\n",
                "DEPTH_MODEL_PATH = 'Depth-Anything-V2/checkpoints/depth_anything_v2_vits.pth'\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "# === Grid Display ===\n",
                "SHOW_FRAME_GRID = True\n",
                "SHOW_OBJECT_GRID = True\n",
                "FRAME_GRID_SIZE_MM = 20\n",
                "OBJECT_GRID_SIZE_MM = 5\n",
                "\n",
                "print(\"‚úì Configuration loaded\")\n",
                "print(f\"  Camera height: {CAMERA_HEIGHT_MM}mm\")\n",
                "print(f\"  Frame grid: {FRAME_GRID_SIZE_MM}mm, Object grid: {OBJECT_GRID_SIZE_MM}mm\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Load Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading DepthAnything V2...\n",
                        "‚úÖ Depth model on cpu\n",
                        "Loading YOLOv8...\n",
                        "‚úÖ YOLO loaded\n"
                    ]
                }
            ],
            "source": [
                "from depth_anything_v2.dpt import DepthAnythingV2\n",
                "\n",
                "model_configs = {\n",
                "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
                "}\n",
                "\n",
                "print(\"Loading DepthAnything V2...\")\n",
                "depth_model = DepthAnythingV2(**model_configs['vits'])\n",
                "depth_model.load_state_dict(torch.load(DEPTH_MODEL_PATH, map_location='cpu'))\n",
                "depth_model = depth_model.to(DEVICE).eval()\n",
                "print(f\"‚úÖ Depth model on {DEVICE}\")\n",
                "\n",
                "print(\"Loading YOLOv8...\")\n",
                "yolo_model = YOLO('yolov8n.pt')\n",
                "print(\"‚úÖ YOLO loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìè Run Depth Calibration (Multi-Object)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ü§ñ HOME...\n"
                    ]
                }
            ],
            "source": [
                "robot.home()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "üìè DEPTH CALIBRATION (Multi-Object)\n",
                        "============================================================\n",
                        "1. ‡∏Å‡∏î C = Calibrate ‡∏û‡∏∑‡πâ‡∏ô (‡πÄ‡∏≠‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏≠‡∏≠‡∏Å)\n",
                        "2. ‡∏ß‡∏≤‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á ‚Üí ‡∏Ñ‡∏•‡∏¥‡∏Å ‚Üí ‡πÉ‡∏™‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á (mm)\n",
                        "3. ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏≠‡∏∑‡πà‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
                        "4. ‡∏Å‡∏î S = Show average scale\n",
                        "5. ‡∏Å‡∏î Q = Quit\n",
                        "============================================================\n",
                        "‚úÖ Floor depth: 3.1107\n",
                        "   ‚úÖ Sample 1: Scale=45.27\n",
                        "   ‚úÖ Sample 2: Scale=45.05\n",
                        "   ‚úÖ Sample 3: Scale=8.71\n",
                        "   ‚úÖ Sample 4: Scale=19.05\n",
                        "\n",
                        "============================================================\n",
                        "üìä Calibration Results:\n",
                        "   1. Height=107.0mm ‚Üí Scale=45.27\n",
                        "   2. Height=107.0mm ‚Üí Scale=45.05\n",
                        "   3. Height=11.0mm ‚Üí Scale=8.71\n",
                        "   4. Height=27.0mm ‚Üí Scale=19.05\n",
                        "============================================================\n",
                        "‚úÖ DEPTH_Z_SCALE = 29.5190 (¬±16.06)\n",
                        "============================================================\n",
                        "   ‚úÖ Sample 5: Scale=12.75\n",
                        "\n",
                        "============================================================\n",
                        "üìä Calibration Results:\n",
                        "   1. Height=107.0mm ‚Üí Scale=45.27\n",
                        "   2. Height=107.0mm ‚Üí Scale=45.05\n",
                        "   3. Height=11.0mm ‚Üí Scale=8.71\n",
                        "   4. Height=27.0mm ‚Üí Scale=19.05\n",
                        "   5. Height=27.0mm ‚Üí Scale=12.75\n",
                        "============================================================\n",
                        "‚úÖ DEPTH_Z_SCALE = 26.1660 (¬±15.86)\n",
                        "============================================================\n",
                        "   ‚ùå Invalid input\n",
                        "\n",
                        "üìã Copy this: DEPTH_Z_SCALE = 26.1660\n"
                    ]
                }
            ],
            "source": [
                "# === MULTI-OBJECT DEPTH CALIBRATION ===\n",
                "print(\"=\"*60)\n",
                "print(\"üìè DEPTH CALIBRATION (Multi-Object)\")\n",
                "print(\"=\"*60)\n",
                "print(\"1. ‡∏Å‡∏î C = Calibrate ‡∏û‡∏∑‡πâ‡∏ô (‡πÄ‡∏≠‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏≠‡∏≠‡∏Å)\")\n",
                "print(\"2. ‡∏ß‡∏≤‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á ‚Üí ‡∏Ñ‡∏•‡∏¥‡∏Å ‚Üí ‡πÉ‡∏™‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á (mm)\")\n",
                "print(\"3. ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏≠‡∏∑‡πà‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\")\n",
                "print(\"4. ‡∏Å‡∏î S = Show average scale\")\n",
                "print(\"5. ‡∏Å‡∏î Q = Quit\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "calibration_samples = []\n",
                "floor_depth = None\n",
                "click_x, click_y = None, None\n",
                "\n",
                "def depth_cal_callback(event, x, y, flags, param):\n",
                "    global click_x, click_y\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        click_x, click_y = x, y\n",
                "\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Depth Calibration')\n",
                "cv2.setMouseCallback('Depth Calibration', depth_cal_callback)\n",
                "\n",
                "current_depth_map = None\n",
                "frame_count = 0\n",
                "\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    \n",
                "    frame_count += 1\n",
                "    if frame_count % 5 == 0:\n",
                "        current_depth_map = depth_model.infer_image(frame)\n",
                "    \n",
                "    # Display\n",
                "    floor_str = f\"Floor: {floor_depth:.4f}\" if floor_depth else \"Floor: NOT SET\"\n",
                "    samples_str = f\"Samples: {len(calibration_samples)}\"\n",
                "    cv2.putText(frame, f\"{floor_str} | {samples_str} | C=Floor S=Show Q=Quit\",\n",
                "               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
                "    \n",
                "    if calibration_samples:\n",
                "        avg_scale = np.mean([s['scale'] for s in calibration_samples])\n",
                "        cv2.putText(frame, f\"Avg DEPTH_Z_SCALE = {avg_scale:.2f}\",\n",
                "                   (10, 460), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
                "    \n",
                "    cv2.imshow('Depth Calibration', frame)\n",
                "    \n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    \n",
                "    if key == ord('q'):\n",
                "        break\n",
                "    \n",
                "    elif key == ord('c'):\n",
                "        if current_depth_map is not None:\n",
                "            h, w = current_depth_map.shape\n",
                "            center = current_depth_map[h//3:2*h//3, w//3:2*w//3]\n",
                "            floor_depth = np.median(center)\n",
                "            print(f\"‚úÖ Floor depth: {floor_depth:.4f}\")\n",
                "    \n",
                "    elif key == ord('s'):\n",
                "        if calibration_samples:\n",
                "            print(\"\\n\" + \"=\"*60)\n",
                "            print(\"üìä Calibration Results:\")\n",
                "            for i, s in enumerate(calibration_samples):\n",
                "                print(f\"   {i+1}. Height={s['height_mm']}mm ‚Üí Scale={s['scale']:.2f}\")\n",
                "            avg = np.mean([s['scale'] for s in calibration_samples])\n",
                "            std = np.std([s['scale'] for s in calibration_samples])\n",
                "            print(\"=\"*60)\n",
                "            print(f\"‚úÖ DEPTH_Z_SCALE = {avg:.4f} (¬±{std:.2f})\")\n",
                "            print(\"=\"*60)\n",
                "    \n",
                "    # Handle click\n",
                "    if click_x is not None and current_depth_map is not None and floor_depth is not None:\n",
                "        # Get depth at click point (small region)\n",
                "        x, y = click_x, click_y\n",
                "        h, w = current_depth_map.shape\n",
                "        x = max(10, min(w-10, x))\n",
                "        y = max(10, min(h-10, y))\n",
                "        \n",
                "        region = current_depth_map[y-10:y+10, x-10:x+10]\n",
                "        obj_depth = np.median(region)\n",
                "        raw_diff = obj_depth - floor_depth\n",
                "        \n",
                "        if raw_diff > 0:\n",
                "            try:\n",
                "                height_mm = float(input(f\"\\nüìè Object at ({x},{y}) - Enter height (mm): \"))\n",
                "                scale = height_mm / raw_diff\n",
                "                calibration_samples.append({\n",
                "                    'height_mm': height_mm,\n",
                "                    'raw_diff': raw_diff,\n",
                "                    'scale': scale\n",
                "                })\n",
                "                print(f\"   ‚úÖ Sample {len(calibration_samples)}: Scale={scale:.2f}\")\n",
                "            except:\n",
                "                print(\"   ‚ùå Invalid input\")\n",
                "        else:\n",
                "            print(f\"   ‚ùå Depth diff={raw_diff:.4f} (should be > 0)\")\n",
                "        \n",
                "        click_x, click_y = None, None\n",
                "\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()\n",
                "\n",
                "if calibration_samples:\n",
                "    final_scale = np.mean([s['scale'] for s in calibration_samples])\n",
                "    print(f\"\\nüìã Copy this: DEPTH_Z_SCALE = {final_scale:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Classes Definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Gripper & Robot classes\n"
                    ]
                }
            ],
            "source": [
                "class SmartGripperController:\n",
                "    CALIB_ANGLES = np.array([22, 30, 40, 50, 60, 70, 80, 90, 96])\n",
                "    CALIB_WIDTHS = np.array([54.0, 52.0, 48.0, 40.0, 32.0, 23.0, 12.0, 3.0, 0.0])\n",
                "    \n",
                "    def __init__(self, port='COM9', baudrate=115200):\n",
                "        self.port = port\n",
                "        self.baudrate = baudrate\n",
                "        self.serial = None\n",
                "        self.target_width = None\n",
                "        \n",
                "    def connect(self):\n",
                "        try:\n",
                "            self.serial = serial.Serial(self.port, self.baudrate, timeout=2)\n",
                "            time.sleep(2)\n",
                "            print(f\"‚úÖ Gripper on {self.port}\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå {e}\")\n",
                "            return False\n",
                "    \n",
                "    def disconnect(self):\n",
                "        if self.serial: self.serial.close()\n",
                "    \n",
                "    def send_command(self, cmd):\n",
                "        if self.serial:\n",
                "            self.serial.write((cmd + '\\n').encode())\n",
                "            time.sleep(0.3)\n",
                "    \n",
                "    def mm_to_angle(self, width_mm):\n",
                "        width = max(0.0, min(54.0, width_mm))\n",
                "        return int(round(np.interp(width, self.CALIB_WIDTHS[::-1], self.CALIB_ANGLES[::-1])))\n",
                "    \n",
                "    def open_for_object(self, width_mm):\n",
                "        self.target_width = width_mm\n",
                "        open_w = min(54.0, width_mm + GRIPPER_OPEN_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(open_w)\n",
                "        print(f\"ü¶æ Open: {width_mm:.1f}mm ‚Üí {open_w:.1f}mm ({angle}¬∞)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def grip_object(self, width_mm):\n",
                "        grip_w = max(0.0, width_mm - GRIPPER_GRIP_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(grip_w)\n",
                "        print(f\"ü¶æ Grip: {width_mm:.1f}mm ({angle}¬∞)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def release(self):\n",
                "        open_w = min(54.0, (self.target_width or 30) + 10)\n",
                "        self.send_command(f'G{self.mm_to_angle(open_w)}')\n",
                "        self.target_width = None\n",
                "\n",
                "\n",
                "class DobotControllerTCP:\n",
                "    def __init__(self, homography_matrix=None):\n",
                "        self.dashboard_port = 29999\n",
                "        self.sock = None\n",
                "        self.H = homography_matrix\n",
                "        \n",
                "    def connect(self, ip):\n",
                "        try:\n",
                "            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
                "            self.sock.settimeout(5)\n",
                "            self.sock.connect((ip, self.dashboard_port))\n",
                "            self.send_command(\"ClearError()\")\n",
                "            time.sleep(0.5)\n",
                "            self.send_command(\"EnableRobot()\")\n",
                "            time.sleep(4)\n",
                "            self.send_command(\"User(1)\")\n",
                "            self.send_command(\"Tool(1)\")\n",
                "            self.send_command(\"SpeedFactor(50)\")\n",
                "            print(\"‚úÖ Robot connected!\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"Error: {e}\")\n",
                "            return False\n",
                "\n",
                "    def send_command(self, cmd):\n",
                "        if self.sock:\n",
                "            self.sock.send((cmd + \"\\n\").encode(\"utf-8\"))\n",
                "            return self.sock.recv(1024).decode(\"utf-8\")\n",
                "\n",
                "    def home(self):\n",
                "        print(\"ü§ñ HOME...\")\n",
                "        self.send_command(\"MovJ(-253.07, 115.17, -17.07, -62.78)\")\n",
                "        time.sleep(4)\n",
                "\n",
                "    def move_to(self, x, y, z, r=0):\n",
                "        cmd = f\"MovJ({x},{y},{z},{r})\"\n",
                "        print(f\"   ‚Üí {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def move_to_and_wait(self, x, y, z, r=0, wait=3):\n",
                "        self.move_to(x, y, z, r)\n",
                "        time.sleep(wait)\n",
                "    \n",
                "    def joint_move(self, j1=0, j2=0, j3=0, j4=0):\n",
                "        cmd = f\"JointMovJ({j1},{j2},{j3},{j4})\"\n",
                "        print(f\"   ‚Üí {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def joint_move_and_wait(self, j1=0, j2=0, j3=0, j4=0, wait=3):\n",
                "        self.joint_move(j1, j2, j3, j4)\n",
                "        time.sleep(wait)\n",
                "\n",
                "    def pixel_to_robot(self, u, v):\n",
                "        if self.H is None: return None, None\n",
                "        pt = np.array([u, v, 1], dtype=np.float32)\n",
                "        res = np.dot(self.H, pt)\n",
                "        return res[0]/res[2], res[1]/res[2]\n",
                "\n",
                "print(\"‚úì Gripper & Robot classes\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Detector class\n"
                    ]
                }
            ],
            "source": [
                "class PreciseSizeDetector:\n",
                "    \"\"\"YOLO + Contour + Grid (Frame + Object)\"\"\"\n",
                "    \n",
                "    def __init__(self, yolo_model, pixels_per_mm):\n",
                "        self.yolo = yolo_model\n",
                "        self.ppm = pixels_per_mm\n",
                "    \n",
                "    def detect(self, frame):\n",
                "        objects = []\n",
                "        results = self.yolo(frame, conf=YOLO_CONFIDENCE, verbose=False)\n",
                "        \n",
                "        for r in results:\n",
                "            for box in r.boxes:\n",
                "                x1,y1,x2,y2 = map(int, box.xyxy[0])\n",
                "                conf = float(box.conf[0])\n",
                "                \n",
                "                roi = frame[y1:y2, x1:x2]\n",
                "                if roi.size == 0: continue\n",
                "                \n",
                "                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
                "                _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
                "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "                \n",
                "                if contours:\n",
                "                    cnt = max(contours, key=cv2.contourArea)\n",
                "                    cnt += np.array([x1, y1])\n",
                "                    rect = cv2.minAreaRect(cnt)\n",
                "                    cx, cy = int(rect[0][0]), int(rect[0][1])\n",
                "                    \n",
                "                    objects.append({\n",
                "                        'bbox': (x1, y1, x2-x1, y2-y1),\n",
                "                        'center': (cx, cy),\n",
                "                        'rect': rect,\n",
                "                        'rect_size': rect[1],\n",
                "                        'rect_angle': rect[2],\n",
                "                        'contour': cnt,\n",
                "                        'conf': conf,\n",
                "                        'area': cv2.contourArea(cnt)\n",
                "                    })\n",
                "        \n",
                "        if not objects:\n",
                "            objects = self.edge_detect(frame)\n",
                "        \n",
                "        return objects\n",
                "    \n",
                "    def edge_detect(self, frame):\n",
                "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
                "        edges = cv2.Canny(cv2.GaussianBlur(gray, (5,5), 0), 50, 150)\n",
                "        edges = cv2.dilate(edges, np.ones((3,3), np.uint8), iterations=2)\n",
                "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "        \n",
                "        objects = []\n",
                "        for cnt in contours:\n",
                "            area = cv2.contourArea(cnt)\n",
                "            if area > MIN_OBJECT_AREA:\n",
                "                hull = cv2.convexHull(cnt)\n",
                "                rect = cv2.minAreaRect(hull)\n",
                "                x,y,w,h = cv2.boundingRect(hull)\n",
                "                objects.append({\n",
                "                    'bbox': (x,y,w,h),\n",
                "                    'center': (x+w//2, y+h//2),\n",
                "                    'rect': rect,\n",
                "                    'rect_size': rect[1],\n",
                "                    'rect_angle': rect[2],\n",
                "                    'contour': hull,\n",
                "                    'area': area\n",
                "                })\n",
                "        return sorted(objects, key=lambda o: o['area'], reverse=True)\n",
                "    \n",
                "    def draw_frame_grid(self, frame):\n",
                "        \"\"\"Draw grid on entire frame\"\"\"\n",
                "        if not SHOW_FRAME_GRID: return frame\n",
                "        h, w = frame.shape[:2]\n",
                "        grid_px = int(FRAME_GRID_SIZE_MM * self.ppm)\n",
                "        for x in range(0, w, grid_px):\n",
                "            cv2.line(frame, (x,0), (x,h), (50,50,50), 1)\n",
                "        for y in range(0, h, grid_px):\n",
                "            cv2.line(frame, (0,y), (w,y), (50,50,50), 1)\n",
                "        cv2.putText(frame, f\"Frame Grid: {FRAME_GRID_SIZE_MM}mm\", (10, h-10),\n",
                "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100,100,100), 1)\n",
                "        return frame\n",
                "    \n",
                "    def draw_object_grid(self, frame, obj):\n",
                "        \"\"\"Draw grid overlay on object\"\"\"\n",
                "        if not SHOW_OBJECT_GRID: return\n",
                "        \n",
                "        x, y, w, h = obj['bbox']\n",
                "        grid_px = int(OBJECT_GRID_SIZE_MM * self.ppm)\n",
                "        if grid_px < 3: grid_px = 3\n",
                "        \n",
                "        # Draw grid inside bbox\n",
                "        for gx in range(x, x+w, grid_px):\n",
                "            cv2.line(frame, (gx, y), (gx, y+h), (100,100,255), 1)\n",
                "        for gy in range(y, y+h, grid_px):\n",
                "            cv2.line(frame, (x, gy), (x+w, gy), (100,100,255), 1)\n",
                "        \n",
                "        # Size labels\n",
                "        w_mm = w / self.ppm\n",
                "        h_mm = h / self.ppm\n",
                "        cv2.putText(frame, f\"{w_mm:.0f}mm\", (x + w//2 - 15, y - 3),\n",
                "                   cv2.FONT_HERSHEY_SIMPLEX, 0.35, (100,100,255), 1)\n",
                "        cv2.putText(frame, f\"{h_mm:.0f}mm\", (x + w + 3, y + h//2),\n",
                "                   cv2.FONT_HERSHEY_SIMPLEX, 0.35, (100,100,255), 1)\n",
                "\n",
                "print(\"‚úì Detector class\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Grasp selector\n"
                    ]
                }
            ],
            "source": [
                "class SmartGraspSelector:\n",
                "    def __init__(self, pixels_per_mm):\n",
                "        self.ppm = pixels_per_mm\n",
                "    \n",
                "    def analyze_object(self, obj):\n",
                "        w, h = obj['rect_size']\n",
                "        angle = obj['rect_angle']\n",
                "        cx, cy = obj['center']\n",
                "        aspect = max(w,h) / (min(w,h) + 0.001)\n",
                "        is_ring = self.detect_ring(obj)\n",
                "        \n",
                "        grasps = []\n",
                "        \n",
                "        if aspect > 2.0:\n",
                "            if w < h:\n",
                "                grip_w, grip_a = w / self.ppm, angle + 90\n",
                "            else:\n",
                "                grip_w, grip_a = h / self.ppm, angle\n",
                "            grasps.append({'center': (cx,cy), 'width_mm': grip_w, 'angle': self.norm(grip_a), 'score': 1.0, 'type': 'narrow'})\n",
                "            \n",
                "            alt_w = max(w,h) / self.ppm\n",
                "            if alt_w <= GRIPPER_MAX_WIDTH_MM:\n",
                "                grasps.append({'center': (cx,cy), 'width_mm': alt_w, 'angle': self.norm(grip_a+90), 'score': 0.5, 'type': 'alt'})\n",
                "        \n",
                "        elif is_ring:\n",
                "            inner_w = max(w,h) / self.ppm * 0.3\n",
                "            for i in range(4):\n",
                "                grasps.append({'center': (cx,cy), 'width_mm': inner_w, 'angle': i*45, 'score': 1.0 if i==0 else 0.8, 'type': 'ring'})\n",
                "        \n",
                "        else:\n",
                "            if w < h:\n",
                "                grip_w, grip_a = w / self.ppm, angle + 90\n",
                "            else:\n",
                "                grip_w, grip_a = h / self.ppm, angle\n",
                "            grasps.append({'center': (cx,cy), 'width_mm': grip_w, 'angle': self.norm(grip_a), 'score': 1.0, 'type': 'default'})\n",
                "            \n",
                "            perp_w = max(w,h) / self.ppm\n",
                "            if perp_w <= GRIPPER_MAX_WIDTH_MM:\n",
                "                grasps.append({'center': (cx,cy), 'width_mm': perp_w, 'angle': self.norm(grip_a+90), 'score': 0.6, 'type': 'perp'})\n",
                "        \n",
                "        return grasps\n",
                "    \n",
                "    def detect_ring(self, obj):\n",
                "        cnt = obj.get('contour')\n",
                "        if cnt is None: return False\n",
                "        hull = cv2.convexHull(cnt)\n",
                "        return (cv2.contourArea(cnt) / (cv2.contourArea(hull) + 0.001)) < 0.7\n",
                "    \n",
                "    def norm(self, a):\n",
                "        while a > 90: a -= 180\n",
                "        while a < -90: a += 180\n",
                "        return a\n",
                "\n",
                "print(\"‚úì Grasp selector\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Depth estimator\n"
                    ]
                }
            ],
            "source": [
                "class RobustDepthEstimator:\n",
                "    \"\"\"Multi-sample + temporal + camera height aware\"\"\"\n",
                "    \n",
                "    def __init__(self, model, device='cpu', camera_height_mm=450, history_size=5):\n",
                "        self.model = model\n",
                "        self.device = device\n",
                "        self.camera_height = camera_height_mm\n",
                "        self.floor_depth = None\n",
                "        self.history = deque(maxlen=history_size)\n",
                "    \n",
                "    def estimate_depth(self, frame):\n",
                "        return self.model.infer_image(frame)\n",
                "    \n",
                "    def calibrate_floor(self, frame):\n",
                "        depth = self.estimate_depth(frame)\n",
                "        h, w = depth.shape\n",
                "        center = depth[h//3:2*h//3, w//3:2*w//3]\n",
                "        self.floor_depth = np.median(center)\n",
                "        print(f\"‚úÖ Floor depth: {self.floor_depth:.4f}\")\n",
                "        print(f\"   Camera height: {self.camera_height}mm\")\n",
                "        return self.floor_depth\n",
                "    \n",
                "    def get_object_height(self, depth_map, obj, scale):\n",
                "        if self.floor_depth is None: return 0\n",
                "        \n",
                "        x, y, w, h = obj['bbox']\n",
                "        region = depth_map[y:y+h, x:x+w]\n",
                "        if region.size == 0: return 0\n",
                "        \n",
                "        # Multi-sample\n",
                "        samples = [np.median(region)]\n",
                "        qh, qw = h//4, w//4\n",
                "        if qh > 0 and qw > 0:\n",
                "            samples.extend([\n",
                "                np.median(region[:qh, :qw]),\n",
                "                np.median(region[:qh, -qw:]),\n",
                "                np.median(region[-qh:, :qw]),\n",
                "                np.median(region[-qh:, -qw:])\n",
                "            ])\n",
                "        \n",
                "        obj_depth = np.median(samples)\n",
                "        height = max(0, (obj_depth - self.floor_depth) * scale)\n",
                "        \n",
                "        # Temporal averaging\n",
                "        self.history.append(height)\n",
                "        return np.median(self.history)\n",
                "    \n",
                "    def calculate_z(self, height_mm):\n",
                "        z = Z_FLOOR + (height_mm * 0.5)\n",
                "        return max(Z_FLOOR, min(Z_SAFE, z))\n",
                "\n",
                "print(\"‚úì Depth estimator\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Initialize & Connect"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Components initialized\n"
                    ]
                }
            ],
            "source": [
                "gripper = SmartGripperController(port=ESP32_PORT, baudrate=ESP32_BAUDRATE)\n",
                "robot = DobotControllerTCP(homography_matrix=HOMOGRAPHY_MATRIX)\n",
                "detector = PreciseSizeDetector(yolo_model, PIXELS_PER_MM)\n",
                "grasp_selector = SmartGraspSelector(PIXELS_PER_MM)\n",
                "depth_estimator = RobustDepthEstimator(depth_model, device=DEVICE, camera_height_mm=CAMERA_HEIGHT_MM)\n",
                "print(\"‚úì Components initialized\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Gripper on COM9\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "gripper.connect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Robot connected!\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "robot.connect(ROBOT_IP)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì∑ Capture Background"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üì∑ BACKGROUND | SPACE=Capture Q=Skip\n",
                        "‚úÖ Floor depth: 3.0112\n",
                        "   Camera height: 630mm\n"
                    ]
                }
            ],
            "source": [
                "print(\"üì∑ BACKGROUND | SPACE=Capture Q=Skip\")\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    cv2.putText(frame, \"SPACE=Capture | Q=Skip\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
                "    cv2.imshow('BG', frame)\n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord(' '):\n",
                "        depth_estimator.calibrate_floor(frame)\n",
                "        break\n",
                "    elif key == ord('q'):\n",
                "        print(\"Skipped\")\n",
                "        break\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üéØ MAIN PICK-AND-PLACE\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Robot connected!\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "robot.connect(ROBOT_IP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ü§ñ HOME...\n"
                    ]
                }
            ],
            "source": [
                "robot.home()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==================================================\n",
                        "üéØ PICK v7\n",
                        "Click=Select | SPACE=Execute | F=FrameGrid | O=ObjGrid | Q=Quit\n",
                        "==================================================\n"
                    ]
                }
            ],
            "source": [
                "selected_object = None\n",
                "selected_grasp = None\n",
                "detected_objects = []\n",
                "current_grasps = []\n",
                "current_depth = None\n",
                "\n",
                "def mouse_callback(event, x, y, flags, param):\n",
                "    global selected_object, selected_grasp, current_grasps\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        for g in current_grasps:\n",
                "            gx, gy = g['center']\n",
                "            if abs(x-gx) < 20 and abs(y-gy) < 20:\n",
                "                selected_grasp = g\n",
                "                print(f\"\\nüéØ Grasp: W={g['width_mm']:.1f}mm A={g['angle']:.1f}¬∞\")\n",
                "                return\n",
                "        for obj in detected_objects:\n",
                "            bx,by,bw,bh = obj['bbox']\n",
                "            if bx <= x <= bx+bw and by <= y <= by+bh:\n",
                "                selected_object = obj\n",
                "                current_grasps = grasp_selector.analyze_object(obj)\n",
                "                selected_grasp = current_grasps[0] if current_grasps else None\n",
                "                if selected_grasp:\n",
                "                    print(f\"\\nüì¶ Object: {len(current_grasps)} grasps\")\n",
                "                break\n",
                "\n",
                "def draw_grasps(frame, grasps, selected):\n",
                "    for g in grasps:\n",
                "        cx, cy = g['center']\n",
                "        angle = g['angle']\n",
                "        is_sel = (selected and g == selected)\n",
                "        color = (0,0,255) if is_sel else ((0,255,0) if g['score']>=1.0 else (0,255,255))\n",
                "        thick = 3 if is_sel else (2 if g['score']>=1.0 else 1)\n",
                "        dx = int(30 * np.cos(np.radians(angle)))\n",
                "        dy = int(30 * np.sin(np.radians(angle)))\n",
                "        cv2.line(frame, (cx-dx,cy-dy), (cx+dx,cy+dy), color, thick)\n",
                "        cv2.circle(frame, (cx,cy), 5, color, -1)\n",
                "\n",
                "def pick_with_grasp(obj, grasp):\n",
                "    cx, cy = grasp['center']\n",
                "    grip_w = grasp['width_mm']\n",
                "    robot_r = -grasp['angle']\n",
                "    robot_x, robot_y = robot.pixel_to_robot(cx, cy)\n",
                "    height = depth_estimator.get_object_height(current_depth, obj, DEPTH_Z_SCALE) if current_depth is not None else 0\n",
                "    z_grasp = depth_estimator.calculate_z(height)\n",
                "    \n",
                "    print(f\"\\nü§ñ Pick: W={grip_w:.1f}mm R={robot_r:.1f}¬∞ Z={z_grasp:.1f}\")\n",
                "    print(\"üîÑ Safe position...\")\n",
                "    robot.joint_move_and_wait(0, 0, 0, 0, 3)\n",
                "    gripper.open_for_object(GRIPPER_MAX_WIDTH_MM)\n",
                "    time.sleep(4)\n",
                "    robot.move_to_and_wait(robot_x, robot_y, Z_APPROACH, robot_r, 3)\n",
                "    robot.move_to_and_wait(robot_x, robot_y, z_grasp, robot_r, 2)\n",
                "    gripper.grip_object(grip_w-6) ### ‡πÄ‡∏û‡∏¥‡πà‡∏° -5 ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô\n",
                "    time.sleep(4)\n",
                "    robot.move_to_and_wait(robot_x, robot_y, Z_SAFE, robot_r, 2)\n",
                "    robot.move_to_and_wait(*DROP_POS[:3], DROP_POS[3], 3)\n",
                "    gripper.release()\n",
                "    time.sleep(4)\n",
                "    robot.home()\n",
                "    print(\"‚úÖ Complete!\")\n",
                "\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Pick v7')\n",
                "cv2.setMouseCallback('Pick v7', mouse_callback)\n",
                "\n",
                "frame_count = 0\n",
                "print(\"=\"*50)\n",
                "print(\"üéØ PICK v7\")\n",
                "print(\"Click=Select | SPACE=Execute | F=FrameGrid | O=ObjGrid | Q=Quit\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    \n",
                "    # Frame grid\n",
                "    frame = detector.draw_frame_grid(frame)\n",
                "    \n",
                "    frame_count += 1\n",
                "    if frame_count % 10 == 0:\n",
                "        current_depth = depth_estimator.estimate_depth(frame)\n",
                "    \n",
                "    detected_objects = detector.detect(frame)\n",
                "    \n",
                "    for obj in detected_objects:\n",
                "        x,y,w,h = obj['bbox']\n",
                "        is_sel = (selected_object and obj['center'] == selected_object['center'])\n",
                "        color = (0,0,255) if is_sel else (0,255,0)\n",
                "        \n",
                "        cv2.rectangle(frame, (x,y), (x+w,y+h), color, 2)\n",
                "        if 'rect' in obj:\n",
                "            box = cv2.boxPoints(obj['rect'])\n",
                "            cv2.drawContours(frame, [np.int32(box)], 0, color, 1)\n",
                "        \n",
                "        # Object grid\n",
                "        detector.draw_object_grid(frame, obj)\n",
                "        \n",
                "        rect_w, rect_h = obj['rect_size']\n",
                "        w_mm = min(rect_w, rect_h) / PIXELS_PER_MM\n",
                "        cv2.putText(frame, f\"W:{w_mm:.0f}mm\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
                "    \n",
                "    if selected_object and current_grasps:\n",
                "        draw_grasps(frame, current_grasps, selected_grasp)\n",
                "    \n",
                "    cv2.rectangle(frame, (0,0), (640,35), (30,30,30), -1)\n",
                "    cv2.putText(frame, f\"Obj:{len(detected_objects)} | Click | SPACE | F=FGrid O=OGrid | Q\",\n",
                "               (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1)\n",
                "    \n",
                "    if selected_grasp:\n",
                "        cv2.putText(frame, f\"[GRASP: W={selected_grasp['width_mm']:.1f}mm - SPACE]\",\n",
                "                   (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
                "    \n",
                "    cv2.imshow('Pick v7', frame)\n",
                "    \n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == ord('r'):\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "    elif key == ord('f'):\n",
                "        SHOW_FRAME_GRID = not SHOW_FRAME_GRID\n",
                "        print(f\"Frame grid: {SHOW_FRAME_GRID}\")\n",
                "    elif key == ord('o'):\n",
                "        SHOW_OBJECT_GRID = not SHOW_OBJECT_GRID\n",
                "        print(f\"Object grid: {SHOW_OBJECT_GRID}\")\n",
                "    elif key == ord('h'):\n",
                "        robot.home()\n",
                "    elif key == ord(' ') and selected_object and selected_grasp:\n",
                "        pick_with_grasp(selected_object, selected_grasp)\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gripper.disconnect()\n",
                "print(\"‚úÖ Done\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
