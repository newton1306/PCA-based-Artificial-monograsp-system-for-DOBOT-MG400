{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ Advanced Grasp Detection v9\n",
                "\n",
                "## New in v9\n",
                "| Feature | Description |\n",
                "|---------|-------------|\n",
                "| **üîÑ Robot R Offset** | ‡πÉ‡∏ä‡πâ R=-25.55 ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ‡∏´‡∏°‡∏∏‡∏ô‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ ¬±360¬∞ |\n",
                "| **üî¨ PCA-based Grasp** | ‡πÉ‡∏ä‡πâ PCA ‡∏´‡∏≤‡πÅ‡∏Å‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ |\n",
                "| **ü¶æ Tighter Grip** | grip_w - 5mm ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÅ‡∏ô‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô |\n",
                "\n",
                "### Robot R Reference\n",
                "- `R = -25.55` ‚Üí ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (0¬∞)\n",
                "- `R = -116.07` ‚Üí ‡∏´‡∏°‡∏∏‡∏ô‡∏ï‡∏≤‡∏°‡πÄ‡∏Ç‡πá‡∏° 90¬∞\n",
                "- `R = 60.87` ‚Üí ‡∏´‡∏°‡∏∏‡∏ô‡∏ó‡∏ß‡∏ô‡πÄ‡∏Ç‡πá‡∏° 90¬∞"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch: 2.9.1+cpu\n",
                        "CUDA: False\n",
                        "‚úì Imports\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import cv2\n",
                "import numpy as np\n",
                "import time\n",
                "import socket\n",
                "import serial\n",
                "import torch\n",
                "from collections import deque\n",
                "from ultralytics import YOLO\n",
                "\n",
                "sys.path.append('Depth-Anything-V2')\n",
                "\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "print(\"‚úì Imports\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Hardware Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Hardware config\n"
                    ]
                }
            ],
            "source": [
                "ROBOT_IP = '192.168.1.6'\n",
                "ESP32_PORT = 'COM9'\n",
                "ESP32_BAUDRATE = 115200\n",
                "CAMERA_ID = 2\n",
                "\n",
                "HOMOGRAPHY_MATRIX = np.array([\n",
                "    [0.005703976266962427, -0.3265299161278153, 88.58634169557483],\n",
                "    [-0.47704058225560797, 0.015355046930804153, 172.0941543570439],\n",
                "    [-0.00029949919510557677, 0.00018728182448344945, 1.0],\n",
                "], dtype=np.float32)\n",
                "\n",
                "print(\"‚úì Hardware config\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Robot connected!\n",
                        "   R offset: -25.55¬∞\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "robot.connect(ROBOT_IP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ü§ñ HOME...\n"
                    ]
                }
            ],
            "source": [
                "robot.home()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üîß CALIBRATION SECTION\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìê Calibration 1: PIXELS_PER_MM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Distance: 112.0 px\n",
                        "PIXELS_PER_MM = 2.2400\n",
                        "Distance: 0.0 px\n"
                    ]
                }
            ],
            "source": [
                "# Uncomment ‡πÄ‡∏û‡∏∑‡πà‡∏≠ calibrate\n",
                "\n",
                "drawing = False\n",
                "start_pt, end_pt = None, None\n",
                "px_dist = 0\n",
                "\n",
                "def cb(event, x, y, flags, param):\n",
                "    global drawing, start_pt, end_pt, px_dist\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        drawing, start_pt = True, (x, y)\n",
                "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
                "        end_pt = (x, y)\n",
                "    elif event == cv2.EVENT_LBUTTONUP:\n",
                "        drawing, end_pt = False, (x, y)\n",
                "        px_dist = np.sqrt((end_pt[0]-start_pt[0])**2 + (end_pt[1]-start_pt[1])**2)\n",
                "        print(f\"Distance: {px_dist:.1f} px\")\n",
                "\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Pixel Cal')\n",
                "cv2.setMouseCallback('Pixel Cal', cb)\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    if start_pt and end_pt: cv2.line(frame, start_pt, end_pt, (0,255,0), 2)\n",
                "    cv2.imshow('Pixel Cal', frame)\n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == 13 and px_dist > 0:\n",
                "        mm = float(input(\"Real size (mm): \"))\n",
                "        print(f\"PIXELS_PER_MM = {px_dist/mm:.4f}\")\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìè Calibration 2: Camera Height & Depth Scale"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Camera height: 630mm\n"
                    ]
                }
            ],
            "source": [
                "CAMERA_HEIGHT_MM = 630  # ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô\n",
                "print(f\"Camera height: {CAMERA_HEIGHT_MM}mm\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3Ô∏è‚É£ Configuration\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Configuration\n",
                        "  Robot R offset: -25.55¬∞ (neutral position)\n",
                        "  GRIP_MARGIN: -5mm (tighter grip)\n"
                    ]
                }
            ],
            "source": [
                "# === CALIBRATED VALUES ===\n",
                "PIXELS_PER_MM = 2.240\n",
                "DEPTH_Z_SCALE = 26.1660\n",
                "DEPTH_Z_SCALE = 63.2093\n",
                "CAMERA_HEIGHT_MM = 630\n",
                "\n",
                "# === Robot R Rotation ===\n",
                "# R = -25.55 ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (camera angle 0¬∞)\n",
                "# R = -116.07 ‡∏Ñ‡∏∑‡∏≠‡∏´‡∏°‡∏∏‡∏ô‡∏ï‡∏≤‡∏°‡πÄ‡∏Ç‡πá‡∏° 90¬∞ ‡∏à‡∏≤‡∏Å -25.55\n",
                "# R = 60.87 ‡∏Ñ‡∏∑‡∏≠‡∏´‡∏°‡∏∏‡∏ô‡∏ó‡∏ß‡∏ô‡πÄ‡∏Ç‡πá‡∏° 90¬∞ ‡∏à‡∏≤‡∏Å -25.55\n",
                "ROBOT_R_OFFSET = -25.55  # ‡∏Ñ‡πà‡∏≤ R ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á gripper\n",
                "\n",
                "# === Z Heights ===\n",
                "Z_FLOOR = -64\n",
                "Z_SAFE = -40\n",
                "Z_APPROACH = -55\n",
                "\n",
                "# === Drop Position ===\n",
                "DROP_POS = (-253.07, 115.17, -17.07, -62.78)\n",
                "\n",
                "# === Gripper ===\n",
                "GRIPPER_SERVO_OPEN_ANGLE = 22\n",
                "GRIPPER_SERVO_CLOSE_ANGLE = 96\n",
                "GRIPPER_MAX_WIDTH_MM = 54\n",
                "GRIPPER_MIN_WIDTH_MM = 0\n",
                "GRIPPER_OPEN_MARGIN_MM = 5\n",
                "GRIPPER_GRIP_MARGIN_MM = 5  # -5mm ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÅ‡∏ô‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô\n",
                "\n",
                "# === Detection ===\n",
                "MIN_OBJECT_AREA = 1000\n",
                "YOLO_CONFIDENCE = 0.25\n",
                "\n",
                "# === Depth Model ===\n",
                "DEPTH_MODEL_PATH = 'Depth-Anything-V2/checkpoints/depth_anything_v2_vits.pth'\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "# === Grid Display ===\n",
                "SHOW_FRAME_GRID = True\n",
                "SHOW_OBJECT_GRID = True\n",
                "FRAME_GRID_SIZE_MM = 20\n",
                "OBJECT_GRID_SIZE_MM = 5\n",
                "\n",
                "print(\"‚úì Configuration\")\n",
                "print(f\"  Robot R offset: {ROBOT_R_OFFSET}¬∞ (neutral position)\")\n",
                "print(f\"  GRIP_MARGIN: -{GRIPPER_GRIP_MARGIN_MM}mm (tighter grip)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Load Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading DepthAnything V2...\n",
                        "‚úÖ Depth model on cpu\n",
                        "Loading YOLOv8...\n",
                        "‚úÖ YOLO loaded\n"
                    ]
                }
            ],
            "source": [
                "from depth_anything_v2.dpt import DepthAnythingV2\n",
                "\n",
                "model_configs = {\n",
                "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
                "}\n",
                "\n",
                "print(\"Loading DepthAnything V2...\")\n",
                "depth_model = DepthAnythingV2(**model_configs['vits'])\n",
                "depth_model.load_state_dict(torch.load(DEPTH_MODEL_PATH, map_location='cpu'))\n",
                "depth_model = depth_model.to(DEVICE).eval()\n",
                "print(f\"‚úÖ Depth model on {DEVICE}\")\n",
                "\n",
                "print(\"Loading YOLOv8...\")\n",
                "yolo_model = YOLO('yolov8n.pt')\n",
                "print(\"‚úÖ YOLO loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìè Multi-Object Depth Calibration (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "üìè DEPTH CALIBRATION\n",
                        "C=Floor | Click=Add Sample | S=Show | Q=Quit\n",
                        "============================================================\n",
                        "‚úÖ Floor: 2.3933\n",
                        "   Sample 1: Scale=73.92\n",
                        "   Sample 2: Scale=138.00\n",
                        "   Sample 3: Scale=15.14\n",
                        "   Sample 4: Scale=25.77\n",
                        "\n",
                        "‚úÖ DEPTH_Z_SCALE = 63.2093\n",
                        "\n",
                        "üìã DEPTH_Z_SCALE = 63.2093\n"
                    ]
                }
            ],
            "source": [
                "# Run ‡∏ô‡∏µ‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ calibrate depth\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üìè DEPTH CALIBRATION\")\n",
                "print(\"C=Floor | Click=Add Sample | S=Show | Q=Quit\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "calibration_samples = []\n",
                "floor_depth = None\n",
                "click_x, click_y = None, None\n",
                "\n",
                "def depth_cal_cb(event, x, y, flags, param):\n",
                "    global click_x, click_y\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        click_x, click_y = x, y\n",
                "\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Depth Cal')\n",
                "cv2.setMouseCallback('Depth Cal', depth_cal_cb)\n",
                "current_depth_map = None\n",
                "fc = 0\n",
                "\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    fc += 1\n",
                "    if fc % 5 == 0:\n",
                "        current_depth_map = depth_model.infer_image(frame)\n",
                "    \n",
                "    floor_str = f\"Floor: {floor_depth:.4f}\" if floor_depth else \"Floor: NOT SET\"\n",
                "    cv2.putText(frame, f\"{floor_str} | Samples: {len(calibration_samples)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
                "    if calibration_samples:\n",
                "        cv2.putText(frame, f\"Scale: {np.mean([s['scale'] for s in calibration_samples]):.2f}\", (10, 460), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
                "    cv2.imshow('Depth Cal', frame)\n",
                "    \n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == ord('c') and current_depth_map is not None:\n",
                "        h, w = current_depth_map.shape\n",
                "        floor_depth = np.median(current_depth_map[h//3:2*h//3, w//3:2*w//3])\n",
                "        print(f\"‚úÖ Floor: {floor_depth:.4f}\")\n",
                "    elif key == ord('s') and calibration_samples:\n",
                "        print(f\"\\n‚úÖ DEPTH_Z_SCALE = {np.mean([s['scale'] for s in calibration_samples]):.4f}\")\n",
                "    \n",
                "    if click_x is not None and current_depth_map is not None and floor_depth is not None:\n",
                "        x, y = click_x, click_y\n",
                "        region = current_depth_map[max(0,y-10):y+10, max(0,x-10):x+10]\n",
                "        raw_diff = np.median(region) - floor_depth\n",
                "        if raw_diff > 0:\n",
                "            try:\n",
                "                h_mm = float(input(f\"Height at ({x},{y}) in mm: \"))\n",
                "                calibration_samples.append({'height_mm': h_mm, 'scale': h_mm / raw_diff})\n",
                "                print(f\"   Sample {len(calibration_samples)}: Scale={h_mm/raw_diff:.2f}\")\n",
                "            except: pass\n",
                "        click_x, click_y = None, None\n",
                "\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()\n",
                "if calibration_samples:\n",
                "    print(f\"\\nüìã DEPTH_Z_SCALE = {np.mean([s['scale'] for s in calibration_samples]):.4f}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Classes Definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Gripper & Robot classes (v9 with R offset)\n"
                    ]
                }
            ],
            "source": [
                "class SmartGripperController:\n",
                "    CALIB_ANGLES = np.array([22, 30, 40, 50, 60, 70, 80, 90, 96])\n",
                "    CALIB_WIDTHS = np.array([54.0, 52.0, 48.0, 40.0, 32.0, 23.0, 12.0, 3.0, 0.0])\n",
                "    \n",
                "    def __init__(self, port='COM9', baudrate=115200):\n",
                "        self.port = port\n",
                "        self.baudrate = baudrate\n",
                "        self.serial = None\n",
                "        self.target_width = None\n",
                "        \n",
                "    def connect(self):\n",
                "        try:\n",
                "            self.serial = serial.Serial(self.port, self.baudrate, timeout=2)\n",
                "            time.sleep(2)\n",
                "            print(f\"‚úÖ Gripper on {self.port}\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå {e}\")\n",
                "            return False\n",
                "    \n",
                "    def disconnect(self):\n",
                "        if self.serial: self.serial.close()\n",
                "    \n",
                "    def send_command(self, cmd):\n",
                "        if self.serial:\n",
                "            self.serial.write((cmd + '\\n').encode())\n",
                "            time.sleep(0.3)\n",
                "    \n",
                "    def mm_to_angle(self, width_mm):\n",
                "        width = max(0.0, min(54.0, width_mm))\n",
                "        return int(round(np.interp(width, self.CALIB_WIDTHS[::-1], self.CALIB_ANGLES[::-1])))\n",
                "    \n",
                "    def open_for_object(self, width_mm):\n",
                "        self.target_width = width_mm\n",
                "        open_w = min(54.0, width_mm + GRIPPER_OPEN_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(open_w)\n",
                "        print(f\"ü¶æ Open: {open_w:.1f}mm ({angle}¬∞)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def grip_object(self, width_mm):\n",
                "        grip_w = max(0.0, width_mm - GRIPPER_GRIP_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(grip_w)\n",
                "        print(f\"ü¶æ Grip: {width_mm:.1f}mm - {GRIPPER_GRIP_MARGIN_MM}mm = {grip_w:.1f}mm ({angle}¬∞)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def release(self):\n",
                "        open_w = min(54.0, (self.target_width or 30) + 10)\n",
                "        self.send_command(f'G{self.mm_to_angle(open_w)}')\n",
                "        self.target_width = None\n",
                "\n",
                "\n",
                "class DobotControllerTCP:\n",
                "    def __init__(self, homography_matrix=None, r_offset=-25.55):\n",
                "        self.dashboard_port = 29999\n",
                "        self.sock = None\n",
                "        self.H = homography_matrix\n",
                "        self.r_offset = r_offset  # v9: Robot R offset\n",
                "        \n",
                "    def connect(self, ip):\n",
                "        try:\n",
                "            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
                "            self.sock.settimeout(5)\n",
                "            self.sock.connect((ip, self.dashboard_port))\n",
                "            self.send_command(\"ClearError()\")\n",
                "            time.sleep(0.5)\n",
                "            self.send_command(\"EnableRobot()\")\n",
                "            time.sleep(4)\n",
                "            self.send_command(\"User(1)\")\n",
                "            self.send_command(\"Tool(1)\")\n",
                "            self.send_command(\"SpeedFactor(50)\")\n",
                "            print(\"‚úÖ Robot connected!\")\n",
                "            print(f\"   R offset: {self.r_offset}¬∞\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"Error: {e}\")\n",
                "            return False\n",
                "\n",
                "    def send_command(self, cmd):\n",
                "        if self.sock:\n",
                "            self.sock.send((cmd + \"\\n\").encode(\"utf-8\"))\n",
                "            return self.sock.recv(1024).decode(\"utf-8\")\n",
                "\n",
                "    def home(self):\n",
                "        print(\"ü§ñ HOME...\")\n",
                "        self.send_command(\"MovJ(-253.07, 115.17, -17.07, -62.78)\")\n",
                "        time.sleep(4)\n",
                "\n",
                "    def move_to(self, x, y, z, r=0):\n",
                "        cmd = f\"MovJ({x},{y},{z},{r})\"\n",
                "        print(f\"   ‚Üí {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def move_to_and_wait(self, x, y, z, r=0, wait=3):\n",
                "        self.move_to(x, y, z, r)\n",
                "        time.sleep(wait)\n",
                "    \n",
                "    def joint_move(self, j1=0, j2=0, j3=0, j4=0):\n",
                "        cmd = f\"JointMovJ({j1},{j2},{j3},{j4})\"\n",
                "        print(f\"   ‚Üí {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def joint_move_and_wait(self, j1=0, j2=0, j3=0, j4=0, wait=3):\n",
                "        self.joint_move(j1, j2, j3, j4)\n",
                "        time.sleep(wait)\n",
                "\n",
                "    def pixel_to_robot(self, u, v):\n",
                "        if self.H is None: return None, None\n",
                "        pt = np.array([u, v, 1], dtype=np.float32)\n",
                "        res = np.dot(self.H, pt)\n",
                "        return res[0]/res[2], res[1]/res[2]\n",
                "    \n",
                "    def camera_angle_to_robot_r(self, camera_angle):\n",
                "        \"\"\"v9: ‡πÅ‡∏õ‡∏•‡∏á camera angle ‡πÄ‡∏õ‡πá‡∏ô robot R\n",
                "        \n",
                "        Camera angle 0¬∞ ‚Üí Robot R = -25.55 (neutral)\n",
                "        Camera angle +90¬∞ ‚Üí Robot R = +64.45 (‡∏ó‡∏ß‡∏ô‡πÄ‡∏Ç‡πá‡∏°)\n",
                "        Camera angle -90¬∞ ‚Üí Robot R = -115.55 (‡∏ï‡∏≤‡∏°‡πÄ‡∏Ç‡πá‡∏°)\n",
                "        \"\"\"\n",
                "        robot_r = self.r_offset - camera_angle\n",
                "        return robot_r\n",
                "\n",
                "print(\"‚úì Gripper & Robot classes (v9 with R offset)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Detector class\n"
                    ]
                }
            ],
            "source": [
                "class PreciseSizeDetector:\n",
                "    \"\"\"YOLO + Contour + Grid\"\"\"\n",
                "    \n",
                "    def __init__(self, yolo_model, pixels_per_mm):\n",
                "        self.yolo = yolo_model\n",
                "        self.ppm = pixels_per_mm\n",
                "    \n",
                "    def detect(self, frame):\n",
                "        objects = []\n",
                "        results = self.yolo(frame, conf=YOLO_CONFIDENCE, verbose=False)\n",
                "        \n",
                "        for r in results:\n",
                "            for box in r.boxes:\n",
                "                x1,y1,x2,y2 = map(int, box.xyxy[0])\n",
                "                conf = float(box.conf[0])\n",
                "                \n",
                "                roi = frame[y1:y2, x1:x2]\n",
                "                if roi.size == 0: continue\n",
                "                \n",
                "                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
                "                _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
                "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "                \n",
                "                if contours:\n",
                "                    cnt = max(contours, key=cv2.contourArea)\n",
                "                    cnt = cnt + np.array([x1, y1])\n",
                "                    rect = cv2.minAreaRect(cnt)\n",
                "                    cx, cy = int(rect[0][0]), int(rect[0][1])\n",
                "                    \n",
                "                    objects.append({\n",
                "                        'bbox': (x1, y1, x2-x1, y2-y1),\n",
                "                        'center': (cx, cy),\n",
                "                        'rect': rect,\n",
                "                        'rect_size': rect[1],\n",
                "                        'rect_angle': rect[2],\n",
                "                        'contour': cnt,\n",
                "                        'conf': conf,\n",
                "                        'area': cv2.contourArea(cnt)\n",
                "                    })\n",
                "        \n",
                "        if not objects:\n",
                "            objects = self.edge_detect(frame)\n",
                "        \n",
                "        return objects\n",
                "    \n",
                "    def edge_detect(self, frame):\n",
                "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
                "        edges = cv2.Canny(cv2.GaussianBlur(gray, (5,5), 0), 50, 150)\n",
                "        edges = cv2.dilate(edges, np.ones((3,3), np.uint8), iterations=2)\n",
                "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "        \n",
                "        objects = []\n",
                "        for cnt in contours:\n",
                "            area = cv2.contourArea(cnt)\n",
                "            if area > MIN_OBJECT_AREA:\n",
                "                hull = cv2.convexHull(cnt)\n",
                "                rect = cv2.minAreaRect(hull)\n",
                "                x,y,w,h = cv2.boundingRect(hull)\n",
                "                objects.append({\n",
                "                    'bbox': (x,y,w,h),\n",
                "                    'center': (x+w//2, y+h//2),\n",
                "                    'rect': rect,\n",
                "                    'rect_size': rect[1],\n",
                "                    'rect_angle': rect[2],\n",
                "                    'contour': hull,\n",
                "                    'area': area\n",
                "                })\n",
                "        return sorted(objects, key=lambda o: o['area'], reverse=True)\n",
                "    \n",
                "    def draw_frame_grid(self, frame):\n",
                "        if not SHOW_FRAME_GRID: return frame\n",
                "        h, w = frame.shape[:2]\n",
                "        grid_px = int(FRAME_GRID_SIZE_MM * self.ppm)\n",
                "        for x in range(0, w, grid_px):\n",
                "            cv2.line(frame, (x,0), (x,h), (50,50,50), 1)\n",
                "        for y in range(0, h, grid_px):\n",
                "            cv2.line(frame, (0,y), (w,y), (50,50,50), 1)\n",
                "        return frame\n",
                "    \n",
                "    def draw_object_grid(self, frame, obj):\n",
                "        if not SHOW_OBJECT_GRID: return\n",
                "        x, y, w, h = obj['bbox']\n",
                "        grid_px = max(3, int(OBJECT_GRID_SIZE_MM * self.ppm))\n",
                "        for gx in range(x, x+w, grid_px):\n",
                "            cv2.line(frame, (gx, y), (gx, y+h), (100,100,255), 1)\n",
                "        for gy in range(y, y+h, grid_px):\n",
                "            cv2.line(frame, (x, gy), (x+w, gy), (100,100,255), 1)\n",
                "        w_mm, h_mm = w / self.ppm, h / self.ppm\n",
                "        cv2.putText(frame, f\"{w_mm:.0f}x{h_mm:.0f}mm\", (x, y-3), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (100,100,255), 1)\n",
                "\n",
                "print(\"‚úì Detector class\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì PCA Grasp Selector (v9)\n"
                    ]
                }
            ],
            "source": [
                "class PCAGraspSelector:\n",
                "    \"\"\"v9: PCA + Robot R offset\"\"\"\n",
                "    \n",
                "    def __init__(self, pixels_per_mm):\n",
                "        self.ppm = pixels_per_mm\n",
                "    \n",
                "    def analyze_object(self, obj):\n",
                "        \"\"\"‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡πâ‡∏ß‡∏¢ PCA\"\"\"\n",
                "        cnt = obj.get('contour')\n",
                "        if cnt is None or len(cnt) < 5:\n",
                "            return self.fallback_analysis(obj)\n",
                "        \n",
                "        # PCA Analysis\n",
                "        pts = cnt.reshape(-1, 2).astype(np.float64)\n",
                "        mean = np.mean(pts, axis=0)\n",
                "        pts_centered = pts - mean\n",
                "        \n",
                "        # Covariance ‡πÅ‡∏•‡∏∞ eigenvectors\n",
                "        cov = np.cov(pts_centered.T)\n",
                "        eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
                "        \n",
                "        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° eigenvalue\n",
                "        idx = np.argsort(eigenvalues)[::-1]\n",
                "        eigenvalues = eigenvalues[idx]\n",
                "        eigenvectors = eigenvectors[:, idx]\n",
                "        \n",
                "        major_axis = eigenvectors[:, 0]  # ‡πÅ‡∏Å‡∏ô‡∏¢‡∏≤‡∏ß\n",
                "        minor_axis = eigenvectors[:, 1]  # ‡πÅ‡∏Å‡∏ô‡πÅ‡∏Ñ‡∏ö\n",
                "        \n",
                "        # ‡∏°‡∏∏‡∏°‡∏Ç‡∏≠‡∏á‡πÅ‡∏Å‡∏ô‡∏´‡∏•‡∏±‡∏Å (camera angle)\n",
                "        angle_major = np.degrees(np.arctan2(major_axis[1], major_axis[0]))\n",
                "        \n",
                "        # ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡πÅ‡∏Å‡∏ô‡∏£‡∏≠‡∏á\n",
                "        projections = np.dot(pts_centered, minor_axis)\n",
                "        width_px = np.max(projections) - np.min(projections)\n",
                "        width_mm = width_px / self.ppm\n",
                "        \n",
                "        # ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ï‡∏≤‡∏°‡πÅ‡∏Å‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
                "        proj_major = np.dot(pts_centered, major_axis)\n",
                "        length_px = np.max(proj_major) - np.min(proj_major)\n",
                "        length_mm = length_px / self.ppm\n",
                "        \n",
                "        cx, cy = int(mean[0]), int(mean[1])\n",
                "        \n",
                "        # Camera angle ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö grasp (‡∏à‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡πÅ‡∏ô‡∏ß‡πÅ‡∏Ñ‡∏ö = ‡∏ï‡∏±‡πâ‡∏á‡∏â‡∏≤‡∏Å‡∏Å‡∏±‡∏ö‡πÅ‡∏Å‡∏ô‡∏¢‡∏≤‡∏ß)\n",
                "        grasp_camera_angle = self.normalize_angle(angle_major + 90)\n",
                "        \n",
                "        grasps = []\n",
                "        \n",
                "        # Grasp ‡∏´‡∏•‡∏±‡∏Å: ‡∏à‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡πÅ‡∏ô‡∏ß‡πÅ‡∏Ñ‡∏ö\n",
                "        if width_mm <= GRIPPER_MAX_WIDTH_MM:\n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': width_mm,\n",
                "                'camera_angle': grasp_camera_angle,  # v9: ‡πÄ‡∏Å‡πá‡∏ö camera angle\n",
                "                'score': 1.0,\n",
                "                'type': 'PCA_narrow',\n",
                "                'axis_info': {'major': major_axis, 'minor': minor_axis}\n",
                "            })\n",
                "        \n",
                "        # Grasp ‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å: ‡∏à‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡πÅ‡∏ô‡∏ß‡∏¢‡∏≤‡∏ß\n",
                "        if length_mm <= GRIPPER_MAX_WIDTH_MM:\n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': length_mm,\n",
                "                'camera_angle': self.normalize_angle(angle_major),\n",
                "                'score': 0.5,\n",
                "                'type': 'PCA_long',\n",
                "                'axis_info': None\n",
                "            })\n",
                "        \n",
                "        if not grasps:\n",
                "            return self.fallback_analysis(obj)\n",
                "        \n",
                "        return grasps\n",
                "    \n",
                "    def fallback_analysis(self, obj):\n",
                "        \"\"\"Fallback ‡∏ñ‡πâ‡∏≤ PCA ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ú‡∏•\"\"\"\n",
                "        rect = obj.get('rect')\n",
                "        if rect is None:\n",
                "            return []\n",
                "        \n",
                "        (cx, cy), (w, h), angle = rect\n",
                "        cx, cy = int(cx), int(cy)\n",
                "        \n",
                "        if w < h:\n",
                "            grip_w = w / self.ppm\n",
                "            grip_a = angle + 90\n",
                "        else:\n",
                "            grip_w = h / self.ppm\n",
                "            grip_a = angle\n",
                "        \n",
                "        grasps = []\n",
                "        if grip_w <= GRIPPER_MAX_WIDTH_MM:\n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': grip_w,\n",
                "                'camera_angle': self.normalize_angle(grip_a),\n",
                "                'score': 0.8,\n",
                "                'type': 'rect_fallback',\n",
                "                'axis_info': None\n",
                "            })\n",
                "        \n",
                "        return grasps\n",
                "    \n",
                "    def normalize_angle(self, angle):\n",
                "        while angle > 90: angle -= 180\n",
                "        while angle < -90: angle += 180\n",
                "        return angle\n",
                "\n",
                "print(\"‚úì PCA Grasp Selector (v9)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Depth estimator\n"
                    ]
                }
            ],
            "source": [
                "class RobustDepthEstimator:\n",
                "    def __init__(self, model, device='cpu', camera_height_mm=630, history_size=5):\n",
                "        self.model = model\n",
                "        self.device = device\n",
                "        self.camera_height = camera_height_mm\n",
                "        self.floor_depth = None\n",
                "        self.history = deque(maxlen=history_size)\n",
                "    \n",
                "    def estimate_depth(self, frame):\n",
                "        return self.model.infer_image(frame)\n",
                "    \n",
                "    def calibrate_floor(self, frame):\n",
                "        depth = self.estimate_depth(frame)\n",
                "        h, w = depth.shape\n",
                "        self.floor_depth = np.median(depth[h//3:2*h//3, w//3:2*w//3])\n",
                "        print(f\"‚úÖ Floor depth: {self.floor_depth:.4f}\")\n",
                "        return self.floor_depth\n",
                "    \n",
                "    def get_object_height(self, depth_map, obj, scale):\n",
                "        if self.floor_depth is None: return 0\n",
                "        x, y, w, h = obj['bbox']\n",
                "        region = depth_map[y:y+h, x:x+w]\n",
                "        if region.size == 0: return 0\n",
                "        \n",
                "        samples = [np.median(region)]\n",
                "        qh, qw = h//4, w//4\n",
                "        if qh > 0 and qw > 0:\n",
                "            samples.extend([np.median(region[:qh,:qw]), np.median(region[:qh,-qw:]),\n",
                "                           np.median(region[-qh:,:qw]), np.median(region[-qh:,-qw:])])\n",
                "        \n",
                "        height = max(0, (np.median(samples) - self.floor_depth) * scale)\n",
                "        self.history.append(height)\n",
                "        return np.median(self.history)\n",
                "    \n",
                "    def calculate_z(self, height_mm):\n",
                "        return max(Z_FLOOR, min(Z_SAFE, Z_FLOOR + height_mm * 0.5))\n",
                "\n",
                "print(\"‚úì Depth estimator\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Initialize & Connect"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Components initialized (v9 with R offset)\n"
                    ]
                }
            ],
            "source": [
                "gripper = SmartGripperController(port=ESP32_PORT, baudrate=ESP32_BAUDRATE)\n",
                "robot = DobotControllerTCP(homography_matrix=HOMOGRAPHY_MATRIX, r_offset=ROBOT_R_OFFSET)  # v9: R offset\n",
                "detector = PreciseSizeDetector(yolo_model, PIXELS_PER_MM)\n",
                "grasp_selector = PCAGraspSelector(PIXELS_PER_MM)\n",
                "depth_estimator = RobustDepthEstimator(depth_model, device=DEVICE, camera_height_mm=CAMERA_HEIGHT_MM)\n",
                "print(\"‚úì Components initialized (v9 with R offset)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Gripper on COM9\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 48,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "gripper.connect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Robot connected!\n",
                        "   R offset: -25.55¬∞\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 42,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "robot.connect(ROBOT_IP)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì∑ Capture Background"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üì∑ BACKGROUND | SPACE=Capture Q=Skip\n",
                        "‚úÖ Floor depth: 2.3835\n"
                    ]
                }
            ],
            "source": [
                "print(\"üì∑ BACKGROUND | SPACE=Capture Q=Skip\")\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    cv2.putText(frame, \"SPACE=Capture | Q=Skip\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
                "    cv2.imshow('BG', frame)\n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord(' '):\n",
                "        depth_estimator.calibrate_floor(frame)\n",
                "        break\n",
                "    elif key == ord('q'):\n",
                "        print(\"Skipped\")\n",
                "        break\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üéØ MAIN PICK-AND-PLACE v9\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚ùå could not open port 'COM9': PermissionError(13, 'Access is denied.', None, 5)\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "False"
                        ]
                    },
                    "execution_count": 53,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "gripper.connect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Robot connected!\n",
                        "   R offset: -25.55¬∞\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 56,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "robot.connect(ROBOT_IP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "üéØ PICK v9 (PCA + R Offset)\n",
                        "   R offset: -25.55¬∞ (neutral)\n",
                        "Click=Select | SPACE=Execute | F=Grid | O=ObjGrid | Q=Quit\n",
                        "============================================================\n",
                        "\n",
                        "üì¶ Object: 2 grasps\n",
                        "   Best: W=32.8mm CamA=-1.2¬∞ ‚Üí R=-24.3¬∞\n",
                        "\n",
                        "üì¶ Object: 2 grasps\n",
                        "   Best: W=33.0mm CamA=3.0¬∞ ‚Üí R=-28.5¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=23.1mm CamA=-4.1¬∞ ‚Üí R=-21.4¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=21.8mm CamA=-3.7¬∞ ‚Üí R=-21.8¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=21.8mm CamA=-3.8¬∞ ‚Üí R=-21.8¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=23.4mm CamA=-4.1¬∞ ‚Üí R=-21.4¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=21.7mm CamA=-3.9¬∞ ‚Üí R=-21.7¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=29.8mm CamA=-7.3¬∞ ‚Üí R=-18.2¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=29.7mm CamA=-7.2¬∞ ‚Üí R=-18.4¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=29.7mm CamA=-7.2¬∞ ‚Üí R=-18.4¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=29.6mm CamA=-7.2¬∞ ‚Üí R=-18.3¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=29.7mm CamA=-7.3¬∞ ‚Üí R=-18.3¬∞\n",
                        "\n",
                        "üéØ Grasp: W=29.7mm CamA=-7.3¬∞ ‚Üí R=-18.3¬∞ (PCA_narrow)\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=46.6mm CamA=11.7¬∞ ‚Üí R=-37.3¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=46.7mm CamA=11.8¬∞ ‚Üí R=-37.3¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=46.7mm CamA=11.8¬∞ ‚Üí R=-37.4¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=46.7mm CamA=11.8¬∞ ‚Üí R=-37.4¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=46.8mm CamA=11.8¬∞ ‚Üí R=-37.4¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=46.8mm CamA=11.9¬∞ ‚Üí R=-37.4¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=43.0mm CamA=5.0¬∞ ‚Üí R=-30.5¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=43.0mm CamA=5.0¬∞ ‚Üí R=-30.5¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=43.0mm CamA=5.0¬∞ ‚Üí R=-30.5¬∞\n",
                        "\n",
                        "ü§ñ Pick: W=43.0mm CamAngle=5.0¬∞ ‚Üí R=-30.5¬∞ Z=-64.0\n",
                        "   Type: PCA_narrow\n",
                        "üîÑ Safe position...\n",
                        "   ‚Üí JointMovJ(0,0,0,0)\n",
                        "ü¶æ Open: 54.0mm (22¬∞)\n",
                        "   ‚Üí MovJ(37.016448974609375,40.93083190917969,-55,-30.50606959425831)\n",
                        "   ‚Üí MovJ(37.016448974609375,40.93083190917969,-64,-30.50606959425831)\n",
                        "ü¶æ Grip: 34.5mm - 5mm = 29.5mm (63¬∞)\n",
                        "   ‚Üí MovJ(37.016448974609375,40.93083190917969,-40,-30.50606959425831)\n",
                        "   ‚Üí MovJ(-253.07,115.17,-17.07,-62.78)\n",
                        "ü§ñ HOME...\n",
                        "‚úÖ Complete!\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=42.7mm CamA=5.4¬∞ ‚Üí R=-31.0¬∞\n"
                    ]
                }
            ],
            "source": [
                "selected_object = None\n",
                "selected_grasp = None\n",
                "detected_objects = []\n",
                "current_grasps = []\n",
                "current_depth = None\n",
                "\n",
                "def mouse_callback(event, x, y, flags, param):\n",
                "    global selected_object, selected_grasp, current_grasps\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        for g in current_grasps:\n",
                "            gx, gy = g['center']\n",
                "            if abs(x-gx) < 20 and abs(y-gy) < 20:\n",
                "                selected_grasp = g\n",
                "                robot_r = robot.camera_angle_to_robot_r(g['camera_angle'])\n",
                "                print(f\"\\nüéØ Grasp: W={g['width_mm']:.1f}mm CamA={g['camera_angle']:.1f}¬∞ ‚Üí R={robot_r:.1f}¬∞ ({g['type']})\")\n",
                "                return\n",
                "        for obj in detected_objects:\n",
                "            bx,by,bw,bh = obj['bbox']\n",
                "            if bx <= x <= bx+bw and by <= y <= by+bh:\n",
                "                selected_object = obj\n",
                "                current_grasps = grasp_selector.analyze_object(obj)\n",
                "                selected_grasp = current_grasps[0] if current_grasps else None\n",
                "                if selected_grasp:\n",
                "                    robot_r = robot.camera_angle_to_robot_r(selected_grasp['camera_angle'])\n",
                "                    print(f\"\\nüì¶ Object: {len(current_grasps)} grasps\")\n",
                "                    print(f\"   Best: W={selected_grasp['width_mm']:.1f}mm CamA={selected_grasp['camera_angle']:.1f}¬∞ ‚Üí R={robot_r:.1f}¬∞\")\n",
                "                break\n",
                "\n",
                "def draw_grasps(frame, obj, grasps, selected):\n",
                "    for g in grasps:\n",
                "        cx, cy = g['center']\n",
                "        angle = g['camera_angle']\n",
                "        is_sel = (selected and g == selected)\n",
                "        color = (0,0,255) if is_sel else ((0,255,0) if g['score']>=1.0 else (0,255,255))\n",
                "        thick = 3 if is_sel else 2\n",
                "        \n",
                "        # Draw grasp line\n",
                "        length = 40\n",
                "        dx = int(length * np.cos(np.radians(angle)))\n",
                "        dy = int(length * np.sin(np.radians(angle)))\n",
                "        cv2.line(frame, (cx-dx, cy-dy), (cx+dx, cy+dy), color, thick)\n",
                "        cv2.circle(frame, (cx, cy), 5, color, -1)\n",
                "        \n",
                "        # Draw gripper jaws\n",
                "        grip_half = int(g['width_mm'] * PIXELS_PER_MM / 2)\n",
                "        perp_angle = angle + 90\n",
                "        px = int(grip_half * np.cos(np.radians(perp_angle)))\n",
                "        py = int(grip_half * np.sin(np.radians(perp_angle)))\n",
                "        \n",
                "        cv2.line(frame, (cx+px-dx//2, cy+py-dy//2), (cx+px+dx//2, cy+py+dy//2), color, 2)\n",
                "        cv2.line(frame, (cx-px-dx//2, cy-py-dy//2), (cx-px+dx//2, cy-py+dy//2), color, 2)\n",
                "        \n",
                "        if is_sel:\n",
                "            robot_r = robot.camera_angle_to_robot_r(angle)\n",
                "            cv2.putText(frame, f\"{g['width_mm']:.1f}mm R={robot_r:.0f}\", (cx+10, cy-10),\n",
                "                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
                "\n",
                "def pick_with_grasp(obj, grasp):\n",
                "    cx, cy = grasp['center']\n",
                "    grip_w = grasp['width_mm']\n",
                "    camera_angle = grasp['camera_angle']\n",
                "    \n",
                "    # v9: ‡πÅ‡∏õ‡∏•‡∏á camera angle ‡πÄ‡∏õ‡πá‡∏ô robot R\n",
                "    robot_r = robot.camera_angle_to_robot_r(camera_angle)\n",
                "    \n",
                "    robot_x, robot_y = robot.pixel_to_robot(cx, cy)\n",
                "    height = depth_estimator.get_object_height(current_depth, obj, DEPTH_Z_SCALE) if current_depth is not None else 0\n",
                "    z_grasp = depth_estimator.calculate_z(height)\n",
                "    \n",
                "    print(f\"\\nü§ñ Pick: W={grip_w:.1f}mm CamAngle={camera_angle:.1f}¬∞ ‚Üí R={robot_r:.1f}¬∞ Z={z_grasp:.1f}\")\n",
                "    print(f\"   Type: {grasp['type']}\")\n",
                "    \n",
                "    print(\"üîÑ Safe position...\")\n",
                "    robot.joint_move_and_wait(0, 0, 0, 0, 3)\n",
                "    #time.sleep(4)\n",
                "    \n",
                "    # v9: ‡πÄ‡∏õ‡∏¥‡∏î gripper ‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà\n",
                "    gripper.open_for_object(GRIPPER_MAX_WIDTH_MM)\n",
                "    time.sleep(2.5)\n",
                "    \n",
                "    robot.move_to_and_wait(robot_x, robot_y, Z_APPROACH, robot_r, 3)\n",
                "    #time.sleep(4)\n",
                "    robot.move_to_and_wait(robot_x, robot_y, z_grasp, robot_r, 2)\n",
                "    #time.sleep(4)\n",
                "    \n",
                "    # v9: grip_w - 5mm ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÅ‡∏ô‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô\n",
                "    gripper.grip_object(grip_w - 8.5)\n",
                "    #gripper.grip_object(10)\n",
                "    time.sleep(2.5)\n",
                "    \n",
                "    robot.move_to_and_wait(robot_x, robot_y, Z_SAFE, robot_r, 2)\n",
                "    #time.sleep(4)\n",
                "    robot.move_to_and_wait(*DROP_POS[:3], DROP_POS[3], 3)\n",
                "    #time.sleep(4)\n",
                "    \n",
                "    gripper.release()\n",
                "    time.sleep(2.5)\n",
                "    robot.home()\n",
                "    print(\"‚úÖ Complete!\")\n",
                "\n",
                "# Main loop\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Pick v9')\n",
                "cv2.setMouseCallback('Pick v9', mouse_callback)\n",
                "\n",
                "frame_count = 0\n",
                "print(\"=\"*60)\n",
                "print(\"üéØ PICK v9 (PCA + R Offset)\")\n",
                "print(f\"   R offset: {ROBOT_R_OFFSET}¬∞ (neutral)\")\n",
                "print(\"Click=Select | SPACE=Execute | F=Grid | O=ObjGrid | Q=Quit\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    \n",
                "    frame = detector.draw_frame_grid(frame)\n",
                "    \n",
                "    frame_count += 1\n",
                "    if frame_count % 10 == 0:\n",
                "        current_depth = depth_estimator.estimate_depth(frame)\n",
                "    \n",
                "    detected_objects = detector.detect(frame)\n",
                "    \n",
                "    for obj in detected_objects:\n",
                "        x,y,w,h = obj['bbox']\n",
                "        is_sel = (selected_object and obj['center'] == selected_object['center'])\n",
                "        color = (0,0,255) if is_sel else (0,255,0)\n",
                "        \n",
                "        cv2.rectangle(frame, (x,y), (x+w,y+h), color, 2)\n",
                "        if 'rect' in obj:\n",
                "            box = cv2.boxPoints(obj['rect'])\n",
                "            cv2.drawContours(frame, [np.int32(box)], 0, color, 1)\n",
                "        \n",
                "        detector.draw_object_grid(frame, obj)\n",
                "    \n",
                "    if selected_object and current_grasps:\n",
                "        draw_grasps(frame, selected_object, current_grasps, selected_grasp)\n",
                "    \n",
                "    # Status bar\n",
                "    cv2.rectangle(frame, (0,0), (640,35), (30,30,30), -1)\n",
                "    cv2.putText(frame, f\"v9 PCA+R | Obj:{len(detected_objects)} | Click | SPACE | F/O=Grid | Q\",\n",
                "               (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1)\n",
                "    \n",
                "    if selected_grasp:\n",
                "        robot_r = robot.camera_angle_to_robot_r(selected_grasp['camera_angle'])\n",
                "        cv2.putText(frame, f\"[{selected_grasp['type']}: W={selected_grasp['width_mm']:.1f}mm R={robot_r:.0f} - SPACE]\",\n",
                "                   (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
                "    \n",
                "    cv2.imshow('Pick v9', frame)\n",
                "    \n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == ord('r'):\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "    elif key == ord('f'):\n",
                "        SHOW_FRAME_GRID = not SHOW_FRAME_GRID\n",
                "        print(f\"Frame grid: {SHOW_FRAME_GRID}\")\n",
                "    elif key == ord('o'):\n",
                "        SHOW_OBJECT_GRID = not SHOW_OBJECT_GRID\n",
                "        print(f\"Object grid: {SHOW_OBJECT_GRID}\")\n",
                "    elif key == ord('h'):\n",
                "        robot.home()\n",
                "    elif key == ord(' ') and selected_object and selected_grasp:\n",
                "        pick_with_grasp(selected_object, selected_grasp)\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ü§ñ HOME...\n"
                    ]
                }
            ],
            "source": [
                "robot.home()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gripper.disconnect()\n",
                "print(\"‚úÖ Done\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
