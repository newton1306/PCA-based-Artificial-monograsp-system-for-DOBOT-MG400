{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ LIDAR Grasp Detection v11\n",
                "\n",
                "## ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô v11\n",
                "| Feature | Description |\n",
                "|---------|-------------|\n",
                "| **üìè TF-Luna LIDAR** | ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡πÅ‡∏™‡∏á |\n",
                "| **üöÄ Direct Z Calculation** | ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Z ‡∏à‡∏≤‡∏Å LIDAR ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á |\n",
                "| **üéØ PCA Grasp** | ‡πÉ‡∏ä‡πâ PCA ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå grasp ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô v10 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîå Wiring TF-Luna + ESP32\n",
                "\n",
                "```\n",
                "TF-Luna          ESP32\n",
                "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
                "VCC (5V)    ‚Üí    5V\n",
                "GND         ‚Üí    GND  \n",
                "TX          ‚Üí    GPIO16 (RX2)\n",
                "RX          ‚Üê    GPIO17 (TX2)\n",
                "```\n",
                "\n",
                "‚ö†Ô∏è **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** TF-Luna ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü 5V (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 3.3V)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Imports\n"
                    ]
                }
            ],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import time\n",
                "import socket\n",
                "import serial\n",
                "from ultralytics import YOLO\n",
                "\n",
                "print(\"‚úì Imports\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Hardware Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Hardware config\n"
                    ]
                }
            ],
            "source": [
                "ROBOT_IP = '192.168.1.6'\n",
                "ESP32_PORT = 'COM9'\n",
                "ESP32_BAUDRATE = 115200\n",
                "CAMERA_ID = 2\n",
                "\n",
                "HOMOGRAPHY_MATRIX = np.load('homography_matrix.npy')\n",
                "\n",
                "print(\"‚úì Hardware config\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Configuration (v11 with LIDAR)\n"
                    ]
                }
            ],
            "source": [
                "# === CALIBRATED VALUES ===\n",
                "PIXELS_PER_MM = 2.7703\n",
                "\n",
                "# === Robot R Rotation ===\n",
                "ROBOT_R_OFFSET = -25.55\n",
                "\n",
                "# === Z Heights ===\n",
                "Z_FLOOR = -64\n",
                "Z_MEASURE = 120   # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏î LIDAR (‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏π‡∏á‡∏û‡∏≠‡πÉ‡∏´‡πâ LIDAR ‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô >200mm)\n",
                "\n",
                "# === LIDAR Configuration ===\n",
                "LIDAR_TO_GRIPPER_OFFSET = 60  # mm (‡∏à‡∏≤‡∏Å LIDAR ‡∏ñ‡∏∂‡∏á‡∏õ‡∏•‡∏≤‡∏¢ gripper ‡∏ï‡∏≠‡∏ô Z=-64)\n",
                "LIDAR_TIMEOUT = 1.0           # seconds\n",
                "\n",
                "# === Drop Position ===\n",
                "DROP_POS = (-253.07, 115.17, -17.07, -62.78)\n",
                "\n",
                "# === Gripper ===\n",
                "GRIPPER_SERVO_OPEN_ANGLE = 22\n",
                "GRIPPER_SERVO_CLOSE_ANGLE = 96\n",
                "GRIPPER_MAX_WIDTH_MM = 54\n",
                "GRIPPER_MIN_WIDTH_MM = 0\n",
                "GRIPPER_OPEN_MARGIN_MM = 5\n",
                "GRIPPER_GRIP_MARGIN_MM = 5\n",
                "\n",
                "# === Detection ===\n",
                "MIN_OBJECT_AREA = 1000\n",
                "YOLO_CONFIDENCE = 0.25\n",
                "\n",
                "print(\"‚úì Configuration (v11 with LIDAR)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Load Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading YOLOv8...\n",
                        "‚úÖ YOLO loaded\n"
                    ]
                }
            ],
            "source": [
                "print(\"Loading YOLOv8...\")\n",
                "yolo_model = YOLO('yolov8n.pt')\n",
                "print(\"‚úÖ YOLO loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Classes Definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Gripper+LIDAR class\n"
                    ]
                }
            ],
            "source": [
                "class SmartGripperController:\n",
                "    \"\"\"Gripper + LIDAR Controller (v11)\"\"\"\n",
                "    CALIB_ANGLES = np.array([22, 30, 40, 50, 60, 70, 80, 90, 96])\n",
                "    CALIB_WIDTHS = np.array([54.0, 52.0, 48.0, 40.0, 32.0, 23.0, 12.0, 3.0, 0.0])\n",
                "    \n",
                "    def __init__(self, port='COM9', baudrate=115200):\n",
                "        self.port = port\n",
                "        self.baudrate = baudrate\n",
                "        self.serial = None\n",
                "        self.target_width = None\n",
                "        \n",
                "    def connect(self):\n",
                "        try:\n",
                "            self.serial = serial.Serial(self.port, self.baudrate, timeout=2)\n",
                "            time.sleep(2)\n",
                "            self.serial.reset_input_buffer()\n",
                "            print(f\"‚úÖ Gripper+LIDAR on {self.port}\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå {e}\")\n",
                "            return False\n",
                "    \n",
                "    def disconnect(self):\n",
                "        if self.serial: \n",
                "            self.serial.close()\n",
                "    \n",
                "    def send_command(self, cmd):\n",
                "        if self.serial:\n",
                "            self.serial.reset_input_buffer()\n",
                "            self.serial.write((cmd + '\\n').encode())\n",
                "            time.sleep(0.3)\n",
                "    \n",
                "    def mm_to_angle(self, width_mm):\n",
                "        width = max(0.0, min(54.0, width_mm))\n",
                "        return int(round(np.interp(width, self.CALIB_WIDTHS[::-1], self.CALIB_ANGLES[::-1])))\n",
                "    \n",
                "    def open_for_object(self, width_mm):\n",
                "        self.target_width = width_mm\n",
                "        open_w = min(54.0, width_mm + GRIPPER_OPEN_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(open_w)\n",
                "        print(f\"ü¶æ Open: {open_w:.1f}mm ({angle}¬∞)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def grip_object(self, width_mm):\n",
                "        grip_w = max(0.0, width_mm - GRIPPER_GRIP_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(grip_w)\n",
                "        print(f\"ü¶æ Grip: {width_mm:.1f}mm - {GRIPPER_GRIP_MARGIN_MM}mm = {grip_w:.1f}mm ({angle}¬∞)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def release(self):\n",
                "        open_w = min(54.0, (self.target_width or 30) + 10)\n",
                "        self.send_command(f'G{self.mm_to_angle(open_w)}')\n",
                "        self.target_width = None\n",
                "    \n",
                "    # ==================== LIDAR Functions ====================\n",
                "    def read_lidar(self, samples=3):\n",
                "        \"\"\"Read LIDAR distance in mm (average of samples)\"\"\"\n",
                "        if not self.serial:\n",
                "            return None\n",
                "        \n",
                "        readings = []\n",
                "        for _ in range(samples):\n",
                "            self.serial.reset_input_buffer()\n",
                "            self.serial.write(b'L\\n')\n",
                "            \n",
                "            start = time.time()\n",
                "            while time.time() - start < LIDAR_TIMEOUT:\n",
                "                if self.serial.in_waiting > 0:\n",
                "                    response = self.serial.readline().decode().strip()\n",
                "                    if response.startswith(\"LIDAR:\") and \"ERR\" not in response:\n",
                "                        try:\n",
                "                            dist = int(response.split(\":\")[1])\n",
                "                            readings.append(dist)\n",
                "                        except:\n",
                "                            pass\n",
                "                        break\n",
                "            time.sleep(0.05)\n",
                "        \n",
                "        if readings:\n",
                "            return int(np.median(readings))\n",
                "        return None\n",
                "\n",
                "print(\"‚úì Gripper+LIDAR class\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Robot class\n"
                    ]
                }
            ],
            "source": [
                "class DobotControllerTCP:\n",
                "    def __init__(self, homography_matrix=None, r_offset=-25.55):\n",
                "        self.dashboard_port = 29999\n",
                "        self.sock = None\n",
                "        self.H = homography_matrix\n",
                "        self.r_offset = r_offset\n",
                "        \n",
                "    def connect(self, ip):\n",
                "        try:\n",
                "            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
                "            self.sock.settimeout(5)\n",
                "            self.sock.connect((ip, self.dashboard_port))\n",
                "            self.send_command(\"ClearError()\")\n",
                "            time.sleep(0.5)\n",
                "            self.send_command(\"EnableRobot()\")\n",
                "            time.sleep(4)\n",
                "            self.send_command(\"User(1)\")\n",
                "            self.send_command(\"Tool(1)\")\n",
                "            self.send_command(\"SpeedFactor(50)\")\n",
                "            print(\"‚úÖ Robot connected!\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"Error: {e}\")\n",
                "            return False\n",
                "\n",
                "    def send_command(self, cmd):\n",
                "        if self.sock:\n",
                "            self.sock.send((cmd + \"\\n\").encode(\"utf-8\"))\n",
                "            return self.sock.recv(1024).decode(\"utf-8\")\n",
                "\n",
                "    def home(self):\n",
                "        print(\"ü§ñ HOME...\")\n",
                "        self.send_command(\"MovJ(-253.07, 115.17, -17.07, -62.78)\")\n",
                "        time.sleep(4)\n",
                "\n",
                "    def move_to(self, x, y, z, r=0):\n",
                "        cmd = f\"MovJ({x},{y},{z},{r})\"\n",
                "        print(f\"   ‚Üí {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def move_to_and_wait(self, x, y, z, r=0, wait=3):\n",
                "        self.move_to(x, y, z, r)\n",
                "        time.sleep(wait)\n",
                "    \n",
                "    def joint_move(self, j1=0, j2=0, j3=0, j4=0):\n",
                "        cmd = f\"JointMovJ({j1},{j2},{j3},{j4})\"\n",
                "        print(f\"   ‚Üí {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def joint_move_and_wait(self, j1=0, j2=0, j3=0, j4=0, wait=3):\n",
                "        self.joint_move(j1, j2, j3, j4)\n",
                "        time.sleep(wait)\n",
                "\n",
                "    def pixel_to_robot(self, u, v):\n",
                "        if self.H is None: return None, None\n",
                "        pt = np.array([u, v, 1], dtype=np.float32)\n",
                "        res = np.dot(self.H, pt)\n",
                "        return res[0]/res[2], res[1]/res[2]\n",
                "    \n",
                "    def camera_angle_to_robot_r(self, camera_angle):\n",
                "        return self.r_offset - camera_angle\n",
                "\n",
                "print(\"‚úì Robot class\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Object Detector class\n"
                    ]
                }
            ],
            "source": [
                "class ObjectDetector:\n",
                "    \"\"\"v11: YOLO + Contour Detection (No Depth Model)\"\"\"\n",
                "    \n",
                "    def __init__(self, yolo_model, pixels_per_mm):\n",
                "        self.yolo = yolo_model\n",
                "        self.ppm = pixels_per_mm\n",
                "    \n",
                "    def detect(self, frame):\n",
                "        objects = []\n",
                "        results = self.yolo(frame, conf=YOLO_CONFIDENCE, verbose=False)\n",
                "        \n",
                "        for r in results:\n",
                "            for box in r.boxes:\n",
                "                x1,y1,x2,y2 = map(int, box.xyxy[0])\n",
                "                conf = float(box.conf[0])\n",
                "                \n",
                "                roi = frame[y1:y2, x1:x2]\n",
                "                if roi.size == 0: continue\n",
                "                \n",
                "                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
                "                _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
                "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "                \n",
                "                if contours:\n",
                "                    cnt = max(contours, key=cv2.contourArea)\n",
                "                    cnt = cnt + np.array([x1, y1])\n",
                "                    rect = cv2.minAreaRect(cnt)\n",
                "                    cx, cy = int(rect[0][0]), int(rect[0][1])\n",
                "                    \n",
                "                    objects.append({\n",
                "                        'bbox': (x1, y1, x2-x1, y2-y1),\n",
                "                        'center': (cx, cy),\n",
                "                        'rect': rect,\n",
                "                        'rect_size': rect[1],\n",
                "                        'rect_angle': rect[2],\n",
                "                        'contour': cnt,\n",
                "                        'conf': conf,\n",
                "                        'area': cv2.contourArea(cnt)\n",
                "                    })\n",
                "        \n",
                "        if not objects:\n",
                "            objects = self._edge_detect(frame)\n",
                "        \n",
                "        return objects\n",
                "    \n",
                "    def _edge_detect(self, frame):\n",
                "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
                "        edges = cv2.Canny(cv2.GaussianBlur(gray, (5,5), 0), 50, 150)\n",
                "        edges = cv2.dilate(edges, np.ones((3,3), np.uint8), iterations=2)\n",
                "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "        \n",
                "        objects = []\n",
                "        for cnt in contours:\n",
                "            area = cv2.contourArea(cnt)\n",
                "            if area > MIN_OBJECT_AREA:\n",
                "                hull = cv2.convexHull(cnt)\n",
                "                rect = cv2.minAreaRect(hull)\n",
                "                x,y,w,h = cv2.boundingRect(hull)\n",
                "                objects.append({\n",
                "                    'bbox': (x,y,w,h),\n",
                "                    'center': (x+w//2, y+h//2),\n",
                "                    'rect': rect,\n",
                "                    'rect_size': rect[1],\n",
                "                    'rect_angle': rect[2],\n",
                "                    'contour': hull,\n",
                "                    'area': area\n",
                "                })\n",
                "        return sorted(objects, key=lambda o: o['area'], reverse=True)\n",
                "\n",
                "print(\"‚úì Object Detector class\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì PCA Grasp Selector\n"
                    ]
                }
            ],
            "source": [
                "class PCAGraspSelector:\n",
                "    \"\"\"v11: PCA-based Grasp Selection\"\"\"\n",
                "    \n",
                "    def __init__(self, pixels_per_mm):\n",
                "        self.ppm = pixels_per_mm\n",
                "    \n",
                "    def analyze_object(self, obj):\n",
                "        \"\"\"Analyze object with PCA\"\"\"\n",
                "        cnt = obj.get('contour')\n",
                "        if cnt is None or len(cnt) < 5:\n",
                "            return self._fallback_analysis(obj)\n",
                "        \n",
                "        # PCA Analysis\n",
                "        pts = cnt.reshape(-1, 2).astype(np.float64)\n",
                "        mean = np.mean(pts, axis=0)\n",
                "        pts_centered = pts - mean\n",
                "        \n",
                "        cov = np.cov(pts_centered.T)\n",
                "        eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
                "        \n",
                "        idx = np.argsort(eigenvalues)[::-1]\n",
                "        eigenvectors = eigenvectors[:, idx]\n",
                "        \n",
                "        major_axis = eigenvectors[:, 0]\n",
                "        minor_axis = eigenvectors[:, 1]\n",
                "        \n",
                "        angle_major = np.degrees(np.arctan2(major_axis[1], major_axis[0]))\n",
                "        \n",
                "        projections = np.dot(pts_centered, minor_axis)\n",
                "        width_px = np.max(projections) - np.min(projections)\n",
                "        width_mm = width_px / self.ppm\n",
                "        \n",
                "        proj_major = np.dot(pts_centered, major_axis)\n",
                "        length_px = np.max(proj_major) - np.min(proj_major)\n",
                "        length_mm = length_px / self.ppm\n",
                "        \n",
                "        cx, cy = int(mean[0]), int(mean[1])\n",
                "        grasp_camera_angle = self._normalize_angle(angle_major + 90)\n",
                "        \n",
                "        grasps = []\n",
                "        \n",
                "        # Primary: Narrow side grasp\n",
                "        if width_mm <= GRIPPER_MAX_WIDTH_MM:\n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': width_mm,\n",
                "                'camera_angle': grasp_camera_angle,\n",
                "                'score': 1.0,\n",
                "                'type': 'PCA_narrow',\n",
                "                'axis_info': {'major': major_axis, 'minor': minor_axis}\n",
                "            })\n",
                "        \n",
                "        # Alternative: Long side grasp\n",
                "        if length_mm <= GRIPPER_MAX_WIDTH_MM:\n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': length_mm,\n",
                "                'camera_angle': self._normalize_angle(angle_major),\n",
                "                'score': 0.5,\n",
                "                'type': 'PCA_long',\n",
                "                'axis_info': None\n",
                "            })\n",
                "        \n",
                "        if not grasps:\n",
                "            return self._fallback_analysis(obj)\n",
                "        \n",
                "        return sorted(grasps, key=lambda g: g['score'], reverse=True)\n",
                "    \n",
                "    def _fallback_analysis(self, obj):\n",
                "        rect = obj.get('rect')\n",
                "        if rect is None:\n",
                "            return []\n",
                "        \n",
                "        (cx, cy), (w, h), angle = rect\n",
                "        cx, cy = int(cx), int(cy)\n",
                "        \n",
                "        if w < h:\n",
                "            grip_w = w / self.ppm\n",
                "            grip_a = angle + 90\n",
                "        else:\n",
                "            grip_w = h / self.ppm\n",
                "            grip_a = angle\n",
                "        \n",
                "        grasps = []\n",
                "        if grip_w <= GRIPPER_MAX_WIDTH_MM:\n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': grip_w,\n",
                "                'camera_angle': self._normalize_angle(grip_a),\n",
                "                'score': 0.6,\n",
                "                'type': 'rect_fallback',\n",
                "                'axis_info': None\n",
                "            })\n",
                "        \n",
                "        return grasps\n",
                "    \n",
                "    def _normalize_angle(self, angle):\n",
                "        while angle > 90: angle -= 180\n",
                "        while angle < -90: angle += 180\n",
                "        return angle\n",
                "\n",
                "print(\"‚úì PCA Grasp Selector\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Initialize Components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Components initialized (v11 LIDAR)\n"
                    ]
                }
            ],
            "source": [
                "gripper = SmartGripperController(port=ESP32_PORT, baudrate=ESP32_BAUDRATE)\n",
                "robot = DobotControllerTCP(homography_matrix=HOMOGRAPHY_MATRIX, r_offset=ROBOT_R_OFFSET)\n",
                "detector = ObjectDetector(yolo_model, PIXELS_PER_MM)\n",
                "grasp_selector = PCAGraspSelector(PIXELS_PER_MM)\n",
                "print(\"‚úì Components initialized (v11 LIDAR)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üß™ TEST LIDAR (No Robot)\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "üß™ TEST LIDAR READING\n",
                        "============================================================\n",
                        "‚úÖ Gripper+LIDAR on COM9\n",
                        "\n",
                        "Reading LIDAR 10 times...\n",
                        "  [1] Distance: 290 mm (29.0 cm)\n",
                        "  [2] Distance: 290 mm (29.0 cm)\n",
                        "  [3] Distance: 290 mm (29.0 cm)\n",
                        "  [4] Distance: 290 mm (29.0 cm)\n",
                        "  [5] Distance: 290 mm (29.0 cm)\n",
                        "  [6] Distance: 290 mm (29.0 cm)\n",
                        "  [7] Distance: 290 mm (29.0 cm)\n",
                        "  [8] Distance: 290 mm (29.0 cm)\n",
                        "  [9] Distance: 290 mm (29.0 cm)\n",
                        "  [10] Distance: 290 mm (29.0 cm)\n",
                        "\n",
                        "‚úÖ LIDAR test complete\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"üß™ TEST LIDAR READING\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "gripper.connect()\n",
                "\n",
                "print(\"\\nReading LIDAR 10 times...\")\n",
                "for i in range(10):\n",
                "    dist = gripper.read_lidar()\n",
                "    if dist:\n",
                "        print(f\"  [{i+1}] Distance: {dist} mm ({dist/10:.1f} cm)\")\n",
                "    else:\n",
                "        print(f\"  [{i+1}] LIDAR: Error reading\")\n",
                "    time.sleep(0.3)\n",
                "\n",
                "gripper.disconnect()\n",
                "print(\"\\n‚úÖ LIDAR test complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üß™ TEST GRASP MODEL (No Robot)\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ü§ñ HOME...\n"
                    ]
                }
            ],
            "source": [
                "robot.home()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "üß™ TEST GRASP MODEL (No Robot)\n",
                        "   Click=Select Object | Q=Quit\n",
                        "============================================================\n",
                        "\n",
                        "‚úÖ Test complete\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"üß™ TEST GRASP MODEL (No Robot)\")\n",
                "print(\"   Click=Select Object | Q=Quit\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "test_selected = None\n",
                "test_grasps = []\n",
                "\n",
                "def test_mouse_cb(event, x, y, flags, param):\n",
                "    global test_selected, test_grasps\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        for obj in param.get('objects', []):\n",
                "            bx,by,bw,bh = obj['bbox']\n",
                "            if bx <= x <= bx+bw and by <= y <= by+bh:\n",
                "                test_selected = obj\n",
                "                test_grasps = grasp_selector.analyze_object(obj)\n",
                "                if test_grasps:\n",
                "                    g = test_grasps[0]\n",
                "                    print(f\"\\nüì¶ Selected: W={g['width_mm']:.1f}mm Angle={g['camera_angle']:.1f}¬∞\")\n",
                "                    print(f\"   Type: {g['type']}\")\n",
                "                break\n",
                "\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Test v11')\n",
                "callback_data = {'objects': []}\n",
                "cv2.setMouseCallback('Test v11', test_mouse_cb, callback_data)\n",
                "\n",
                "def draw_grasps(frame, grasps, selected):\n",
                "    for g in grasps:\n",
                "        cx, cy = g['center']\n",
                "        angle = g['camera_angle']\n",
                "        is_sel = (selected and g == selected)\n",
                "        color = (0,0,255) if is_sel else ((0,255,0) if g['score']>=0.7 else (0,255,255))\n",
                "        thick = 3 if is_sel else 2\n",
                "        \n",
                "        length = 40\n",
                "        dx = int(length * np.cos(np.radians(angle)))\n",
                "        dy = int(length * np.sin(np.radians(angle)))\n",
                "        cv2.line(frame, (cx-dx, cy-dy), (cx+dx, cy+dy), color, thick)\n",
                "        cv2.circle(frame, (cx, cy), 5, color, -1)\n",
                "        \n",
                "        grip_half = int(g['width_mm'] * PIXELS_PER_MM / 2)\n",
                "        perp_angle = angle + 90\n",
                "        px = int(grip_half * np.cos(np.radians(perp_angle)))\n",
                "        py = int(grip_half * np.sin(np.radians(perp_angle)))\n",
                "        cv2.line(frame, (cx+px-dx//2, cy+py-dy//2), (cx+px+dx//2, cy+py+dy//2), color, 2)\n",
                "        cv2.line(frame, (cx-px-dx//2, cy-py-dy//2), (cx-px+dx//2, cy-py+dy//2), color, 2)\n",
                "\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    \n",
                "    detected = detector.detect(frame)\n",
                "    callback_data['objects'] = detected\n",
                "    \n",
                "    display = frame.copy()\n",
                "    for obj in detected:\n",
                "        x,y,w,h = obj['bbox']\n",
                "        is_sel = (test_selected and obj['center'] == test_selected['center'])\n",
                "        color = (0,0,255) if is_sel else (0,255,0)\n",
                "        cv2.rectangle(display, (x,y), (x+w,y+h), color, 2)\n",
                "    \n",
                "    if test_selected and test_grasps:\n",
                "        draw_grasps(display, test_grasps, test_grasps[0])\n",
                "    \n",
                "    cv2.rectangle(display, (0,0), (640,35), (30,30,30), -1)\n",
                "    cv2.putText(display, f\"v11 LIDAR | Obj:{len(detected)} | Click | Q=Quit\",\n",
                "               (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1)\n",
                "    \n",
                "    cv2.imshow('Test v11', display)\n",
                "    \n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == ord('r'):\n",
                "        test_selected = None\n",
                "        test_grasps = []\n",
                "\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()\n",
                "print(\"\\n‚úÖ Test complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# ü§ñ FULL ROBOT PICK WITH LIDAR\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "ü§ñ Connecting to Robot and Gripper+LIDAR...\n",
                        "============================================================\n",
                        "‚úÖ Gripper+LIDAR on COM9\n",
                        "‚úÖ Robot connected!\n",
                        "ü§ñ HOME...\n",
                        "‚úÖ Ready!\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"ü§ñ Connecting to Robot and Gripper+LIDAR...\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "gripper.connect()\n",
                "robot.connect(ROBOT_IP)\n",
                "robot.home()\n",
                "\n",
                "print(\"‚úÖ Ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "ename": "SerialException",
                    "evalue": "could not open port 'COM9': PermissionError(13, 'Access is denied.', None, 5)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mSerialException\u001b[39m                           Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mserial\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m ser = \u001b[43mserial\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSerial\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCOM9\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m115200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m time.sleep(\u001b[32m4\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Test open\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CPE KMUTT\\Music\\artificial-12-4-2025\\latest_artif_mng_hardware_room\\.venv\\Lib\\site-packages\\serial\\serialwin32.py:31\u001b[39m, in \u001b[36mSerial.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mself\u001b[39m._overlapped_read = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mself\u001b[39m._overlapped_write = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSerial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CPE KMUTT\\Music\\artificial-12-4-2025\\latest_artif_mng_hardware_room\\.venv\\Lib\\site-packages\\serial\\serialutil.py:240\u001b[39m, in \u001b[36mSerialBase.__init__\u001b[39m\u001b[34m(self, port, baudrate, bytesize, parity, stopbits, timeout, xonxoff, rtscts, write_timeout, dsrdtr, inter_byte_timeout, exclusive, **kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33munexpected keyword arguments: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(kwargs))\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m port \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CPE KMUTT\\Music\\artificial-12-4-2025\\latest_artif_mng_hardware_room\\.venv\\Lib\\site-packages\\serial\\serialwin32.py:62\u001b[39m, in \u001b[36mSerial.open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._port_handle == win32.INVALID_HANDLE_VALUE:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m._port_handle = \u001b[38;5;28;01mNone\u001b[39;00m    \u001b[38;5;66;03m# 'cause __del__ is called anyway\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SerialException(\u001b[33m\"\u001b[39m\u001b[33mcould not open port \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.portstr, ctypes.WinError()))\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mself\u001b[39m._overlapped_read = win32.OVERLAPPED()\n",
                        "\u001b[31mSerialException\u001b[39m: could not open port 'COM9': PermissionError(13, 'Access is denied.', None, 5)"
                    ]
                }
            ],
            "source": [
                "# Test gripper connection\n",
                "import serial\n",
                "import time\n",
                "\n",
                "ser = serial.Serial('COM9', 115200, timeout=2)\n",
                "time.sleep(4)\n",
                "\n",
                "# Test open\n",
                "ser.write(b'O\\n')\n",
                "time.sleep(10)\n",
                "print(ser.readline().decode().strip())\n",
                "\n",
                "# Test close\n",
                "ser.write(b'C\\n')\n",
                "time.sleep(10)\n",
                "print(ser.readline().decode().strip())\n",
                "\n",
                "ser.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ü¶æ Open: 15.0mm (77¬∞)\n"
                    ]
                }
            ],
            "source": [
                "gripper.open_for_object(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ü§ñ HOME...\n"
                    ]
                }
            ],
            "source": [
                "robot.home()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "üéØ PICK v11 (LIDAR-based)\n",
                        "Click=Select | SPACE=Execute | H=Home | Q=Quit\n",
                        "============================================================\n",
                        "\n",
                        "üì¶ Object: 2 grasps\n",
                        "   Best: W=29.6mm R=-19.8¬∞\n",
                        "\n",
                        "ü§ñ Pick (LIDAR): W=29.6mm R=-19.8¬∞\n",
                        "   Type: PCA_narrow\n",
                        "üîÑ Safe position...\n",
                        "   ‚Üí JointMovJ(0,0,0,0)\n",
                        "ü¶æ Open: 54.0mm (22¬∞)\n",
                        "üìè Moving to Z_MEASURE=120...\n",
                        "   ‚Üí MovJ(14.483114712312023,69.12085898453589,120,-19.766358843322767)\n",
                        "üìè LIDAR: 220 mm\n",
                        "üìç Z_GRASP = 120 - 220 + 60 = -40.0\n",
                        "   ‚Üí MovJ(14.483114712312023,69.12085898453589,-40,-19.766358843322767)\n",
                        "ü¶æ Grip: 21.1mm - 5mm = 16.1mm (76¬∞)\n",
                        "   ‚Üí MovJ(-253.07,115.17,-17.07,-62.78)\n",
                        "ü§ñ HOME...\n",
                        "‚úÖ Complete!\n"
                    ]
                }
            ],
            "source": [
                "selected_object = None\n",
                "selected_grasp = None\n",
                "current_grasps = []\n",
                "detected_objects = []\n",
                "\n",
                "def mouse_callback(event, x, y, flags, param):\n",
                "    global selected_object, selected_grasp, current_grasps\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        for g in current_grasps:\n",
                "            gx, gy = g['center']\n",
                "            if abs(x-gx) < 20 and abs(y-gy) < 20:\n",
                "                selected_grasp = g\n",
                "                robot_r = robot.camera_angle_to_robot_r(g['camera_angle'])\n",
                "                print(f\"\\nüéØ Grasp: W={g['width_mm']:.1f}mm ‚Üí R={robot_r:.1f}¬∞\")\n",
                "                return\n",
                "        for obj in detected_objects:\n",
                "            bx,by,bw,bh = obj['bbox']\n",
                "            if bx <= x <= bx+bw and by <= y <= by+bh:\n",
                "                selected_object = obj\n",
                "                current_grasps = grasp_selector.analyze_object(obj)\n",
                "                selected_grasp = current_grasps[0] if current_grasps else None\n",
                "                if selected_grasp:\n",
                "                    robot_r = robot.camera_angle_to_robot_r(selected_grasp['camera_angle'])\n",
                "                    print(f\"\\nüì¶ Object: {len(current_grasps)} grasps\")\n",
                "                    print(f\"   Best: W={selected_grasp['width_mm']:.1f}mm R={robot_r:.1f}¬∞\")\n",
                "                break\n",
                "\n",
                "def pick_with_lidar(obj, grasp):\n",
                "    \"\"\"v11: Pick using LIDAR for Z measurement\"\"\"\n",
                "    cx, cy = grasp['center']\n",
                "    grip_w = grasp['width_mm']\n",
                "    camera_angle = grasp['camera_angle']\n",
                "    robot_r = robot.camera_angle_to_robot_r(camera_angle)\n",
                "    \n",
                "    robot_x, robot_y = robot.pixel_to_robot(cx, cy)\n",
                "    \n",
                "    print(f\"\\nü§ñ Pick (LIDAR): W={grip_w:.1f}mm R={robot_r:.1f}¬∞\")\n",
                "    print(f\"   Type: {grasp['type']}\")\n",
                "    \n",
                "    # 1. Safe position\n",
                "    print(\"üîÑ Safe position...\")\n",
                "    robot.joint_move_and_wait(0, 0, 0, 0, 3)\n",
                "    \n",
                "    # 2. Open gripper\n",
                "    gripper.open_for_object(GRIPPER_MAX_WIDTH_MM)\n",
                "    time.sleep(2.5)\n",
                "    \n",
                "    # 3. Move to measure position (above object)\n",
                "    print(f\"üìè Moving to Z_MEASURE={Z_MEASURE}...\")\n",
                "    robot.move_to_and_wait(robot_x, robot_y, Z_MEASURE, robot_r, 2)\n",
                "    \n",
                "    # 4. Read LIDAR\n",
                "    lidar_dist = gripper.read_lidar(samples=5)\n",
                "    if lidar_dist is None:\n",
                "        print(\"‚ùå LIDAR read failed! Aborting.\")\n",
                "        robot.home()\n",
                "        return\n",
                "    \n",
                "    print(f\"üìè LIDAR: {lidar_dist} mm\")\n",
                "    \n",
                "    # 5. Calculate Z_GRASP\n",
                "    z_grasp = Z_MEASURE - lidar_dist + LIDAR_TO_GRIPPER_OFFSET\n",
                "    z_grasp = max(Z_FLOOR, z_grasp)\n",
                "    \n",
                "    print(f\"üìç Z_GRASP = {Z_MEASURE} - {lidar_dist} + {LIDAR_TO_GRIPPER_OFFSET} = {z_grasp:.1f}\")\n",
                "    \n",
                "    # 6. Go directly to grasp position\n",
                "    robot.move_to_and_wait(robot_x, robot_y, z_grasp, robot_r, 2)\n",
                "    \n",
                "    # 7. Grip\n",
                "    gripper.grip_object(grip_w - 8.5)\n",
                "    time.sleep(2.5)\n",
                "    \n",
                "    # 8. Go directly to drop\n",
                "    robot.move_to_and_wait(*DROP_POS[:3], DROP_POS[3], 3)\n",
                "    \n",
                "    # 9. Release\n",
                "    gripper.release()\n",
                "    time.sleep(2.5)\n",
                "    robot.home()\n",
                "    print(\"‚úÖ Complete!\")\n",
                "\n",
                "# Main loop\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Pick v11 LIDAR')\n",
                "cv2.setMouseCallback('Pick v11 LIDAR', mouse_callback)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üéØ PICK v11 (LIDAR-based)\")\n",
                "print(\"Click=Select | SPACE=Execute | H=Home | Q=Quit\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    \n",
                "    detected_objects = detector.detect(frame)\n",
                "    \n",
                "    display = frame.copy()\n",
                "    for obj in detected_objects:\n",
                "        x,y,w,h = obj['bbox']\n",
                "        is_sel = (selected_object and obj['center'] == selected_object['center'])\n",
                "        color = (0,0,255) if is_sel else (0,255,0)\n",
                "        cv2.rectangle(display, (x,y), (x+w,y+h), color, 2)\n",
                "    \n",
                "    if selected_object and current_grasps:\n",
                "        draw_grasps(display, current_grasps, selected_grasp)\n",
                "    \n",
                "    cv2.rectangle(display, (0,0), (640,35), (30,30,30), -1)\n",
                "    cv2.putText(display, f\"v11 LIDAR | Obj:{len(detected_objects)} | Click | SPACE | H | Q\",\n",
                "               (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1)\n",
                "    \n",
                "    if selected_grasp:\n",
                "        robot_r = robot.camera_angle_to_robot_r(selected_grasp['camera_angle'])\n",
                "        cv2.putText(display, f\"[{selected_grasp['type']}: W={selected_grasp['width_mm']:.1f}mm R={robot_r:.0f} - SPACE]\",\n",
                "                   (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
                "    \n",
                "    cv2.imshow('Pick v11 LIDAR', display)\n",
                "    \n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == ord('r'):\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "    elif key == ord('h'):\n",
                "        robot.home()\n",
                "    elif key == ord(' ') and selected_object and selected_grasp:\n",
                "        pick_with_lidar(selected_object, selected_grasp)\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()\n",
                "gripper.disconnect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ROBOT_R_OFFSET = -25.55\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
