{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ LIDAR Grasp Detection v13 -*BEST FOR NOWWW\n",
                "\n",
                "## ‚ú® ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏ô v13\n",
                "| ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ | ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç |\n",
                "|-------|----------|\n",
                "| LIDAR offset ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ | **LIDAR Calibration Factor** ‡πÅ‡∏¢‡∏Å physical offset ‡∏Å‡∏±‡∏ö correction |\n",
                "| YOLO detect ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ | **Color + Edge Detection** ‡πÑ‡∏°‡πà‡∏û‡∏∂‡πà‡∏á YOLO |\n",
                "| ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏™‡∏π‡∏á ‚Üí LIDAR error ‡∏°‡∏≤‡∏Å | **Height-based Correction** ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Imports (v13 - No YOLO required)\n"
                    ]
                }
            ],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import time\n",
                "import socket\n",
                "import serial\n",
                "\n",
                "print(\"‚úì Imports (v13 - No YOLO required)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Hardware Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Hardware config\n"
                    ]
                }
            ],
            "source": [
                "ROBOT_IP = '192.168.1.6'\n",
                "ESP32_PORT = 'COM9'\n",
                "ESP32_BAUDRATE = 115200\n",
                "CAMERA_ID = 2\n",
                "\n",
                "HOMOGRAPHY_MATRIX = np.load('homography_matrix.npy')\n",
                "\n",
                "print(\"‚úì Hardware config\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Configuration v13\n",
                        "   LIDAR: Physical=60mm, Correction=-21mm\n",
                        "   Height Correction: 12%\n"
                    ]
                }
            ],
            "source": [
                "# === CALIBRATED VALUES ===\n",
                "PIXELS_PER_MM = 2.7703\n",
                "\n",
                "# === Robot R Rotation ===\n",
                "ROBOT_R_OFFSET = -25.55\n",
                "\n",
                "# === Z Heights ===\n",
                "Z_FLOOR = -64\n",
                "#Z_MEASURE = 195 # ‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ\n",
                "Z_MEASURE = 120\n",
                "\n",
                "\n",
                "# === v13: LIDAR Configuration ===\n",
                "# Physical offset = ‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å LIDAR ‡∏ñ‡∏∂‡∏á gripper\n",
                "LIDAR_PHYSICAL_OFFSET = 60  # mm (‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î‡πÑ‡∏î‡πâ)\n",
                "\n",
                "# Correction = ‡∏Ñ‡πà‡∏≤‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç LIDAR error (60 - 39 = 21)\n",
                "LIDAR_CORRECTION = -21  # mm\n",
                "\n",
                "# LIDAR XY Offset\n",
                "LIDAR_X_OFFSET = 25.08\n",
                "LIDAR_Y_OFFSET = 20.71\n",
                "\n",
                "# === v13: Height-based Correction ===\n",
                "#HEIGHT_CORRECTION_FACTOR = 0.15  # 15%\n",
                "#HEIGHT_CORRECTION_FACTOR = 0.10  # 10% (‡∏´‡∏£‡∏∑‡∏≠ 0.05 ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ)\n",
                "# === v13: Height-based Correction ===\n",
                "HEIGHT_CORRECTION_FACTOR = 0.115  # 11.5% (‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏™‡∏π‡∏á >= 152mm ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)\n",
                "HEIGHT_THRESHOLD_MM = 152  # mm - ‡∏ñ‡πâ‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Ñ‡πà‡∏≠‡∏¢‡πÉ‡∏ä‡πâ correction\n",
                "\n",
                "# === Drop Position ===\n",
                "DROP_POS = (169.71, 58.01, -17.07, 13.78)\n",
                "\n",
                "# === Gripper ===\n",
                "GRIPPER_MAX_WIDTH_MM = 54\n",
                "GRIPPER_OPEN_MARGIN_MM = 5\n",
                "GRIPPER_GRIP_MARGIN_MM = 5\n",
                "\n",
                "# === Detection ===\n",
                "MIN_OBJECT_AREA = 800\n",
                "MAX_OBJECT_AREA = 50000\n",
                "\n",
                "print(\"‚úì Configuration v13\")\n",
                "print(f\"   LIDAR: Physical={LIDAR_PHYSICAL_OFFSET}mm, Correction={LIDAR_CORRECTION}mm\")\n",
                "print(f\"   Height Correction: {HEIGHT_CORRECTION_FACTOR*100:.0f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ SmartGripperController Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì SmartGripperController class\n"
                    ]
                }
            ],
            "source": [
                "class SmartGripperController:\n",
                "    \"\"\"Gripper + LIDAR Controller (v13)\"\"\"\n",
                "    CALIB_ANGLES = np.array([22, 30, 40, 50, 60, 70, 80, 90, 96])\n",
                "    CALIB_WIDTHS = np.array([54.0, 52.0, 48.0, 40.0, 32.0, 23.0, 12.0, 3.0, 0.0])\n",
                "    \n",
                "    def __init__(self, port='COM9', baudrate=115200):\n",
                "        self.port = port\n",
                "        self.baudrate = baudrate\n",
                "        self.serial = None\n",
                "        self.target_width = None\n",
                "        \n",
                "    def connect(self):\n",
                "        try:\n",
                "            self.serial = serial.Serial(self.port, self.baudrate, timeout=2)\n",
                "            time.sleep(2)\n",
                "            self.serial.reset_input_buffer()\n",
                "            print(f\"‚úÖ Gripper+LIDAR on {self.port}\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå {e}\")\n",
                "            return False\n",
                "    \n",
                "    def disconnect(self):\n",
                "        if self.serial: \n",
                "            self.serial.close()\n",
                "            self.serial = None\n",
                "    \n",
                "    def send_command(self, cmd):\n",
                "        if self.serial and self.serial.is_open:\n",
                "            self.serial.reset_input_buffer()\n",
                "            self.serial.write((cmd + '\\n').encode())\n",
                "            time.sleep(0.3)\n",
                "    \n",
                "    def mm_to_angle(self, width_mm):\n",
                "        width = max(0.0, min(54.0, width_mm))\n",
                "        return int(round(np.interp(width, self.CALIB_WIDTHS[::-1], self.CALIB_ANGLES[::-1])))\n",
                "    \n",
                "    def open_for_object(self, width_mm):\n",
                "        self.target_width = width_mm\n",
                "        open_w = min(54.0, width_mm + GRIPPER_OPEN_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(open_w)\n",
                "        print(f\"ü¶æ Open: {open_w:.1f}mm ({angle}¬∞)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def grip_object(self, width_mm):\n",
                "        grip_w = max(0.0, width_mm - GRIPPER_GRIP_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(grip_w)\n",
                "        print(f\"ü¶æ Grip: {grip_w:.1f}mm ({angle}¬∞)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def release(self):\n",
                "        open_w = min(54.0, (self.target_width or 30) + 10)\n",
                "        self.send_command(f'G{self.mm_to_angle(open_w)}')\n",
                "        self.target_width = None\n",
                "    \n",
                "    def read_lidar(self, samples=5):\n",
                "        \"\"\"Read LIDAR distance in mm\"\"\"\n",
                "        if not self.serial or not self.serial.is_open:\n",
                "            return None\n",
                "        \n",
                "        readings = []\n",
                "        for _ in range(samples):\n",
                "            self.serial.reset_input_buffer()\n",
                "            self.serial.write(b'L\\n')\n",
                "            \n",
                "            start = time.time()\n",
                "            while time.time() - start < 1.0:\n",
                "                if self.serial.in_waiting > 0:\n",
                "                    response = self.serial.readline().decode().strip()\n",
                "                    if response.startswith(\"LIDAR:\") and \"ERR\" not in response:\n",
                "                        try:\n",
                "                            dist = int(response.split(\":\")[1])\n",
                "                            readings.append(dist)\n",
                "                        except:\n",
                "                            pass\n",
                "                        break\n",
                "            time.sleep(0.05)\n",
                "        \n",
                "        if readings:\n",
                "            return int(np.median(readings))\n",
                "        return None\n",
                "\n",
                "print(\"‚úì SmartGripperController class\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ DobotControllerTCP Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì DobotControllerTCP class\n"
                    ]
                }
            ],
            "source": [
                "class DobotControllerTCP:\n",
                "    def __init__(self, homography_matrix=None, r_offset=-25.55):\n",
                "        self.dashboard_port = 29999\n",
                "        self.sock = None\n",
                "        self.H = homography_matrix\n",
                "        self.r_offset = r_offset\n",
                "        \n",
                "    def connect(self, ip):\n",
                "        try:\n",
                "            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
                "            self.sock.settimeout(5)\n",
                "            self.sock.connect((ip, self.dashboard_port))\n",
                "            self.send_command(\"ClearError()\")\n",
                "            time.sleep(0.5)\n",
                "            self.send_command(\"EnableRobot()\")\n",
                "            time.sleep(4)\n",
                "            self.send_command(\"User(1)\")\n",
                "            self.send_command(\"Tool(1)\")\n",
                "            self.send_command(\"SpeedFactor(50)\")\n",
                "            print(\"‚úÖ Robot connected!\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"Error: {e}\")\n",
                "            return False\n",
                "\n",
                "    def send_command(self, cmd):\n",
                "        if self.sock:\n",
                "            self.sock.send((cmd + \"\\n\").encode(\"utf-8\"))\n",
                "            return self.sock.recv(1024).decode(\"utf-8\")\n",
                "\n",
                "    def home(self):\n",
                "        print(\"ü§ñ HOME...\")\n",
                "        self.send_command(\"MovJ(-253.07, 115.17, -17.07, -62.78)\")\n",
                "        time.sleep(4)\n",
                "\n",
                "    def move_to(self, x, y, z, r=0):\n",
                "        cmd = f\"MovJ({x},{y},{z},{r})\"\n",
                "        print(f\"   ‚Üí {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def move_to_and_wait(self, x, y, z, r=0, wait=3):\n",
                "        self.move_to(x, y, z, r)\n",
                "        time.sleep(wait)\n",
                "    \n",
                "    def joint_move(self, j1=0, j2=0, j3=0, j4=0):\n",
                "        cmd = f\"JointMovJ({j1},{j2},{j3},{j4})\"\n",
                "        print(f\"   ‚Üí {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def joint_move_and_wait(self, j1=0, j2=0, j3=0, j4=0, wait=3):\n",
                "        self.joint_move(j1, j2, j3, j4)\n",
                "        time.sleep(wait)\n",
                "\n",
                "    def pixel_to_robot(self, u, v):\n",
                "        if self.H is None: return None, None\n",
                "        pt = np.array([u, v, 1], dtype=np.float32)\n",
                "        res = np.dot(self.H, pt)\n",
                "        return res[0]/res[2], res[1]/res[2]\n",
                "    \n",
                "    def camera_angle_to_robot_r(self, camera_angle):\n",
                "        return self.r_offset - camera_angle\n",
                "\n",
                "print(\"‚úì DobotControllerTCP class\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ ObjectDetectorV13 Class (Color + Edge - All Colors)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì ObjectDetectorV13 (Saturation + Edge - All Colors)\n"
                    ]
                }
            ],
            "source": [
                "class ObjectDetectorV13:\n",
                "    \"\"\"v13: Universal Color + Edge Detection (No YOLO)\"\"\"\n",
                "    \n",
                "    def __init__(self, pixels_per_mm):\n",
                "        self.ppm = pixels_per_mm\n",
                "    \n",
                "    def detect(self, frame):\n",
                "        \"\"\"Detect objects using saturation-based + edge detection\"\"\"\n",
                "        objects = []\n",
                "        \n",
                "        # Method 1: Saturation-based (detect ANY colored object)\n",
                "        sat_objects = self._detect_by_saturation(frame)\n",
                "        objects.extend(sat_objects)\n",
                "        \n",
                "        # Method 2: Edge detection as fallback\n",
                "        if len(objects) == 0:\n",
                "            edge_objects = self._detect_by_edge(frame)\n",
                "            objects.extend(edge_objects)\n",
                "        \n",
                "        # Remove duplicates\n",
                "        objects = self._remove_duplicates(objects)\n",
                "        \n",
                "        return objects\n",
                "    \n",
                "    def _detect_by_saturation(self, frame):\n",
                "        \"\"\"Detect ANY colored object by saturation (‡∏ó‡∏∏‡∏Å‡∏™‡∏µ)\"\"\"\n",
                "        objects = []\n",
                "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
                "        \n",
                "        # Get saturation channel\n",
                "        h, s, v = cv2.split(hsv)\n",
                "        \n",
                "        # Threshold on saturation (colored objects have high saturation)\n",
                "        _, sat_mask = cv2.threshold(s, 50, 255, cv2.THRESH_BINARY)\n",
                "        \n",
                "        # Also detect dark objects (low value)\n",
                "        _, dark_mask = cv2.threshold(v, 80, 255, cv2.THRESH_BINARY_INV)\n",
                "        \n",
                "        # Combine masks\n",
                "        combined_mask = cv2.bitwise_or(sat_mask, dark_mask)\n",
                "        \n",
                "        # Morphology cleanup\n",
                "        kernel = np.ones((5, 5), np.uint8)\n",
                "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)\n",
                "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
                "        \n",
                "        # Find contours\n",
                "        contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "        \n",
                "        for cnt in contours:\n",
                "            area = cv2.contourArea(cnt)\n",
                "            if MIN_OBJECT_AREA < area < MAX_OBJECT_AREA:\n",
                "                obj = self._contour_to_object(cnt, 'color')\n",
                "                if obj:\n",
                "                    objects.append(obj)\n",
                "        \n",
                "        return objects\n",
                "    \n",
                "    def _detect_by_edge(self, frame):\n",
                "        \"\"\"Detect objects by edge (fallback)\"\"\"\n",
                "        objects = []\n",
                "        \n",
                "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
                "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
                "        edges = cv2.Canny(blur, 50, 150)\n",
                "        \n",
                "        kernel = np.ones((3, 3), np.uint8)\n",
                "        edges = cv2.dilate(edges, kernel, iterations=2)\n",
                "        edges = cv2.erode(edges, kernel, iterations=1)\n",
                "        \n",
                "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "        \n",
                "        for cnt in contours:\n",
                "            area = cv2.contourArea(cnt)\n",
                "            if MIN_OBJECT_AREA < area < MAX_OBJECT_AREA:\n",
                "                obj = self._contour_to_object(cnt, 'edge')\n",
                "                if obj:\n",
                "                    objects.append(obj)\n",
                "        \n",
                "        return objects\n",
                "    \n",
                "    def _contour_to_object(self, cnt, method):\n",
                "        \"\"\"Convert contour to object dict\"\"\"\n",
                "        hull = cv2.convexHull(cnt)\n",
                "        rect = cv2.minAreaRect(hull)\n",
                "        (cx, cy), (w, h), angle = rect\n",
                "        \n",
                "        x, y, bw, bh = cv2.boundingRect(cnt)\n",
                "        \n",
                "        return {\n",
                "            'bbox': (x, y, bw, bh),\n",
                "            'center': (int(cx), int(cy)),\n",
                "            'rect': rect,\n",
                "            'contour': hull,\n",
                "            'area': cv2.contourArea(hull),\n",
                "            'method': method\n",
                "        }\n",
                "    \n",
                "    def _remove_duplicates(self, objects, min_dist=30):\n",
                "        \"\"\"Remove objects too close together\"\"\"\n",
                "        if len(objects) <= 1:\n",
                "            return objects\n",
                "        \n",
                "        unique = []\n",
                "        for obj in sorted(objects, key=lambda o: o['area'], reverse=True):\n",
                "            cx, cy = obj['center']\n",
                "            is_dup = False\n",
                "            for u in unique:\n",
                "                ux, uy = u['center']\n",
                "                if np.sqrt((cx-ux)**2 + (cy-uy)**2) < min_dist:\n",
                "                    is_dup = True\n",
                "                    break\n",
                "            if not is_dup:\n",
                "                unique.append(obj)\n",
                "        \n",
                "        return unique\n",
                "\n",
                "print(\"‚úì ObjectDetectorV13 (Saturation + Edge - All Colors)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ PCAGraspSelector Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì PCAGraspSelector class\n"
                    ]
                }
            ],
            "source": [
                "class PCAGraspSelector:\n",
                "    def __init__(self, pixels_per_mm):\n",
                "        self.ppm = pixels_per_mm\n",
                "    \n",
                "    def analyze_object(self, obj):\n",
                "        cnt = obj.get('contour')\n",
                "        if cnt is None or len(cnt) < 5:\n",
                "            return self._fallback(obj)\n",
                "        \n",
                "        pts = cnt.reshape(-1, 2).astype(np.float64)\n",
                "        mean = np.mean(pts, axis=0)\n",
                "        pts_centered = pts - mean\n",
                "        \n",
                "        cov = np.cov(pts_centered.T)\n",
                "        eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
                "        idx = np.argsort(eigenvalues)[::-1]\n",
                "        eigenvectors = eigenvectors[:, idx]\n",
                "        \n",
                "        major = eigenvectors[:, 0]\n",
                "        minor = eigenvectors[:, 1]\n",
                "        \n",
                "        angle = np.degrees(np.arctan2(major[1], major[0]))\n",
                "        \n",
                "        proj = np.dot(pts_centered, minor)\n",
                "        width_mm = (np.max(proj) - np.min(proj)) / self.ppm\n",
                "        \n",
                "        cx, cy = int(mean[0]), int(mean[1])\n",
                "        grasp_angle = self._normalize(angle + 90)\n",
                "        \n",
                "        grasps = []\n",
                "        if width_mm <= GRIPPER_MAX_WIDTH_MM:\n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': width_mm,\n",
                "                'camera_angle': grasp_angle,\n",
                "                'score': 1.0,\n",
                "                'type': 'PCA'\n",
                "            })\n",
                "        return grasps if grasps else self._fallback(obj)\n",
                "    \n",
                "    def _fallback(self, obj):\n",
                "        rect = obj.get('rect')\n",
                "        if not rect: return []\n",
                "        (cx, cy), (w, h), angle = rect\n",
                "        grip_w = min(w, h) / self.ppm\n",
                "        grip_a = angle + 90 if w < h else angle\n",
                "        if grip_w <= GRIPPER_MAX_WIDTH_MM:\n",
                "            return [{'center': (int(cx), int(cy)), 'width_mm': grip_w, \n",
                "                     'camera_angle': self._normalize(grip_a), 'score': 0.6, 'type': 'Rect'}]\n",
                "        return []\n",
                "    \n",
                "    def _normalize(self, a):\n",
                "        while a > 90: a -= 180\n",
                "        while a < -90: a += 180\n",
                "        return a\n",
                "\n",
                "print(\"‚úì PCAGraspSelector class\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8Ô∏è‚É£ Initialize Components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Components initialized (v13)\n"
                    ]
                }
            ],
            "source": [
                "gripper = SmartGripperController(port=ESP32_PORT, baudrate=ESP32_BAUDRATE)\n",
                "robot = DobotControllerTCP(homography_matrix=HOMOGRAPHY_MATRIX, r_offset=ROBOT_R_OFFSET)\n",
                "detector = ObjectDetectorV13(PIXELS_PER_MM)\n",
                "grasp_selector = PCAGraspSelector(PIXELS_PER_MM)\n",
                "print(\"‚úì Components initialized (v13)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# ü§ñ CONNECT ROBOT & GRIPPER\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "ü§ñ Connecting to Robot and Gripper+LIDAR...\n",
                        "============================================================\n",
                        "‚úÖ Gripper+LIDAR on COM9\n",
                        "‚úÖ Robot connected!\n",
                        "ü§ñ HOME...\n",
                        "‚úÖ Ready!\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"ü§ñ Connecting to Robot and Gripper+LIDAR...\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "gripper.connect()\n",
                "robot.connect(ROBOT_IP)\n",
                "robot.home()\n",
                "\n",
                "print(\"‚úÖ Ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üéØ FULL ROBOT PICK v13\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "selected_object = None\n",
                "selected_grasp = None\n",
                "current_grasps = []\n",
                "detected_objects = []\n",
                "\n",
                "def mouse_callback(event, x, y, flags, param):\n",
                "    global selected_object, selected_grasp, current_grasps\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        for obj in detected_objects:\n",
                "            bx, by, bw, bh = obj['bbox']\n",
                "            if bx <= x <= bx+bw and by <= y <= by+bh:\n",
                "                selected_object = obj\n",
                "                current_grasps = grasp_selector.analyze_object(obj)\n",
                "                selected_grasp = current_grasps[0] if current_grasps else None\n",
                "                if selected_grasp:\n",
                "                    print(f\"\\nüì¶ Object: W={selected_grasp['width_mm']:.1f}mm\")\n",
                "                break\n",
                "\n",
                "def draw_grasps(frame, grasps, selected):\n",
                "    for g in grasps:\n",
                "        cx, cy = g['center']\n",
                "        angle = g['camera_angle']\n",
                "        is_sel = (selected and g == selected)\n",
                "        color = (0, 0, 255) if is_sel else (0, 255, 0)\n",
                "        thick = 3 if is_sel else 2\n",
                "        \n",
                "        length = 40\n",
                "        dx = int(length * np.cos(np.radians(angle)))\n",
                "        dy = int(length * np.sin(np.radians(angle)))\n",
                "        cv2.line(frame, (cx-dx, cy-dy), (cx+dx, cy+dy), color, thick)\n",
                "        cv2.circle(frame, (cx, cy), 5, color, -1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# update ‡∏Ñ‡πà‡πà‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏™‡πÜ1234\n",
                "HEIGHT_CORRECTION_FACTOR = 0.115"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "def pick_with_lidar_v13(obj, grasp):\n",
                "    \"\"\"v13: Pick with improved LIDAR correction\"\"\"\n",
                "    cx, cy = grasp['center']\n",
                "    grip_w = grasp['width_mm']\n",
                "    camera_angle = grasp['camera_angle']\n",
                "    \n",
                "    robot_r = ROBOT_R_OFFSET\n",
                "    gripper_x, gripper_y = robot.pixel_to_robot(cx, cy)\n",
                "    lidar_x = gripper_x + LIDAR_X_OFFSET\n",
                "    lidar_y = gripper_y + LIDAR_Y_OFFSET\n",
                "    \n",
                "    print(f\"\\nü§ñ Pick v13: W={grip_w:.1f}mm\")\n",
                "    print(f\"   Gripper: ({gripper_x:.1f}, {gripper_y:.1f})\")\n",
                "    print(f\"   LIDAR:   ({lidar_x:.1f}, {lidar_y:.1f})\")\n",
                "    \n",
                "    # 1. Safe position\n",
                "    print(\"üîÑ Safe position...\")\n",
                "    robot.joint_move_and_wait(0, 0, 0, 0, 1)\n",
                "    \n",
                "    # 2. Open gripper\n",
                "    gripper.open_for_object(GRIPPER_MAX_WIDTH_MM)\n",
                "    time.sleep(2)\n",
                "    \n",
                "    # 3. Move LIDAR above object\n",
                "    print(f\"üìè Moving LIDAR above object (Z={Z_MEASURE})...\")\n",
                "    robot.move_to_and_wait(lidar_x, lidar_y, Z_MEASURE, robot_r, 2)\n",
                "    time.sleep(2)\n",
                "    \n",
                "    # 4. Read LIDAR\n",
                "    lidar_dist = gripper.read_lidar(samples=100)\n",
                "    #time.sleep(4)\n",
                "    if lidar_dist is None:\n",
                "        print(\"‚ùå LIDAR read failed! Aborting.\")\n",
                "        robot.home()\n",
                "        return\n",
                "    \n",
                "    print(f\"üìè LIDAR raw: {lidar_dist} mm\")\n",
                "    \n",
                "    # 5. Calculate Z_GRASP with v13 corrections\n",
                "    z_base = Z_MEASURE - lidar_dist + LIDAR_PHYSICAL_OFFSET\n",
                "    print(f\"   z_base = {Z_MEASURE} - {lidar_dist} + {LIDAR_PHYSICAL_OFFSET} = {z_base:.1f}\")\n",
                "    \n",
                "    z_corrected = z_base + LIDAR_CORRECTION\n",
                "    print(f\"   + correction ({LIDAR_CORRECTION}) = {z_corrected:.1f}\")\n",
                "    \n",
                "    # Height-based correction\n",
                "    # Height-based correction (‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏™‡∏π‡∏á >= HEIGHT_THRESHOLD_MM ‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô)\n",
                "    object_height_from_floor = z_corrected - Z_FLOOR\n",
                "\n",
                "    if object_height_from_floor >= HEIGHT_THRESHOLD_MM:\n",
                "        height_correction = object_height_from_floor * HEIGHT_CORRECTION_FACTOR\n",
                "        z_grasp = z_corrected - height_correction\n",
                "        print(f\"   ‚úÖ Height={object_height_from_floor:.1f}mm >= {HEIGHT_THRESHOLD_MM}mm\")\n",
                "        print(f\"   + height correction ({height_correction:.1f}) = {z_grasp:.1f}\")\n",
                "    else:\n",
                "        z_grasp = z_corrected\n",
                "        print(f\"   ‚ùå Skip correction (height={object_height_from_floor:.1f}mm < {HEIGHT_THRESHOLD_MM}mm)\")\n",
                "        \n",
                "    z_grasp = max(Z_FLOOR, z_grasp)\n",
                "    print(f\"üìç Final Z_GRASP = {z_grasp:.1f}\")\n",
                "    \n",
                "    # 6. Move Gripper above object\n",
                "    print(\"üéØ Moving Gripper above object...\")\n",
                "    robot.move_to_and_wait(gripper_x, gripper_y, Z_MEASURE, robot_r, 2)\n",
                "    \n",
                "    # 7. Rotate first (at Z_MEASURE)\n",
                "    final_r = robot.camera_angle_to_robot_r(camera_angle)\n",
                "    print(f\"üîÑ Rotating to R={final_r:.1f}¬∞...\")\n",
                "    robot.move_to_and_wait(gripper_x, gripper_y, Z_MEASURE, final_r, 2)\n",
                "    \n",
                "    # 7.1 Then go down to grasp\n",
                "    print(f\"‚¨áÔ∏è Going down to Z={z_grasp:.1f}...\")\n",
                "    robot.move_to_and_wait(gripper_x, gripper_y, z_grasp, final_r, 2)\n",
                "    \n",
                "    # 8. Grip\n",
                "    gripper.grip_object(grip_w - 8.5)\n",
                "    time.sleep(4)\n",
                "    \n",
                "    # 9. Lift 50mm\n",
                "    z_lift = z_grasp + 50\n",
                "    print(f\"‚¨ÜÔ∏è Lifting to Z={z_lift:.1f}...\")\n",
                "    robot.move_to_and_wait(gripper_x, gripper_y, z_lift, final_r, 2)\n",
                "    \n",
                "    # 10. Go to drop\n",
                "    robot.move_to_and_wait(*DROP_POS[:3], DROP_POS[3], 3)\n",
                "    \n",
                "    # 11. Release\n",
                "    gripper.release()\n",
                "    time.sleep(2)\n",
                "    \n",
                "    # 12. Lift up first (at drop position)\n",
                "    drop_x, drop_y, drop_z, drop_r = DROP_POS\n",
                "    z_safe_up = 150  # ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏û‡∏≠\n",
                "    print(f\"‚¨ÜÔ∏è Lifting at drop position to Z={z_safe_up}...\")\n",
                "    robot.move_to_and_wait(drop_x, drop_y, z_safe_up, drop_r, 2)\n",
                "    \n",
                "    # 13. Move to Joint (0,0,0,0) - safe intermediate position\n",
                "    print(\"üîÑ Moving to safe position (0,0,0,0)...\")\n",
                "    robot.joint_move_and_wait(0, 0, 0, 0, 3)\n",
                "    \n",
                "    # 14. Home\n",
                "    robot.home()\n",
                "    print(\"‚úÖ Complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "üéØ PICK v13 (Improved Detection + LIDAR Correction)\n",
                        "Click=Select | SPACE=Execute | H=Home | C=Reconnect | Q=Quit\n",
                        "============================================================\n",
                        "\n",
                        "üì¶ Object: W=17.1mm\n",
                        "\n",
                        "ü§ñ Pick v13: W=17.1mm\n",
                        "   Gripper: (27.6, 3.4)\n",
                        "   LIDAR:   (52.7, 24.1)\n",
                        "üîÑ Safe position...\n",
                        "   ‚Üí JointMovJ(0,0,0,0)\n",
                        "ü¶æ Open: 54.0mm (22¬∞)\n",
                        "üìè Moving LIDAR above object (Z=120)...\n",
                        "   ‚Üí MovJ(52.726341114118725,24.122955685764357,120,-25.55)\n",
                        "üìè LIDAR raw: 220 mm\n",
                        "   z_base = 120 - 220 + 60 = -40.0\n",
                        "   + correction (-21) = -61.0\n",
                        "   ‚ùå Skip correction (height=3.0mm < 152mm)\n",
                        "üìç Final Z_GRASP = -61.0\n",
                        "üéØ Moving Gripper above object...\n",
                        "   ‚Üí MovJ(27.64634111411873,3.4129556857643566,120,-25.55)\n",
                        "üîÑ Rotating to R=-29.4¬∞...\n",
                        "   ‚Üí MovJ(27.64634111411873,3.4129556857643566,120,-29.42641684181965)\n",
                        "‚¨áÔ∏è Going down to Z=-61.0...\n",
                        "   ‚Üí MovJ(27.64634111411873,3.4129556857643566,-61,-29.42641684181965)\n",
                        "ü¶æ Grip: 3.6mm (89¬∞)\n",
                        "‚¨ÜÔ∏è Lifting to Z=-11.0...\n",
                        "   ‚Üí MovJ(27.64634111411873,3.4129556857643566,-11,-29.42641684181965)\n",
                        "   ‚Üí MovJ(169.71,58.01,-17.07,13.78)\n",
                        "‚¨ÜÔ∏è Lifting at drop position to Z=150...\n",
                        "   ‚Üí MovJ(169.71,58.01,150,13.78)\n",
                        "üîÑ Moving to safe position (0,0,0,0)...\n",
                        "   ‚Üí JointMovJ(0,0,0,0)\n",
                        "ü§ñ HOME...\n",
                        "‚úÖ Complete!\n",
                        "\n",
                        "üì¶ Object: W=50.2mm\n",
                        "\n",
                        "ü§ñ Pick v13: W=50.2mm\n",
                        "   Gripper: (5.2, 76.6)\n",
                        "   LIDAR:   (30.2, 97.3)\n",
                        "üîÑ Safe position...\n",
                        "   ‚Üí JointMovJ(0,0,0,0)\n",
                        "ü¶æ Open: 54.0mm (22¬∞)\n",
                        "üìè Moving LIDAR above object (Z=120)...\n",
                        "   ‚Üí MovJ(30.240955119870144,97.3062024938306,120,-25.55)\n",
                        "üìè LIDAR raw: 220 mm\n",
                        "   z_base = 120 - 220 + 60 = -40.0\n",
                        "   + correction (-21) = -61.0\n",
                        "   ‚ùå Skip correction (height=3.0mm < 152mm)\n",
                        "üìç Final Z_GRASP = -61.0\n",
                        "üéØ Moving Gripper above object...\n",
                        "   ‚Üí MovJ(5.160955119870147,76.59620249383059,120,-25.55)\n",
                        "üîÑ Rotating to R=58.2¬∞...\n",
                        "   ‚Üí MovJ(5.160955119870147,76.59620249383059,120,58.174198429832586)\n",
                        "‚¨áÔ∏è Going down to Z=-61.0...\n",
                        "   ‚Üí MovJ(5.160955119870147,76.59620249383059,-61,58.174198429832586)\n",
                        "ü¶æ Grip: 36.7mm (54¬∞)\n",
                        "‚¨ÜÔ∏è Lifting to Z=-11.0...\n",
                        "   ‚Üí MovJ(5.160955119870147,76.59620249383059,-11,58.174198429832586)\n",
                        "   ‚Üí MovJ(169.71,58.01,-17.07,13.78)\n",
                        "‚¨ÜÔ∏è Lifting at drop position to Z=150...\n",
                        "   ‚Üí MovJ(169.71,58.01,150,13.78)\n",
                        "üîÑ Moving to safe position (0,0,0,0)...\n",
                        "   ‚Üí JointMovJ(0,0,0,0)\n",
                        "ü§ñ HOME...\n",
                        "‚úÖ Complete!\n",
                        "\n",
                        "üì¶ Object: W=31.2mm\n",
                        "\n",
                        "ü§ñ Pick v13: W=31.2mm\n",
                        "   Gripper: (47.6, 40.6)\n",
                        "   LIDAR:   (72.7, 61.4)\n",
                        "üîÑ Safe position...\n",
                        "   ‚Üí JointMovJ(0,0,0,0)\n",
                        "ü¶æ Open: 54.0mm (22¬∞)\n",
                        "üìè Moving LIDAR above object (Z=120)...\n",
                        "   ‚Üí MovJ(72.68686924841592,61.35497559858993,120,-25.55)\n",
                        "üìè LIDAR raw: 200 mm\n",
                        "   z_base = 120 - 200 + 60 = -20.0\n",
                        "   + correction (-21) = -41.0\n",
                        "   ‚ùå Skip correction (height=23.0mm < 152mm)\n",
                        "üìç Final Z_GRASP = -41.0\n",
                        "üéØ Moving Gripper above object...\n",
                        "   ‚Üí MovJ(47.60686924841591,40.64497559858993,120,-25.55)\n",
                        "üîÑ Rotating to R=-27.6¬∞...\n",
                        "   ‚Üí MovJ(47.60686924841591,40.64497559858993,120,-27.568333837906923)\n",
                        "‚¨áÔ∏è Going down to Z=-41.0...\n",
                        "   ‚Üí MovJ(47.60686924841591,40.64497559858993,-41,-27.568333837906923)\n",
                        "ü¶æ Grip: 17.7mm (75¬∞)\n",
                        "‚¨ÜÔ∏è Lifting to Z=9.0...\n",
                        "   ‚Üí MovJ(47.60686924841591,40.64497559858993,9,-27.568333837906923)\n",
                        "   ‚Üí MovJ(169.71,58.01,-17.07,13.78)\n",
                        "‚¨ÜÔ∏è Lifting at drop position to Z=150...\n",
                        "   ‚Üí MovJ(169.71,58.01,150,13.78)\n",
                        "üîÑ Moving to safe position (0,0,0,0)...\n",
                        "   ‚Üí JointMovJ(0,0,0,0)\n",
                        "ü§ñ HOME...\n",
                        "‚úÖ Complete!\n"
                    ]
                }
            ],
            "source": [
                "# Main loop\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Pick v13')\n",
                "cv2.setMouseCallback('Pick v13', mouse_callback)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üéØ PICK v13 (Improved Detection + LIDAR Correction)\")\n",
                "print(\"Click=Select | SPACE=Execute | H=Home | C=Reconnect | Q=Quit\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    \n",
                "    detected_objects = detector.detect(frame)\n",
                "    \n",
                "    display = frame.copy()\n",
                "    for obj in detected_objects:\n",
                "        x, y, w, h = obj['bbox']\n",
                "        is_sel = (selected_object and obj['center'] == selected_object['center'])\n",
                "        color = (0, 0, 255) if is_sel else (0, 255, 0)\n",
                "        cv2.rectangle(display, (x, y), (x+w, y+h), color, 2)\n",
                "        cv2.putText(display, obj.get('method', ''), (x, y-5), \n",
                "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
                "    \n",
                "    if selected_object and current_grasps:\n",
                "        draw_grasps(display, current_grasps, selected_grasp)\n",
                "    \n",
                "    cv2.rectangle(display, (0, 0), (640, 35), (30, 30, 30), -1)\n",
                "    cv2.putText(display, f\"v13 | Obj:{len(detected_objects)} | SPACE | H | Q\",\n",
                "               (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 1)\n",
                "    \n",
                "    if selected_grasp:\n",
                "        cv2.putText(display, f\"[W={selected_grasp['width_mm']:.1f}mm - SPACE]\",\n",
                "                   (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
                "    \n",
                "    cv2.imshow('Pick v13', display)\n",
                "    \n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == ord('r'):\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "    elif key == ord('h'):\n",
                "        robot.home()\n",
                "    elif key == ord(' ') and selected_object and selected_grasp:\n",
                "        pick_with_lidar_v13(selected_object, selected_grasp)\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "    elif key == ord('c'):\n",
                "        # Reconnect all (clear error)\n",
                "        print(\"\\nüîÑ Reconnecting...\")\n",
                "        \n",
                "        # 1. Reconnect gripper+LIDAR\n",
                "        try:\n",
                "            gripper.disconnect()\n",
                "        except:\n",
                "            pass\n",
                "        time.sleep(1)\n",
                "        gripper.connect()\n",
                "        \n",
                "        # 2. Reconnect robot\n",
                "        try:\n",
                "            robot.sock.close()\n",
                "        except:\n",
                "            pass\n",
                "        time.sleep(1)\n",
                "        robot.connect(ROBOT_IP)\n",
                "        \n",
                "        # 3. Home\n",
                "        robot.home()\n",
                "        \n",
                "        # 4. Reset selection\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "        \n",
                "        print(\"‚úÖ Reconnected! Ready to continue.\")\n",
                "\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()\n",
                "gripper.disconnect()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
