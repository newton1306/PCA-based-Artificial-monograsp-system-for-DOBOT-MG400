{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¯ Hybrid Grasp Detection v10\n",
                "\n",
                "## New in v10\n",
                "| Feature | Description |\n",
                "|---------|-------------|\n",
                "| **ðŸ§  Depth-Enhanced Scoring** | à¹ƒà¸Šà¹‰ Depth à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸šà¸ªà¸³à¸«à¸£à¸±à¸š quality scoring |\n",
                "| **ðŸŽ¨ Depth Segmentation** | à¹à¸¢à¸à¸§à¸±à¸•à¸–à¸¸à¸”à¹‰à¸§à¸¢ depth map |\n",
                "| **ðŸ“Š Quality Heatmap** | à¹à¸ªà¸”à¸‡ grasp quality overlay |\n",
                "| **ðŸ”¬ Hybrid PCA+Depth** | à¸£à¸§à¸¡ PCA geometry à¸à¸±à¸š depth features |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1ï¸âƒ£ Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch: 2.9.1+cpu\n",
                        "CUDA: False\n",
                        "âœ“ Imports\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import cv2\n",
                "import numpy as np\n",
                "import time\n",
                "import socket\n",
                "import serial\n",
                "import torch\n",
                "from collections import deque\n",
                "from ultralytics import YOLO\n",
                "from scipy import ndimage\n",
                "\n",
                "sys.path.append('Depth-Anything-V2')\n",
                "\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "print(\"âœ“ Imports\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2ï¸âƒ£ Hardware Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Hardware config\n"
                    ]
                }
            ],
            "source": [
                "ROBOT_IP = '192.168.1.6'\n",
                "ESP32_PORT = 'COM9'\n",
                "ESP32_BAUDRATE = 115200\n",
                "CAMERA_ID = 2\n",
                "\"\"\"\n",
                "HOMOGRAPHY_MATRIX = np.array([\n",
                "    [0.005703976266962427, -0.3265299161278153, 88.58634169557483],\n",
                "    [-0.47704058225560797, 0.015355046930804153, 172.0941543570439],\n",
                "    [-0.00029949919510557677, 0.00018728182448344945, 1.0],\n",
                "], dtype=np.float32)\"\"\"\n",
                "\n",
                "HOMOGRAPHY_MATRIX = np.load('homography_matrix.npy')\n",
                "\n",
                "print(\"âœ“ Hardware config\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3ï¸âƒ£ Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Configuration (v10 with Depth-Enhanced Scoring)\n"
                    ]
                }
            ],
            "source": [
                "# === CALIBRATED VALUES ===\n",
                "PIXELS_PER_MM = 2.7703\n",
                "DEPTH_Z_SCALE = 45.3800\n",
                "CAMERA_HEIGHT_MM = 630\n",
                "\n",
                "# === Robot R Rotation ===\n",
                "ROBOT_R_OFFSET = -25.55\n",
                "\n",
                "# === Z Heights ===\n",
                "Z_FLOOR = -64\n",
                "Z_SAFE = -40\n",
                "Z_APPROACH = -55\n",
                "\n",
                "# === Drop Position ===\n",
                "DROP_POS = (-253.07, 115.17, -17.07, -62.78)\n",
                "\n",
                "# === Gripper ===\n",
                "GRIPPER_SERVO_OPEN_ANGLE = 22\n",
                "GRIPPER_SERVO_CLOSE_ANGLE = 96\n",
                "GRIPPER_MAX_WIDTH_MM = 54\n",
                "GRIPPER_MIN_WIDTH_MM = 0\n",
                "GRIPPER_OPEN_MARGIN_MM = 5\n",
                "GRIPPER_GRIP_MARGIN_MM = 5\n",
                "\n",
                "# === Detection ===\n",
                "MIN_OBJECT_AREA = 1000\n",
                "YOLO_CONFIDENCE = 0.25\n",
                "\n",
                "# === Depth Model ===\n",
                "DEPTH_MODEL_PATH = 'Depth-Anything-V2/checkpoints/depth_anything_v2_vits.pth'\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "# === v10: Depth Quality Scoring ===\n",
                "DEPTH_EDGE_WEIGHT = 0.3      # à¸™à¹‰à¸³à¸«à¸™à¸±à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸‚à¸­à¸šà¸§à¸±à¸•à¸–à¸¸à¸Šà¸±à¸”à¹€à¸ˆà¸™\n",
                "DEPTH_CENTER_WEIGHT = 0.4    # à¸™à¹‰à¸³à¸«à¸™à¸±à¸à¸ªà¸³à¸«à¸£à¸±à¸š grasp à¸—à¸µà¹ˆà¸à¸¥à¸²à¸‡à¸§à¸±à¸•à¸–à¸¸\n",
                "DEPTH_FLATNESS_WEIGHT = 0.3  # à¸™à¹‰à¸³à¸«à¸™à¸±à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸žà¸·à¹‰à¸™à¸œà¸´à¸§à¹€à¸£à¸µà¸¢à¸š\n",
                "\n",
                "# === Grid Display ===\n",
                "SHOW_FRAME_GRID = False\n",
                "SHOW_OBJECT_GRID = True\n",
                "SHOW_DEPTH_OVERLAY = True\n",
                "FRAME_GRID_SIZE_MM = 20\n",
                "OBJECT_GRID_SIZE_MM = 5\n",
                "\n",
                "print(\"âœ“ Configuration (v10 with Depth-Enhanced Scoring)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4ï¸âƒ£ Load Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "xFormers not available\n",
                        "xFormers not available\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading DepthAnything V2...\n",
                        "âœ… Depth model on cpu\n",
                        "Loading YOLOv8...\n",
                        "âœ… YOLO loaded\n"
                    ]
                }
            ],
            "source": [
                "from depth_anything_v2.dpt import DepthAnythingV2\n",
                "\n",
                "model_configs = {\n",
                "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
                "}\n",
                "\n",
                "print(\"Loading DepthAnything V2...\")\n",
                "depth_model = DepthAnythingV2(**model_configs['vits'])\n",
                "depth_model.load_state_dict(torch.load(DEPTH_MODEL_PATH, map_location='cpu', weights_only=True))\n",
                "depth_model = depth_model.to(DEVICE).eval()\n",
                "print(f\"âœ… Depth model on {DEVICE}\")\n",
                "\n",
                "print(\"Loading YOLOv8...\")\n",
                "yolo_model = YOLO('yolov8n.pt')\n",
                "print(\"âœ… YOLO loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5ï¸âƒ£ Classes Definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Gripper class\n"
                    ]
                }
            ],
            "source": [
                "class SmartGripperController:\n",
                "    CALIB_ANGLES = np.array([22, 30, 40, 50, 60, 70, 80, 90, 96])\n",
                "    CALIB_WIDTHS = np.array([54.0, 52.0, 48.0, 40.0, 32.0, 23.0, 12.0, 3.0, 0.0])\n",
                "    \n",
                "    def __init__(self, port='COM9', baudrate=115200):\n",
                "        self.port = port\n",
                "        self.baudrate = baudrate\n",
                "        self.serial = None\n",
                "        self.target_width = None\n",
                "        \n",
                "    def connect(self):\n",
                "        try:\n",
                "            self.serial = serial.Serial(self.port, self.baudrate, timeout=2)\n",
                "            time.sleep(2)\n",
                "            print(f\"âœ… Gripper on {self.port}\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"âŒ {e}\")\n",
                "            return False\n",
                "    \n",
                "    def disconnect(self):\n",
                "        if self.serial: self.serial.close()\n",
                "    \n",
                "    def send_command(self, cmd):\n",
                "        if self.serial:\n",
                "            self.serial.write((cmd + '\\n').encode())\n",
                "            time.sleep(0.3)\n",
                "    \n",
                "    def mm_to_angle(self, width_mm):\n",
                "        width = max(0.0, min(54.0, width_mm))\n",
                "        return int(round(np.interp(width, self.CALIB_WIDTHS[::-1], self.CALIB_ANGLES[::-1])))\n",
                "    \n",
                "    def open_for_object(self, width_mm):\n",
                "        self.target_width = width_mm\n",
                "        open_w = min(54.0, width_mm + GRIPPER_OPEN_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(open_w)\n",
                "        print(f\"ðŸ¦¾ Open: {open_w:.1f}mm ({angle}Â°)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def grip_object(self, width_mm):\n",
                "        grip_w = max(0.0, width_mm - GRIPPER_GRIP_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(grip_w)\n",
                "        print(f\"ðŸ¦¾ Grip: {width_mm:.1f}mm - {GRIPPER_GRIP_MARGIN_MM}mm = {grip_w:.1f}mm ({angle}Â°)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def release(self):\n",
                "        open_w = min(54.0, (self.target_width or 30) + 10)\n",
                "        self.send_command(f'G{self.mm_to_angle(open_w)}')\n",
                "        self.target_width = None\n",
                "\n",
                "print(\"âœ“ Gripper class\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Robot class\n"
                    ]
                }
            ],
            "source": [
                "class DobotControllerTCP:\n",
                "    def __init__(self, homography_matrix=None, r_offset=-25.55):\n",
                "        self.dashboard_port = 29999\n",
                "        self.sock = None\n",
                "        self.H = homography_matrix\n",
                "        self.r_offset = r_offset\n",
                "        \n",
                "    def connect(self, ip):\n",
                "        try:\n",
                "            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
                "            self.sock.settimeout(5)\n",
                "            self.sock.connect((ip, self.dashboard_port))\n",
                "            self.send_command(\"ClearError()\")\n",
                "            time.sleep(0.5)\n",
                "            self.send_command(\"EnableRobot()\")\n",
                "            time.sleep(4)\n",
                "            self.send_command(\"User(1)\")\n",
                "            self.send_command(\"Tool(1)\")\n",
                "            self.send_command(\"SpeedFactor(50)\")\n",
                "            print(\"âœ… Robot connected!\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"Error: {e}\")\n",
                "            return False\n",
                "\n",
                "    def send_command(self, cmd):\n",
                "        if self.sock:\n",
                "            self.sock.send((cmd + \"\\n\").encode(\"utf-8\"))\n",
                "            return self.sock.recv(1024).decode(\"utf-8\")\n",
                "\n",
                "    def home(self):\n",
                "        print(\"ðŸ¤– HOME...\")\n",
                "        self.send_command(\"MovJ(-253.07, 115.17, -17.07, -62.78)\")\n",
                "        time.sleep(4)\n",
                "\n",
                "    def move_to(self, x, y, z, r=0):\n",
                "        cmd = f\"MovJ({x},{y},{z},{r})\"\n",
                "        print(f\"   â†’ {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def move_to_and_wait(self, x, y, z, r=0, wait=3):\n",
                "        self.move_to(x, y, z, r)\n",
                "        time.sleep(wait)\n",
                "    \n",
                "    def joint_move(self, j1=0, j2=0, j3=0, j4=0):\n",
                "        cmd = f\"JointMovJ({j1},{j2},{j3},{j4})\"\n",
                "        print(f\"   â†’ {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def joint_move_and_wait(self, j1=0, j2=0, j3=0, j4=0, wait=3):\n",
                "        self.joint_move(j1, j2, j3, j4)\n",
                "        time.sleep(wait)\n",
                "\n",
                "    def pixel_to_robot(self, u, v):\n",
                "        if self.H is None: return None, None\n",
                "        pt = np.array([u, v, 1], dtype=np.float32)\n",
                "        res = np.dot(self.H, pt)\n",
                "        return res[0]/res[2], res[1]/res[2]\n",
                "    \n",
                "    def camera_angle_to_robot_r(self, camera_angle):\n",
                "        return self.r_offset - camera_angle\n",
                "\n",
                "print(\"âœ“ Robot class\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Depth-Enhanced Detector class\n"
                    ]
                }
            ],
            "source": [
                "class DepthEnhancedDetector:\n",
                "    \"\"\"v10: YOLO + Contour + Depth Segmentation\"\"\"\n",
                "    \n",
                "    def __init__(self, yolo_model, depth_model, pixels_per_mm, device='cpu'):\n",
                "        self.yolo = yolo_model\n",
                "        self.depth_model = depth_model\n",
                "        self.ppm = pixels_per_mm\n",
                "        self.device = device\n",
                "        self.current_depth = None\n",
                "        self.floor_depth = None\n",
                "    \n",
                "    def update_depth(self, frame):\n",
                "        self.current_depth = self.depth_model.infer_image(frame)\n",
                "        return self.current_depth\n",
                "    \n",
                "    def calibrate_floor(self, frame):\n",
                "        depth = self.update_depth(frame)\n",
                "        h, w = depth.shape\n",
                "        self.floor_depth = np.median(depth[h//3:2*h//3, w//3:2*w//3])\n",
                "        print(f\"âœ… Floor depth: {self.floor_depth:.4f}\")\n",
                "        return self.floor_depth\n",
                "    \n",
                "    def detect(self, frame):\n",
                "        objects = []\n",
                "        results = self.yolo(frame, conf=YOLO_CONFIDENCE, verbose=False)\n",
                "        \n",
                "        for r in results:\n",
                "            for box in r.boxes:\n",
                "                x1,y1,x2,y2 = map(int, box.xyxy[0])\n",
                "                conf = float(box.conf[0])\n",
                "                \n",
                "                roi = frame[y1:y2, x1:x2]\n",
                "                if roi.size == 0: continue\n",
                "                \n",
                "                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
                "                _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
                "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "                \n",
                "                if contours:\n",
                "                    cnt = max(contours, key=cv2.contourArea)\n",
                "                    cnt = cnt + np.array([x1, y1])\n",
                "                    rect = cv2.minAreaRect(cnt)\n",
                "                    cx, cy = int(rect[0][0]), int(rect[0][1])\n",
                "                    \n",
                "                    # v10: Get depth features\n",
                "                    depth_info = self._get_depth_features(x1, y1, x2-x1, y2-y1)\n",
                "                    \n",
                "                    objects.append({\n",
                "                        'bbox': (x1, y1, x2-x1, y2-y1),\n",
                "                        'center': (cx, cy),\n",
                "                        'rect': rect,\n",
                "                        'rect_size': rect[1],\n",
                "                        'rect_angle': rect[2],\n",
                "                        'contour': cnt,\n",
                "                        'conf': conf,\n",
                "                        'area': cv2.contourArea(cnt),\n",
                "                        'depth_info': depth_info\n",
                "                    })\n",
                "        \n",
                "        if not objects:\n",
                "            objects = self._edge_detect_with_depth(frame)\n",
                "        \n",
                "        return objects\n",
                "    \n",
                "    def _get_depth_features(self, x, y, w, h):\n",
                "        if self.current_depth is None or self.floor_depth is None:\n",
                "            return {'height': 0, 'flatness': 0, 'edge_clarity': 0}\n",
                "        \n",
                "        # Resize depth to match frame if needed\n",
                "        dh, dw = self.current_depth.shape\n",
                "        fh, fw = 480, 640  # Assumed frame size\n",
                "        scale_x, scale_y = dw/fw, dh/fh\n",
                "        \n",
                "        dx, dy = int(x*scale_x), int(y*scale_y)\n",
                "        dw2, dh2 = int(w*scale_x), int(h*scale_y)\n",
                "        \n",
                "        region = self.current_depth[dy:dy+dh2, dx:dx+dw2]\n",
                "        if region.size == 0:\n",
                "            return {'height': 0, 'flatness': 0, 'edge_clarity': 0}\n",
                "        \n",
                "        # Height from floor\n",
                "        height = max(0, (np.median(region) - self.floor_depth) * DEPTH_Z_SCALE)\n",
                "        \n",
                "        # Flatness (inverse of std dev)\n",
                "        flatness = 1.0 / (1.0 + np.std(region))\n",
                "        \n",
                "        # Edge clarity (gradient magnitude)\n",
                "        if region.shape[0] > 2 and region.shape[1] > 2:\n",
                "            gx = cv2.Sobel(region.astype(np.float32), cv2.CV_32F, 1, 0, ksize=3)\n",
                "            gy = cv2.Sobel(region.astype(np.float32), cv2.CV_32F, 0, 1, ksize=3)\n",
                "            edge_mag = np.sqrt(gx**2 + gy**2)\n",
                "            edge_clarity = np.mean(edge_mag)\n",
                "        else:\n",
                "            edge_clarity = 0\n",
                "        \n",
                "        return {'height': height, 'flatness': flatness, 'edge_clarity': edge_clarity}\n",
                "    \n",
                "    def _edge_detect_with_depth(self, frame):\n",
                "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
                "        edges = cv2.Canny(cv2.GaussianBlur(gray, (5,5), 0), 50, 150)\n",
                "        edges = cv2.dilate(edges, np.ones((3,3), np.uint8), iterations=2)\n",
                "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "        \n",
                "        objects = []\n",
                "        for cnt in contours:\n",
                "            area = cv2.contourArea(cnt)\n",
                "            if area > MIN_OBJECT_AREA:\n",
                "                hull = cv2.convexHull(cnt)\n",
                "                rect = cv2.minAreaRect(hull)\n",
                "                x,y,w,h = cv2.boundingRect(hull)\n",
                "                depth_info = self._get_depth_features(x, y, w, h)\n",
                "                objects.append({\n",
                "                    'bbox': (x,y,w,h),\n",
                "                    'center': (x+w//2, y+h//2),\n",
                "                    'rect': rect,\n",
                "                    'rect_size': rect[1],\n",
                "                    'rect_angle': rect[2],\n",
                "                    'contour': hull,\n",
                "                    'area': area,\n",
                "                    'depth_info': depth_info\n",
                "                })\n",
                "        return sorted(objects, key=lambda o: o['area'], reverse=True)\n",
                "    \n",
                "    def get_depth_colormap(self, alpha=0.3):\n",
                "        if self.current_depth is None:\n",
                "            return None\n",
                "        depth_norm = cv2.normalize(self.current_depth, None, 0, 255, cv2.NORM_MINMAX)\n",
                "        depth_color = cv2.applyColorMap(depth_norm.astype(np.uint8), cv2.COLORMAP_JET)\n",
                "        return depth_color\n",
                "\n",
                "print(\"âœ“ Depth-Enhanced Detector class\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Hybrid Grasp Selector (v10)\n"
                    ]
                }
            ],
            "source": [
                "class HybridGraspSelector:\n",
                "    \"\"\"v10: PCA + Depth-Enhanced Quality Scoring\"\"\"\n",
                "    \n",
                "    def __init__(self, pixels_per_mm):\n",
                "        self.ppm = pixels_per_mm\n",
                "    \n",
                "    def analyze_object(self, obj, depth_map=None, floor_depth=None):\n",
                "        \"\"\"à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸§à¸±à¸•à¸–à¸¸à¸”à¹‰à¸§à¸¢ PCA + Depth Quality Scoring\"\"\"\n",
                "        cnt = obj.get('contour')\n",
                "        if cnt is None or len(cnt) < 5:\n",
                "            return self._fallback_analysis(obj)\n",
                "        \n",
                "        # PCA Analysis\n",
                "        pts = cnt.reshape(-1, 2).astype(np.float64)\n",
                "        mean = np.mean(pts, axis=0)\n",
                "        pts_centered = pts - mean\n",
                "        \n",
                "        cov = np.cov(pts_centered.T)\n",
                "        eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
                "        \n",
                "        idx = np.argsort(eigenvalues)[::-1]\n",
                "        eigenvalues = eigenvalues[idx]\n",
                "        eigenvectors = eigenvectors[:, idx]\n",
                "        \n",
                "        major_axis = eigenvectors[:, 0]\n",
                "        minor_axis = eigenvectors[:, 1]\n",
                "        \n",
                "        angle_major = np.degrees(np.arctan2(major_axis[1], major_axis[0]))\n",
                "        \n",
                "        projections = np.dot(pts_centered, minor_axis)\n",
                "        width_px = np.max(projections) - np.min(projections)\n",
                "        width_mm = width_px / self.ppm\n",
                "        \n",
                "        proj_major = np.dot(pts_centered, major_axis)\n",
                "        length_px = np.max(proj_major) - np.min(proj_major)\n",
                "        length_mm = length_px / self.ppm\n",
                "        \n",
                "        cx, cy = int(mean[0]), int(mean[1])\n",
                "        grasp_camera_angle = self._normalize_angle(angle_major + 90)\n",
                "        \n",
                "        # v10: Calculate depth-enhanced quality score\n",
                "        depth_info = obj.get('depth_info', {})\n",
                "        depth_quality = self._calculate_depth_quality(depth_info, depth_map, cx, cy, floor_depth)\n",
                "        \n",
                "        grasps = []\n",
                "        \n",
                "        # Primary: Narrow side grasp\n",
                "        if width_mm <= GRIPPER_MAX_WIDTH_MM:\n",
                "            base_score = 1.0\n",
                "            final_score = base_score * 0.5 + depth_quality * 0.5\n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': width_mm,\n",
                "                'camera_angle': grasp_camera_angle,\n",
                "                'score': final_score,\n",
                "                'depth_score': depth_quality,\n",
                "                'type': 'PCA_narrow',\n",
                "                'axis_info': {'major': major_axis, 'minor': minor_axis}\n",
                "            })\n",
                "        \n",
                "        # Alternative: Long side grasp\n",
                "        if length_mm <= GRIPPER_MAX_WIDTH_MM:\n",
                "            base_score = 0.5\n",
                "            final_score = base_score * 0.5 + depth_quality * 0.5\n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': length_mm,\n",
                "                'camera_angle': self._normalize_angle(angle_major),\n",
                "                'score': final_score,\n",
                "                'depth_score': depth_quality,\n",
                "                'type': 'PCA_long',\n",
                "                'axis_info': None\n",
                "            })\n",
                "        \n",
                "        if not grasps:\n",
                "            return self._fallback_analysis(obj)\n",
                "        \n",
                "        return sorted(grasps, key=lambda g: g['score'], reverse=True)\n",
                "    \n",
                "    def _calculate_depth_quality(self, depth_info, depth_map, cx, cy, floor_depth):\n",
                "        \"\"\"Calculate quality score based on depth features\"\"\"\n",
                "        if not depth_info:\n",
                "            return 0.5\n",
                "        \n",
                "        flatness = depth_info.get('flatness', 0.5)\n",
                "        edge_clarity = min(1.0, depth_info.get('edge_clarity', 0) / 10.0)\n",
                "        height = depth_info.get('height', 0)\n",
                "        \n",
                "        # Higher objects are usually easier to grasp\n",
                "        height_score = min(1.0, height / 50.0) if height > 5 else 0.3\n",
                "        \n",
                "        # Center accessibility from depth map\n",
                "        center_score = 0.5\n",
                "        if depth_map is not None and floor_depth is not None:\n",
                "            h, w = depth_map.shape\n",
                "            if 0 <= cy < h and 0 <= cx < w:\n",
                "                local_depth = depth_map[max(0,cy-5):min(h,cy+5), max(0,cx-5):min(w,cx+5)]\n",
                "                if local_depth.size > 0:\n",
                "                    center_height = (np.median(local_depth) - floor_depth) * DEPTH_Z_SCALE\n",
                "                    center_score = min(1.0, max(0.3, center_height / 50.0))\n",
                "        \n",
                "        quality = (\n",
                "            DEPTH_EDGE_WEIGHT * edge_clarity +\n",
                "            DEPTH_CENTER_WEIGHT * center_score +\n",
                "            DEPTH_FLATNESS_WEIGHT * flatness\n",
                "        )\n",
                "        \n",
                "        return min(1.0, max(0.0, quality))\n",
                "    \n",
                "    def _fallback_analysis(self, obj):\n",
                "        rect = obj.get('rect')\n",
                "        if rect is None:\n",
                "            return []\n",
                "        \n",
                "        (cx, cy), (w, h), angle = rect\n",
                "        cx, cy = int(cx), int(cy)\n",
                "        \n",
                "        if w < h:\n",
                "            grip_w = w / self.ppm\n",
                "            grip_a = angle + 90\n",
                "        else:\n",
                "            grip_w = h / self.ppm\n",
                "            grip_a = angle\n",
                "        \n",
                "        grasps = []\n",
                "        if grip_w <= GRIPPER_MAX_WIDTH_MM:\n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': grip_w,\n",
                "                'camera_angle': self._normalize_angle(grip_a),\n",
                "                'score': 0.6,\n",
                "                'depth_score': 0.5,\n",
                "                'type': 'rect_fallback',\n",
                "                'axis_info': None\n",
                "            })\n",
                "        \n",
                "        return grasps\n",
                "    \n",
                "    def _normalize_angle(self, angle):\n",
                "        while angle > 90: angle -= 180\n",
                "        while angle < -90: angle += 180\n",
                "        return angle\n",
                "\n",
                "print(\"âœ“ Hybrid Grasp Selector (v10)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6ï¸âƒ£ Initialize Components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Components initialized (v10 Hybrid)\n"
                    ]
                }
            ],
            "source": [
                "gripper = SmartGripperController(port=ESP32_PORT, baudrate=ESP32_BAUDRATE)\n",
                "robot = DobotControllerTCP(homography_matrix=HOMOGRAPHY_MATRIX, r_offset=ROBOT_R_OFFSET)\n",
                "detector = DepthEnhancedDetector(yolo_model, depth_model, PIXELS_PER_MM, device=DEVICE)\n",
                "grasp_selector = HybridGraspSelector(PIXELS_PER_MM)\n",
                "print(\"âœ“ Components initialized (v10 Hybrid)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# ðŸ§ª TEST GRASP MODEL (No Robot)\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "ðŸ§ª TEST GRASP MODEL (No Robot Connection)\n",
                        "   Click=Select Object | D=Toggle Depth | Q=Quit\n",
                        "============================================================\n",
                        "\n",
                        "ðŸ“· Press SPACE to calibrate floor...\n",
                        "Skipped calibration\n",
                        "\n",
                        "âœ… Test complete\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"ðŸ§ª TEST GRASP MODEL (No Robot Connection)\")\n",
                "print(\"   Click=Select Object | D=Toggle Depth | Q=Quit\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "test_selected = None\n",
                "test_grasps = []\n",
                "show_depth = True\n",
                "\n",
                "def test_mouse_cb(event, x, y, flags, param):\n",
                "    global test_selected, test_grasps\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        for obj in param.get('objects', []):\n",
                "            bx,by,bw,bh = obj['bbox']\n",
                "            if bx <= x <= bx+bw and by <= y <= by+bh:\n",
                "                test_selected = obj\n",
                "                test_grasps = grasp_selector.analyze_object(\n",
                "                    obj, \n",
                "                    detector.current_depth, \n",
                "                    detector.floor_depth\n",
                "                )\n",
                "                if test_grasps:\n",
                "                    g = test_grasps[0]\n",
                "                    print(f\"\\nðŸ“¦ Selected: W={g['width_mm']:.1f}mm Angle={g['camera_angle']:.1f}Â°\")\n",
                "                    print(f\"   Score: {g['score']:.2f} (Depth: {g['depth_score']:.2f})\")\n",
                "                    print(f\"   Type: {g['type']}\")\n",
                "                break\n",
                "\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "#cap = cv2.VideoCapture(1)\n",
                "cv2.namedWindow('Test v10')\n",
                "callback_data = {'objects': []}\n",
                "cv2.setMouseCallback('Test v10', test_mouse_cb, callback_data)\n",
                "\n",
                "# Calibrate floor first\n",
                "print(\"\\nðŸ“· Press SPACE to calibrate floor...\")\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    cv2.putText(frame, \"SPACE=Calibrate Floor | Q=Skip\", (10, 30), \n",
                "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
                "    cv2.imshow('Test v10', frame)\n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord(' '):\n",
                "        detector.calibrate_floor(frame)\n",
                "        break\n",
                "    elif key == ord('q'):\n",
                "        print(\"Skipped calibration\")\n",
                "        break\n",
                "\n",
                "frame_count = 0\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    \n",
                "    frame_count += 1\n",
                "    if frame_count % 5 == 0:\n",
                "        detector.update_depth(frame)\n",
                "    \n",
                "    detected = detector.detect(frame)\n",
                "    callback_data['objects'] = detected\n",
                "    \n",
                "    display = frame.copy()\n",
                "    \n",
                "    # Depth overlay\n",
                "    if show_depth and detector.current_depth is not None:\n",
                "        depth_color = detector.get_depth_colormap()\n",
                "        if depth_color is not None:\n",
                "            depth_resized = cv2.resize(depth_color, (frame.shape[1], frame.shape[0]))\n",
                "            display = cv2.addWeighted(display, 0.7, depth_resized, 0.3, 0)\n",
                "    \n",
                "    # Draw objects\n",
                "    for obj in detected:\n",
                "        x,y,w,h = obj['bbox']\n",
                "        is_sel = test_selected and obj['center'] == test_selected['center']\n",
                "        color = (0,0,255) if is_sel else (0,255,0)\n",
                "        cv2.rectangle(display, (x,y), (x+w,y+h), color, 2)\n",
                "        \n",
                "        # Show depth info\n",
                "        d_info = obj.get('depth_info', {})\n",
                "        h_mm = d_info.get('height', 0)\n",
                "        cv2.putText(display, f\"H:{h_mm:.0f}mm\", (x, y-5), \n",
                "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
                "    \n",
                "    # Draw grasps\n",
                "    if test_selected and test_grasps:\n",
                "        for i, g in enumerate(test_grasps):\n",
                "            cx, cy = g['center']\n",
                "            angle = g['camera_angle']\n",
                "            is_best = (i == 0)\n",
                "            color = (0,0,255) if is_best else (0,255,255)\n",
                "            thick = 3 if is_best else 2\n",
                "            \n",
                "            length = 40\n",
                "            dx = int(length * np.cos(np.radians(angle)))\n",
                "            dy = int(length * np.sin(np.radians(angle)))\n",
                "            cv2.line(display, (cx-dx, cy-dy), (cx+dx, cy+dy), color, thick)\n",
                "            cv2.circle(display, (cx, cy), 5, color, -1)\n",
                "            \n",
                "            # Quality bar\n",
                "            bar_len = int(g['score'] * 50)\n",
                "            cv2.rectangle(display, (cx+15, cy-5), (cx+15+bar_len, cy+5), color, -1)\n",
                "            cv2.putText(display, f\"{g['score']:.2f}\", (cx+70, cy+5), \n",
                "                        cv2.FONT_HERSHEY_SIMPLEX, 0.35, color, 1)\n",
                "    \n",
                "    # Status bar\n",
                "    cv2.rectangle(display, (0,0), (640,35), (30,30,30), -1)\n",
                "    status = f\"v10 TEST | Obj:{len(detected)} | D=Depth:{show_depth} | Click | Q\"\n",
                "    cv2.putText(display, status, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1)\n",
                "    \n",
                "    cv2.imshow('Test v10', display)\n",
                "    \n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == ord('d'):\n",
                "        show_depth = not show_depth\n",
                "        print(f\"Depth overlay: {show_depth}\")\n",
                "    elif key == ord('r'):\n",
                "        test_selected = None\n",
                "        test_grasps = []\n",
                "\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()\n",
                "print(\"\\nâœ… Test complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# ðŸ¤– Connect Hardware (When Ready)\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Gripper on COM9\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "gripper.connect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Robot connected!\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "robot.connect(ROBOT_IP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ¤– HOME...\n"
                    ]
                }
            ],
            "source": [
                "robot.home()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# ðŸŽ¯ MAIN PICK-AND-PLACE v10\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“· Press SPACE to calibrate floor...\n",
                        "============================================================\n",
                        "ðŸŽ¯ PICK v10 (Hybrid PCA + Depth)\n",
                        "Click=Select | SPACE=Execute | D=Depth | Q=Quit\n",
                        "============================================================\n",
                        "\n",
                        "ðŸ“¦ Object: 2 grasps\n",
                        "   Best: W=29.9mm R=-28.5Â° Score=0.75\n",
                        "\n",
                        "ðŸ¤– Pick: W=29.9mm Angle=2.9Â° â†’ R=-28.5Â° Z=-46.9\n",
                        "   Score: 0.75 Type: PCA_narrow\n",
                        "ðŸ”„ Safe position...\n",
                        "   â†’ JointMovJ(0,0,0,0)\n",
                        "ðŸ¦¾ Open: 54.0mm (22Â°)\n",
                        "   â†’ MovJ(30.816154557895118,-3.4751038588505505,-46.873809814453125,-28.496289222156197)\n",
                        "ðŸ¦¾ Grip: 21.2mm - 5mm = 16.2mm (76Â°)\n",
                        "   â†’ MovJ(-253.07,115.17,-17.07,-62.78)\n",
                        "ðŸ¤– HOME...\n",
                        "âœ… Complete!\n",
                        "\n",
                        "ðŸ“¦ Object: 2 grasps\n",
                        "   Best: W=21.4mm R=-22.3Â° Score=0.77\n",
                        "\n",
                        "ðŸ¤– Pick: W=21.4mm Angle=-3.3Â° â†’ R=-22.3Â° Z=-44.1\n",
                        "   Score: 0.77 Type: PCA_narrow\n",
                        "ðŸ”„ Safe position...\n",
                        "   â†’ JointMovJ(0,0,0,0)\n",
                        "ðŸ¦¾ Open: 54.0mm (22Â°)\n",
                        "   â†’ MovJ(-6.56538329809821,41.42992403421328,-44.08769989013672,-22.259695875984352)\n",
                        "ðŸ¦¾ Grip: 12.7mm - 5mm = 7.7mm (85Â°)\n",
                        "   â†’ MovJ(-253.07,115.17,-17.07,-62.78)\n",
                        "ðŸ¤– HOME...\n",
                        "âœ… Complete!\n",
                        "\n",
                        "ðŸ“¦ Object: 2 grasps\n",
                        "   Best: W=23.1mm R=-47.6Â° Score=0.72\n",
                        "\n",
                        "ðŸ¤– Pick: W=23.1mm Angle=22.0Â° â†’ R=-47.6Â° Z=-51.6\n",
                        "   Score: 0.72 Type: PCA_narrow\n",
                        "ðŸ”„ Safe position...\n",
                        "   â†’ JointMovJ(0,0,0,0)\n",
                        "ðŸ¦¾ Open: 54.0mm (22Â°)\n",
                        "   â†’ MovJ(-39.700912354907,6.617520783280887,-51.57197952270508,-47.59442793663453)\n",
                        "ðŸ¦¾ Grip: 14.4mm - 5mm = 9.4mm (83Â°)\n",
                        "   â†’ MovJ(-253.07,115.17,-17.07,-62.78)\n",
                        "ðŸ¤– HOME...\n",
                        "âœ… Complete!\n",
                        "\n",
                        "ðŸ“¦ Object: 2 grasps\n",
                        "   Best: W=14.9mm R=-16.4Â° Score=0.79\n",
                        "\n",
                        "ðŸ¤– Pick: W=14.9mm Angle=-9.2Â° â†’ R=-16.4Â° Z=-48.0\n",
                        "   Score: 0.79 Type: PCA_narrow\n",
                        "ðŸ”„ Safe position...\n",
                        "   â†’ JointMovJ(0,0,0,0)\n",
                        "ðŸ¦¾ Open: 54.0mm (22Â°)\n",
                        "   â†’ MovJ(26.74676509557921,67.39584880448929,-48.022560119628906,-16.360263736848157)\n",
                        "ðŸ¦¾ Grip: 6.2mm - 5mm = 1.2mm (94Â°)\n",
                        "   â†’ MovJ(-253.07,115.17,-17.07,-62.78)\n",
                        "ðŸ¤– HOME...\n",
                        "âœ… Complete!\n",
                        "\n",
                        "ðŸ“¦ Object: 2 grasps\n",
                        "   Best: W=29.6mm R=-28.1Â° Score=0.78\n",
                        "\n",
                        "ðŸ¤– Pick: W=29.6mm Angle=2.5Â° â†’ R=-28.1Â° Z=-40.0\n",
                        "   Score: 0.78 Type: PCA_narrow\n",
                        "ðŸ”„ Safe position...\n",
                        "   â†’ JointMovJ(0,0,0,0)\n",
                        "ðŸ¦¾ Open: 54.0mm (22Â°)\n",
                        "   â†’ MovJ(32.74152913212342,-3.532376738001899,-40,-28.07162568881238)\n",
                        "ðŸ¦¾ Grip: 20.9mm - 5mm = 15.9mm (76Â°)\n",
                        "   â†’ MovJ(-253.07,115.17,-17.07,-62.78)\n",
                        "ðŸ¤– HOME...\n",
                        "âœ… Complete!\n"
                    ]
                }
            ],
            "source": [
                "selected_object = None\n",
                "selected_grasp = None\n",
                "detected_objects = []\n",
                "current_grasps = []\n",
                "\n",
                "def mouse_callback(event, x, y, flags, param):\n",
                "    global selected_object, selected_grasp, current_grasps\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        for g in current_grasps:\n",
                "            gx, gy = g['center']\n",
                "            if abs(x-gx) < 20 and abs(y-gy) < 20:\n",
                "                selected_grasp = g\n",
                "                robot_r = robot.camera_angle_to_robot_r(g['camera_angle'])\n",
                "                print(f\"\\nðŸŽ¯ Grasp: W={g['width_mm']:.1f}mm â†’ R={robot_r:.1f}Â° Score={g['score']:.2f}\")\n",
                "                return\n",
                "        for obj in detected_objects:\n",
                "            bx,by,bw,bh = obj['bbox']\n",
                "            if bx <= x <= bx+bw and by <= y <= by+bh:\n",
                "                selected_object = obj\n",
                "                current_grasps = grasp_selector.analyze_object(\n",
                "                    obj, detector.current_depth, detector.floor_depth\n",
                "                )\n",
                "                selected_grasp = current_grasps[0] if current_grasps else None\n",
                "                if selected_grasp:\n",
                "                    robot_r = robot.camera_angle_to_robot_r(selected_grasp['camera_angle'])\n",
                "                    print(f\"\\nðŸ“¦ Object: {len(current_grasps)} grasps\")\n",
                "                    print(f\"   Best: W={selected_grasp['width_mm']:.1f}mm R={robot_r:.1f}Â° Score={selected_grasp['score']:.2f}\")\n",
                "                break\n",
                "\n",
                "def draw_grasps(frame, grasps, selected):\n",
                "    for g in grasps:\n",
                "        cx, cy = g['center']\n",
                "        angle = g['camera_angle']\n",
                "        is_sel = (selected and g == selected)\n",
                "        color = (0,0,255) if is_sel else ((0,255,0) if g['score']>=0.7 else (0,255,255))\n",
                "        thick = 3 if is_sel else 2\n",
                "        \n",
                "        length = 40\n",
                "        dx = int(length * np.cos(np.radians(angle)))\n",
                "        dy = int(length * np.sin(np.radians(angle)))\n",
                "        cv2.line(frame, (cx-dx, cy-dy), (cx+dx, cy+dy), color, thick)\n",
                "        cv2.circle(frame, (cx, cy), 5, color, -1)\n",
                "        \n",
                "        grip_half = int(g['width_mm'] * PIXELS_PER_MM / 2)\n",
                "        perp_angle = angle + 90\n",
                "        px = int(grip_half * np.cos(np.radians(perp_angle)))\n",
                "        py = int(grip_half * np.sin(np.radians(perp_angle)))\n",
                "        cv2.line(frame, (cx+px-dx//2, cy+py-dy//2), (cx+px+dx//2, cy+py+dy//2), color, 2)\n",
                "        cv2.line(frame, (cx-px-dx//2, cy-py-dy//2), (cx-px+dx//2, cy-py+dy//2), color, 2)\n",
                "        \n",
                "        if is_sel:\n",
                "            robot_r = robot.camera_angle_to_robot_r(angle)\n",
                "            cv2.putText(frame, f\"{g['width_mm']:.1f}mm R={robot_r:.0f} Q={g['score']:.2f}\", \n",
                "                       (cx+10, cy-10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
                "\n",
                "\"\"\"def pick_with_grasp(obj, grasp):\n",
                "    cx, cy = grasp['center']\n",
                "    grip_w = grasp['width_mm']\n",
                "    camera_angle = grasp['camera_angle']\n",
                "    robot_r = robot.camera_angle_to_robot_r(camera_angle)\n",
                "    \n",
                "    robot_x, robot_y = robot.pixel_to_robot(cx, cy)\n",
                "    d_info = obj.get('depth_info', {})\n",
                "    height = d_info.get('height', 0)\n",
                "    z_grasp = max(Z_FLOOR, min(Z_SAFE, Z_FLOOR + height * 0.5))\n",
                "    \n",
                "    print(f\"\\nðŸ¤– Pick: W={grip_w:.1f}mm Angle={camera_angle:.1f}Â° â†’ R={robot_r:.1f}Â° Z={z_grasp:.1f}\")\n",
                "    print(f\"   Score: {grasp['score']:.2f} Type: {grasp['type']}\")\n",
                "    \n",
                "    print(\"ðŸ”„ Safe position...\")\n",
                "    robot.joint_move_and_wait(0, 0, 0, 0, 3)\n",
                "    \n",
                "    gripper.open_for_object(GRIPPER_MAX_WIDTH_MM)\n",
                "    time.sleep(2.5)\n",
                "    \n",
                "    robot.move_to_and_wait(robot_x, robot_y, Z_APPROACH, robot_r, 3)\n",
                "    robot.move_to_and_wait(robot_x, robot_y, z_grasp, robot_r, 2)\n",
                "    \n",
                "    gripper.grip_object(grip_w - 8.5)\n",
                "    time.sleep(2.5)\n",
                "    \n",
                "    robot.move_to_and_wait(robot_x, robot_y, Z_SAFE, robot_r, 2)\n",
                "    robot.move_to_and_wait(*DROP_POS[:3], DROP_POS[3], 3)\n",
                "    \n",
                "    gripper.release()\n",
                "    time.sleep(2.5)\n",
                "    robot.home()\n",
                "    print(\"âœ… Complete!\")\"\"\"\n",
                "\n",
                "def pick_with_grasp(obj, grasp):\n",
                "    cx, cy = grasp['center']\n",
                "    grip_w = grasp['width_mm']\n",
                "    camera_angle = grasp['camera_angle']\n",
                "    robot_r = robot.camera_angle_to_robot_r(camera_angle)\n",
                "    \n",
                "    robot_x, robot_y = robot.pixel_to_robot(cx, cy)\n",
                "    d_info = obj.get('depth_info', {})\n",
                "    height = d_info.get('height', 0)\n",
                "    z_grasp = max(Z_FLOOR, min(Z_SAFE, Z_FLOOR + height * 0.5))\n",
                "    \n",
                "    print(f\"\\nðŸ¤– Pick: W={grip_w:.1f}mm Angle={camera_angle:.1f}Â° â†’ R={robot_r:.1f}Â° Z={z_grasp:.1f}\")\n",
                "    print(f\"   Score: {grasp['score']:.2f} Type: {grasp['type']}\")\n",
                "    \n",
                "    print(\"ðŸ”„ Safe position...\")\n",
                "    robot.joint_move_and_wait(0, 0, 0, 0, 3)\n",
                "    \n",
                "    gripper.open_for_object(GRIPPER_MAX_WIDTH_MM)\n",
                "    time.sleep(3)\n",
                "    \n",
                "    # âœ… à¸¥à¸‡à¹„à¸›à¸—à¸µà¹ˆ z_grasp à¹‚à¸”à¸¢à¸•à¸£à¸‡ (à¹„à¸¡à¹ˆà¸œà¹ˆà¸²à¸™ Z_APPROACH - à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸Šà¸™à¸§à¸±à¸•à¸–à¸¸à¸ªà¸¹à¸‡)\n",
                "    robot.move_to_and_wait(robot_x, robot_y, z_grasp, robot_r, 3)\n",
                "    \n",
                "    gripper.grip_object(grip_w - 8.7)\n",
                "    time.sleep(2.5)\n",
                "    \n",
                "    # âœ… à¹„à¸›à¸—à¸µà¹ˆà¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸§à¸²à¸‡à¹‚à¸”à¸¢à¸•à¸£à¸‡ (à¹„à¸¡à¹ˆà¸œà¹ˆà¸²à¸™ Z_SAFE - à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸Šà¸™à¹€à¸¡à¸·à¹ˆà¸­à¸¢à¸à¸‚à¸­à¸‡à¸ªà¸¹à¸‡)\n",
                "    robot.move_to_and_wait(*DROP_POS[:3], DROP_POS[3], 3)\n",
                "    \n",
                "    gripper.release()\n",
                "    time.sleep(2.5)\n",
                "    robot.home()\n",
                "    print(\"âœ… Complete!\")\n",
                "\n",
                "# Main loop\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Pick v10')\n",
                "cv2.setMouseCallback('Pick v10', mouse_callback)\n",
                "\n",
                "# Calibrate floor\n",
                "print(\"ðŸ“· Press SPACE to calibrate floor...\")\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    cv2.putText(frame, \"SPACE=Calibrate | Q=Skip\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
                "    cv2.imshow('Pick v10', frame)\n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord(' '):\n",
                "        detector.calibrate_floor(frame)\n",
                "        break\n",
                "    elif key == ord('q'): break\n",
                "\n",
                "frame_count = 0\n",
                "print(\"=\"*60)\n",
                "print(\"ðŸŽ¯ PICK v10 (Hybrid PCA + Depth)\")\n",
                "print(\"Click=Select | SPACE=Execute | D=Depth | Q=Quit\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    \n",
                "    frame_count += 1\n",
                "    if frame_count % 5 == 0:\n",
                "        detector.update_depth(frame)\n",
                "    \n",
                "    detected_objects = detector.detect(frame)\n",
                "    \n",
                "    display = frame.copy()\n",
                "    if SHOW_DEPTH_OVERLAY and detector.current_depth is not None:\n",
                "        depth_color = detector.get_depth_colormap()\n",
                "        if depth_color is not None:\n",
                "            depth_resized = cv2.resize(depth_color, (frame.shape[1], frame.shape[0]))\n",
                "            display = cv2.addWeighted(display, 0.7, depth_resized, 0.3, 0)\n",
                "    \n",
                "    for obj in detected_objects:\n",
                "        x,y,w,h = obj['bbox']\n",
                "        is_sel = (selected_object and obj['center'] == selected_object['center'])\n",
                "        color = (0,0,255) if is_sel else (0,255,0)\n",
                "        cv2.rectangle(display, (x,y), (x+w,y+h), color, 2)\n",
                "        \n",
                "        d_info = obj.get('depth_info', {})\n",
                "        cv2.putText(display, f\"H:{d_info.get('height',0):.0f}mm\", (x, y-5), \n",
                "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
                "    \n",
                "    if selected_object and current_grasps:\n",
                "        draw_grasps(display, current_grasps, selected_grasp)\n",
                "    \n",
                "    cv2.rectangle(display, (0,0), (640,35), (30,30,30), -1)\n",
                "    cv2.putText(display, f\"v10 Hybrid | Obj:{len(detected_objects)} | Click | SPACE | D | Q\",\n",
                "               (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1)\n",
                "    \n",
                "    if selected_grasp:\n",
                "        robot_r = robot.camera_angle_to_robot_r(selected_grasp['camera_angle'])\n",
                "        cv2.putText(display, f\"[{selected_grasp['type']}: W={selected_grasp['width_mm']:.1f}mm R={robot_r:.0f} Q={selected_grasp['score']:.2f} - SPACE]\",\n",
                "                   (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
                "    \n",
                "    cv2.imshow('Pick v10', display)\n",
                "    \n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == ord('r'):\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "    elif key == ord('d'):\n",
                "        SHOW_DEPTH_OVERLAY = not SHOW_DEPTH_OVERLAY\n",
                "        print(f\"Depth overlay: {SHOW_DEPTH_OVERLAY}\")\n",
                "    elif key == ord('h'):\n",
                "        robot.home()\n",
                "    elif key == ord(' ') and selected_object and selected_grasp:\n",
                "        pick_with_grasp(selected_object, selected_grasp)\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "robot.home()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gripper.disconnect()\n",
                "print(\"âœ… Done\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
