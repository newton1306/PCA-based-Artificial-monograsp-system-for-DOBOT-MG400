{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ LIDAR Grasp Detection v12\n",
    "\n",
    "## ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô v12\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **üìê LIDAR Offset Calibration** | Calibrate ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå LIDAR-Gripper 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á |\n",
    "| **üîÑ R_OFFSET First** | ‡∏´‡∏°‡∏∏‡∏ô‡πÑ‡∏õ‡∏ó‡∏µ‡πà R_OFFSET ‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡∏±‡∏î (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô LIDAR ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á) |\n",
    "| **üìè Move LIDAR to Object** | ‡∏¢‡πâ‡∏≤‡∏¢ LIDAR ‡πÑ‡∏õ‡∏ï‡∏£‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡∏±‡∏î |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import socket\n",
    "import serial\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"‚úì Imports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Hardware Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Hardware config\n"
     ]
    }
   ],
   "source": [
    "ROBOT_IP = '192.168.1.6'\n",
    "ESP32_PORT = 'COM9'\n",
    "ESP32_BAUDRATE = 115200\n",
    "CAMERA_ID = 2\n",
    "\n",
    "HOMOGRAPHY_MATRIX = np.load('homography_matrix.npy')\n",
    "\n",
    "print(\"‚úì Hardware config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration (v12 with LIDAR Offset Calibration)\n"
     ]
    }
   ],
   "source": [
    "# === CALIBRATED VALUES ===\n",
    "PIXELS_PER_MM = 2.7703\n",
    "\n",
    "# === Robot R Rotation ===\n",
    "ROBOT_R_OFFSET = -25.55  # R ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô calibrate ‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏î LIDAR\n",
    "\n",
    "# === Z Heights ===\n",
    "Z_FLOOR = -64\n",
    "#Z_MEASURE = 201  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà LIDAR ‡∏ß‡∏±‡∏î‡πÑ‡∏î‡πâ‡∏î‡∏µ (>200mm ‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô)\n",
    "Z_MEASURE = 230  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà LIDAR ‡∏ß‡∏±‡∏î‡πÑ‡∏î‡πâ‡∏î‡∏µ (>200mm ‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô)\n",
    "\n",
    "\n",
    "# === LIDAR Configuration ===\n",
    "LIDAR_Z_OFFSET = 39  # mm (‡∏£‡∏∞‡∏¢‡∏∞‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á ‡∏à‡∏≤‡∏Å LIDAR ‡∏ñ‡∏∂‡∏á‡∏õ‡∏•‡∏≤‡∏¢ gripper)\n",
    "\n",
    "# === v12: LIDAR XY Offset (‡∏à‡∏≤‡∏Å Calibration) ===\n",
    "# ‡πÄ‡∏°‡∏∑‡πà‡∏≠ Robot ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà R=ROBOT_R_OFFSET:\n",
    "# - LIDAR_X_OFFSET = ‡∏£‡∏∞‡∏¢‡∏∞ X ‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡∏≤‡∏á gripper ‡∏ñ‡∏∂‡∏á LIDAR\n",
    "# - LIDAR_Y_OFFSET = ‡∏£‡∏∞‡∏¢‡∏∞ Y ‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡∏≤‡∏á gripper ‡∏ñ‡∏∂‡∏á LIDAR\n",
    "LIDAR_X_OFFSET = 25.08   # mm (‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å calibration)\n",
    "LIDAR_Y_OFFSET = 20.71   # mm (‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å calibration)\n",
    "\n",
    "# === Drop Position ===\n",
    "DROP_POS = (-253.07, 115.17, -17.07, -62.78)\n",
    "\n",
    "# === Gripper ===\n",
    "GRIPPER_MAX_WIDTH_MM = 54\n",
    "GRIPPER_OPEN_MARGIN_MM = 5\n",
    "GRIPPER_GRIP_MARGIN_MM = 5\n",
    "\n",
    "# === Detection ===\n",
    "MIN_OBJECT_AREA = 1000\n",
    "#YOLO_CONFIDENCE = 0.25\n",
    "YOLO_CONFIDENCE = 0.15\n",
    "\n",
    "print(\"‚úì Configuration (v12 with LIDAR Offset Calibration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLOv8...\n",
      "‚úÖ YOLO loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading YOLOv8...\")\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "print(\"‚úÖ YOLO loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Classes Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Gripper+LIDAR class\n"
     ]
    }
   ],
   "source": [
    "class SmartGripperController:\n",
    "    \"\"\"Gripper + LIDAR Controller (v12)\"\"\"\n",
    "    CALIB_ANGLES = np.array([22, 30, 40, 50, 60, 70, 80, 90, 96])\n",
    "    CALIB_WIDTHS = np.array([54.0, 52.0, 48.0, 40.0, 32.0, 23.0, 12.0, 3.0, 0.0])\n",
    "    \n",
    "    def __init__(self, port='COM9', baudrate=115200):\n",
    "        self.port = port\n",
    "        self.baudrate = baudrate\n",
    "        self.serial = None\n",
    "        self.target_width = None\n",
    "        \n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.serial = serial.Serial(self.port, self.baudrate, timeout=2)\n",
    "            time.sleep(2)\n",
    "            self.serial.reset_input_buffer()\n",
    "            print(f\"‚úÖ Gripper+LIDAR on {self.port}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {e}\")\n",
    "            return False\n",
    "    \n",
    "    def disconnect(self):\n",
    "        if self.serial: \n",
    "            self.serial.close()\n",
    "            self.serial = None\n",
    "    \n",
    "    def send_command(self, cmd):\n",
    "        if self.serial and self.serial.is_open:\n",
    "            self.serial.reset_input_buffer()\n",
    "            self.serial.write((cmd + '\\n').encode())\n",
    "            time.sleep(0.3)\n",
    "    \n",
    "    def mm_to_angle(self, width_mm):\n",
    "        width = max(0.0, min(54.0, width_mm))\n",
    "        return int(round(np.interp(width, self.CALIB_WIDTHS[::-1], self.CALIB_ANGLES[::-1])))\n",
    "    \n",
    "    def open_for_object(self, width_mm):\n",
    "        self.target_width = width_mm\n",
    "        open_w = min(54.0, width_mm + GRIPPER_OPEN_MARGIN_MM)\n",
    "        angle = self.mm_to_angle(open_w)\n",
    "        print(f\"ü¶æ Open: {open_w:.1f}mm ({angle}¬∞)\")\n",
    "        self.send_command(f'G{angle}')\n",
    "    \n",
    "    def grip_object(self, width_mm):\n",
    "        grip_w = max(0.0, width_mm - GRIPPER_GRIP_MARGIN_MM)\n",
    "        angle = self.mm_to_angle(grip_w)\n",
    "        print(f\"ü¶æ Grip: {grip_w:.1f}mm ({angle}¬∞)\")\n",
    "        self.send_command(f'G{angle}')\n",
    "    \n",
    "    def release(self):\n",
    "        open_w = min(54.0, (self.target_width or 30) + 10)\n",
    "        self.send_command(f'G{self.mm_to_angle(open_w)}')\n",
    "        self.target_width = None\n",
    "    \n",
    "    def read_lidar(self, samples=3):\n",
    "        \"\"\"Read LIDAR distance in mm\"\"\"\n",
    "        if not self.serial or not self.serial.is_open:\n",
    "            return None\n",
    "        \n",
    "        readings = []\n",
    "        for _ in range(samples):\n",
    "            self.serial.reset_input_buffer()\n",
    "            self.serial.write(b'L\\n')\n",
    "            \n",
    "            start = time.time()\n",
    "            while time.time() - start < 1.0:\n",
    "                if self.serial.in_waiting > 0:\n",
    "                    response = self.serial.readline().decode().strip()\n",
    "                    if response.startswith(\"LIDAR:\") and \"ERR\" not in response:\n",
    "                        try:\n",
    "                            dist = int(response.split(\":\")[1])\n",
    "                            readings.append(dist)\n",
    "                        except:\n",
    "                            pass\n",
    "                        break\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        if readings:\n",
    "            return int(np.median(readings))\n",
    "        return None\n",
    "\n",
    "print(\"‚úì Gripper+LIDAR class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Robot class\n"
     ]
    }
   ],
   "source": [
    "class DobotControllerTCP:\n",
    "    def __init__(self, homography_matrix=None, r_offset=-25.55):\n",
    "        self.dashboard_port = 29999\n",
    "        self.sock = None\n",
    "        self.H = homography_matrix\n",
    "        self.r_offset = r_offset\n",
    "        \n",
    "    def connect(self, ip):\n",
    "        try:\n",
    "            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            self.sock.settimeout(5)\n",
    "            self.sock.connect((ip, self.dashboard_port))\n",
    "            self.send_command(\"ClearError()\")\n",
    "            time.sleep(0.5)\n",
    "            self.send_command(\"EnableRobot()\")\n",
    "            time.sleep(4)\n",
    "            self.send_command(\"User(1)\")\n",
    "            self.send_command(\"Tool(1)\")\n",
    "            self.send_command(\"SpeedFactor(50)\")\n",
    "            print(\"‚úÖ Robot connected!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def send_command(self, cmd):\n",
    "        if self.sock:\n",
    "            self.sock.send((cmd + \"\\n\").encode(\"utf-8\"))\n",
    "            return self.sock.recv(1024).decode(\"utf-8\")\n",
    "\n",
    "    def home(self):\n",
    "        print(\"ü§ñ HOME...\")\n",
    "        self.send_command(\"MovJ(-253.07, 115.17, -17.07, -62.78)\")\n",
    "        time.sleep(4)\n",
    "\n",
    "    def move_to(self, x, y, z, r=0):\n",
    "        cmd = f\"MovJ({x},{y},{z},{r})\"\n",
    "        print(f\"   ‚Üí {cmd}\")\n",
    "        return self.send_command(cmd)\n",
    "    \n",
    "    def move_to_and_wait(self, x, y, z, r=0, wait=3):\n",
    "        self.move_to(x, y, z, r)\n",
    "        time.sleep(wait)\n",
    "    \n",
    "    def joint_move(self, j1=0, j2=0, j3=0, j4=0):\n",
    "        cmd = f\"JointMovJ({j1},{j2},{j3},{j4})\"\n",
    "        print(f\"   ‚Üí {cmd}\")\n",
    "        return self.send_command(cmd)\n",
    "    \n",
    "    def joint_move_and_wait(self, j1=0, j2=0, j3=0, j4=0, wait=3):\n",
    "        self.joint_move(j1, j2, j3, j4)\n",
    "        time.sleep(wait)\n",
    "\n",
    "    def pixel_to_robot(self, u, v):\n",
    "        if self.H is None: return None, None\n",
    "        pt = np.array([u, v, 1], dtype=np.float32)\n",
    "        res = np.dot(self.H, pt)\n",
    "        return res[0]/res[2], res[1]/res[2]\n",
    "    \n",
    "    def camera_angle_to_robot_r(self, camera_angle):\n",
    "        return self.r_offset - camera_angle\n",
    "\n",
    "print(\"‚úì Robot class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ObjectDetectorV13 (Saturation + Edge - All Colors)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"class ObjectDetector:\n",
    "    def __init__(self, yolo_model, pixels_per_mm):\n",
    "        self.yolo = yolo_model\n",
    "        self.ppm = pixels_per_mm\n",
    "    \n",
    "    def detect(self, frame):\n",
    "        objects = []\n",
    "        results = self.yolo(frame, conf=YOLO_CONFIDENCE, verbose=False)\n",
    "        \n",
    "        for r in results:\n",
    "            for box in r.boxes:\n",
    "                x1,y1,x2,y2 = map(int, box.xyxy[0])\n",
    "                conf = float(box.conf[0])\n",
    "                \n",
    "                roi = frame[y1:y2, x1:x2]\n",
    "                if roi.size == 0: continue\n",
    "                \n",
    "                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                if contours:\n",
    "                    cnt = max(contours, key=cv2.contourArea)\n",
    "                    cnt = cnt + np.array([x1, y1])\n",
    "                    rect = cv2.minAreaRect(cnt)\n",
    "                    cx, cy = int(rect[0][0]), int(rect[0][1])\n",
    "                    \n",
    "                    objects.append({\n",
    "                        'bbox': (x1, y1, x2-x1, y2-y1),\n",
    "                        'center': (cx, cy),\n",
    "                        'rect': rect,\n",
    "                        'contour': cnt,\n",
    "                        'conf': conf,\n",
    "                        'area': cv2.contourArea(cnt)\n",
    "                    })\n",
    "        \n",
    "        return objects\n",
    "\n",
    "print(\"‚úì Object Detector class\")\"\"\"\n",
    "# ObjectDetector v12.1 - with Color Detection Fallback\n",
    "# Copy cell ‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà ObjectDetector ‡πÄ‡∏î‡∏¥‡∏°\n",
    "\n",
    "class ObjectDetector:\n",
    "    \"\"\"v12.1: YOLO + Color Detection Fallback\"\"\"\n",
    "    \n",
    "    def __init__(self, yolo_model, pixels_per_mm):\n",
    "        self.yolo = yolo_model\n",
    "        self.ppm = pixels_per_mm\n",
    "        \n",
    "        # Color ranges for detection (HSV)\n",
    "        self.color_ranges = {\n",
    "            'blue': ([100, 100, 50], [130, 255, 255]),\n",
    "            'green': ([40, 50, 50], [80, 255, 255]),\n",
    "            'red1': ([0, 100, 50], [10, 255, 255]),\n",
    "            'red2': ([170, 100, 50], [180, 255, 255]),\n",
    "            'yellow': ([20, 100, 100], [35, 255, 255]),\n",
    "        }\n",
    "    \n",
    "    def detect(self, frame):\n",
    "        \"\"\"Detect objects using YOLO first, then color fallback\"\"\"\n",
    "        # Try YOLO first\n",
    "        objects = self._detect_yolo(frame)\n",
    "        \n",
    "        # If YOLO finds nothing, use color detection\n",
    "        if len(objects) == 0:\n",
    "            objects = self._detect_color(frame)\n",
    "        \n",
    "        return objects\n",
    "    \n",
    "    def _detect_yolo(self, frame):\n",
    "        \"\"\"YOLO-based detection\"\"\"\n",
    "        objects = []\n",
    "        results = self.yolo(frame, conf=YOLO_CONFIDENCE, verbose=False)\n",
    "        \n",
    "        for r in results:\n",
    "            for box in r.boxes:\n",
    "                cls_id = int(box.cls[0])\n",
    "                # Skip person class (id=0)\n",
    "                if cls_id == 0:\n",
    "                    continue\n",
    "                    \n",
    "                x1,y1,x2,y2 = map(int, box.xyxy[0])\n",
    "                conf = float(box.conf[0])\n",
    "                \n",
    "                roi = frame[y1:y2, x1:x2]\n",
    "                if roi.size == 0: continue\n",
    "                \n",
    "                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                if contours:\n",
    "                    cnt = max(contours, key=cv2.contourArea)\n",
    "                    cnt = cnt + np.array([x1, y1])\n",
    "                    rect = cv2.minAreaRect(cnt)\n",
    "                    cx, cy = int(rect[0][0]), int(rect[0][1])\n",
    "                    \n",
    "                    objects.append({\n",
    "                        'bbox': (x1, y1, x2-x1, y2-y1),\n",
    "                        'center': (cx, cy),\n",
    "                        'rect': rect,\n",
    "                        'contour': cnt,\n",
    "                        'conf': conf,\n",
    "                        'area': cv2.contourArea(cnt),\n",
    "                        'method': 'YOLO'\n",
    "                    })\n",
    "        \n",
    "        return objects\n",
    "    \n",
    "    def _detect_color(self, frame):\n",
    "        \"\"\"Color-based detection fallback\"\"\"\n",
    "        objects = []\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Combined mask for all colors\n",
    "        combined_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        for color_name, (lower, upper) in self.color_ranges.items():\n",
    "            lower = np.array(lower)\n",
    "            upper = np.array(upper)\n",
    "            mask = cv2.inRange(hsv, lower, upper)\n",
    "            combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "        \n",
    "        # Clean up mask\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)\n",
    "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area < MIN_OBJECT_AREA:\n",
    "                continue\n",
    "            \n",
    "            # Get bounding box and rect\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            rect = cv2.minAreaRect(cnt)\n",
    "            cx, cy = int(rect[0][0]), int(rect[0][1])\n",
    "            \n",
    "            objects.append({\n",
    "                'bbox': (x, y, w, h),\n",
    "                'center': (cx, cy),\n",
    "                'rect': rect,\n",
    "                'contour': cnt,\n",
    "                'conf': 0.8,\n",
    "                'area': area,\n",
    "                'method': 'Color'\n",
    "            })\n",
    "        \n",
    "        # Sort by area (largest first)\n",
    "        objects = sorted(objects, key=lambda o: o['area'], reverse=True)\n",
    "        \n",
    "        return objects\n",
    "\n",
    "print(\"‚úÖ ObjectDetector v12.1 (with Color Detection)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PCA Grasp Selector\n"
     ]
    }
   ],
   "source": [
    "class PCAGraspSelector:\n",
    "    def __init__(self, pixels_per_mm):\n",
    "        self.ppm = pixels_per_mm\n",
    "    \n",
    "    def analyze_object(self, obj):\n",
    "        cnt = obj.get('contour')\n",
    "        if cnt is None or len(cnt) < 5:\n",
    "            return self._fallback(obj)\n",
    "        \n",
    "        pts = cnt.reshape(-1, 2).astype(np.float64)\n",
    "        mean = np.mean(pts, axis=0)\n",
    "        pts_centered = pts - mean\n",
    "        \n",
    "        cov = np.cov(pts_centered.T)\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "        idx = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        major = eigenvectors[:, 0]\n",
    "        minor = eigenvectors[:, 1]\n",
    "        \n",
    "        angle = np.degrees(np.arctan2(major[1], major[0]))\n",
    "        \n",
    "        proj = np.dot(pts_centered, minor)\n",
    "        width_mm = (np.max(proj) - np.min(proj)) / self.ppm\n",
    "        \n",
    "        cx, cy = int(mean[0]), int(mean[1])\n",
    "        grasp_angle = self._normalize(angle + 90)\n",
    "        \n",
    "        grasps = []\n",
    "        if width_mm <= GRIPPER_MAX_WIDTH_MM:\n",
    "            grasps.append({\n",
    "                'center': (cx, cy),\n",
    "                'width_mm': width_mm,\n",
    "                'camera_angle': grasp_angle,\n",
    "                'score': 1.0,\n",
    "                'type': 'PCA'\n",
    "            })\n",
    "        return grasps if grasps else self._fallback(obj)\n",
    "    \n",
    "    def _fallback(self, obj):\n",
    "        rect = obj.get('rect')\n",
    "        if not rect: return []\n",
    "        (cx, cy), (w, h), angle = rect\n",
    "        grip_w = min(w, h) / self.ppm\n",
    "        grip_a = angle + 90 if w < h else angle\n",
    "        if grip_w <= GRIPPER_MAX_WIDTH_MM:\n",
    "            return [{'center': (int(cx), int(cy)), 'width_mm': grip_w, \n",
    "                     'camera_angle': self._normalize(grip_a), 'score': 0.6, 'type': 'Rect'}]\n",
    "        return []\n",
    "    \n",
    "    def _normalize(self, a):\n",
    "        while a > 90: a -= 180\n",
    "        while a < -90: a += 180\n",
    "        return a\n",
    "\n",
    "print(\"‚úì PCA Grasp Selector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Components initialized (v12)\n"
     ]
    }
   ],
   "source": [
    "gripper = SmartGripperController(port=ESP32_PORT, baudrate=ESP32_BAUDRATE)\n",
    "robot = DobotControllerTCP(homography_matrix=HOMOGRAPHY_MATRIX, r_offset=ROBOT_R_OFFSET)\n",
    "detector = ObjectDetector(yolo_model, PIXELS_PER_MM)\n",
    "grasp_selector = PCAGraspSelector(PIXELS_PER_MM)\n",
    "print(\"‚úì Components initialized (v12)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìê LIDAR OFFSET CALIBRATION (v12)\n",
    "---\n",
    "\n",
    "## ‡∏ß‡∏¥‡∏ò‡∏µ Calibrate:\n",
    "1. ‡∏£‡∏±‡∏ô Cell ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á\n",
    "2. ‡πÉ‡∏ä‡πâ Dobot Studio ‡∏¢‡πâ‡∏≤‡∏¢ Robot ‡πÉ‡∏´‡πâ **LIDAR ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏** (R ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô R_OFFSET)\n",
    "3. ‡∏à‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Robot (X1, Y1) ‡∏ó‡∏µ‡πà LIDAR ‡∏ï‡∏£‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏\n",
    "4. ‡∏¢‡πâ‡∏≤‡∏¢ Robot ‡πÉ‡∏´‡πâ **Gripper ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏** (R ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô R_OFFSET ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)\n",
    "5. ‡∏à‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Robot (X2, Y2) ‡∏ó‡∏µ‡πà Gripper ‡∏ï‡∏£‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏\n",
    "6. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì: `LIDAR_X_OFFSET = X1 - X2`, `LIDAR_Y_OFFSET = Y1 - Y2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üìê LIDAR OFFSET CALIBRATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏¢‡πâ‡∏≤‡∏¢ Robot ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ R = {ROBOT_R_OFFSET}\")\n",
    "print(\"\\n‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:\")\n",
    "print(\"1. ‡∏ß‡∏≤‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô\")\n",
    "print(\"2. ‡πÉ‡∏ä‡πâ Dobot Studio ‡∏¢‡πâ‡∏≤‡∏¢ Robot ‡πÉ‡∏´‡πâ LIDAR ‡∏ä‡∏µ‡πâ‡∏ï‡∏£‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏\")\n",
    "print(\"3. ‡∏à‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á X1, Y1\")\n",
    "print(\"4. ‡∏¢‡πâ‡∏≤‡∏¢ Robot ‡πÉ‡∏´‡πâ Gripper ‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏£‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ (R ‡πÄ‡∏î‡∏¥‡∏°)\")\n",
    "print(\"5. ‡∏à‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á X2, Y2\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Input positions\n",
    "print(\"\\nüìç ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á LIDAR ‡∏ï‡∏£‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏:\")\n",
    "x1 = float(input(\"   X1 = \"))\n",
    "y1 = float(input(\"   Y1 = \"))\n",
    "\n",
    "print(\"\\nüìç ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Gripper ‡∏ï‡∏£‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏:\")\n",
    "x2 = float(input(\"   X2 = \"))\n",
    "y2 = float(input(\"   Y2 = \"))\n",
    "\n",
    "# Calculate offset\n",
    "lidar_x_offset = x1 - x2\n",
    "lidar_y_offset = y1 - y2\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ CALIBRATION RESULT:\")\n",
    "print(f\"   LIDAR_X_OFFSET = {lidar_x_offset:.2f}\")\n",
    "print(f\"   LIDAR_Y_OFFSET = {lidar_y_offset:.2f}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìù Copy ‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÉ‡∏ô Cell Configuration (Cell 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡πà‡∏≤ Offset ‡∏´‡∏•‡∏±‡∏á calibrate (‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å calibrate ‡πÄ‡∏™‡∏£‡πá‡∏à)\n",
    "LIDAR_X_OFFSET = 25.08   # ‚Üê ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å calibration\n",
    "LIDAR_Y_OFFSET = 20.71   # ‚Üê ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å calibration\n",
    "\n",
    "print(f\"‚úÖ LIDAR Offset Updated: X={LIDAR_X_OFFSET}, Y={LIDAR_Y_OFFSET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ü§ñ CONNECT ROBOT & GRIPPER\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ü§ñ Connecting to Robot and Gripper+LIDAR...\n",
      "============================================================\n",
      "‚úÖ Gripper+LIDAR on COM9\n",
      "‚úÖ Robot connected!\n",
      "ü§ñ HOME...\n",
      "‚úÖ Ready!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ü§ñ Connecting to Robot and Gripper+LIDAR...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "gripper.connect()\n",
    "robot.connect(ROBOT_IP)\n",
    "robot.home()\n",
    "\n",
    "print(\"‚úÖ Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ FULL ROBOT PICK v12 (LIDAR)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ PICK v12 (LIDAR with Calibrated Offset)\n",
      "Click=Select | SPACE=Execute | H=Home | Q=Quit\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "selected_object = None\n",
    "selected_grasp = None\n",
    "current_grasps = []\n",
    "detected_objects = []\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global selected_object, selected_grasp, current_grasps\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for obj in detected_objects:\n",
    "            bx,by,bw,bh = obj['bbox']\n",
    "            if bx <= x <= bx+bw and by <= y <= by+bh:\n",
    "                selected_object = obj\n",
    "                current_grasps = grasp_selector.analyze_object(obj)\n",
    "                selected_grasp = current_grasps[0] if current_grasps else None\n",
    "                if selected_grasp:\n",
    "                    print(f\"\\nüì¶ Object: W={selected_grasp['width_mm']:.1f}mm\")\n",
    "                break\n",
    "\n",
    "def pick_with_lidar_v12(obj, grasp):\n",
    "    \"\"\"v12: Pick using LIDAR with calibrated offset\"\"\"\n",
    "    cx, cy = grasp['center']\n",
    "    grip_w = grasp['width_mm']\n",
    "    camera_angle = grasp['camera_angle']\n",
    "    \n",
    "    # ‡πÉ‡∏ä‡πâ R_OFFSET ‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ LIDAR ‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
    "    robot_r = ROBOT_R_OFFSET\n",
    "    \n",
    "    # ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Gripper (‡∏à‡∏≤‡∏Å pixel)\n",
    "    gripper_x, gripper_y = robot.pixel_to_robot(cx, cy)\n",
    "    \n",
    "    # ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á LIDAR (offset ‡∏à‡∏≤‡∏Å Gripper)\n",
    "    lidar_x = gripper_x + LIDAR_X_OFFSET\n",
    "    lidar_y = gripper_y + LIDAR_Y_OFFSET\n",
    "    \n",
    "    print(f\"\\nü§ñ Pick v12 (LIDAR): W={grip_w:.1f}mm\")\n",
    "    print(f\"   Gripper: ({gripper_x:.1f}, {gripper_y:.1f})\")\n",
    "    print(f\"   LIDAR:   ({lidar_x:.1f}, {lidar_y:.1f})\")\n",
    "    \n",
    "    # 1. Safe position (‡∏´‡∏°‡∏∏‡∏ô‡πÑ‡∏õ‡∏ó‡∏µ‡πà R_OFFSET ‡∏Å‡πà‡∏≠‡∏ô)\n",
    "    print(\"üîÑ Safe position...\")\n",
    "    robot.joint_move_and_wait(0, 0, 0, 0, 3)\n",
    "    \n",
    "    # 2. Open gripper\n",
    "    gripper.open_for_object(GRIPPER_MAX_WIDTH_MM)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # 3. Move LIDAR to above object (‡πÉ‡∏´‡πâ LIDAR ‡∏ï‡∏£‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏)\n",
    "    print(f\"üìè Moving LIDAR above object (Z{Z_MEASURE})...\")\n",
    "    robot.move_to_and_wait(lidar_x, lidar_y, Z_MEASURE, robot_r, 2)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # 4. Read LIDAR\n",
    "    lidar_dist = gripper.read_lidar(samples=15)\n",
    "    # # # # #\n",
    "    time.sleep(4)\n",
    "    if lidar_dist is None:\n",
    "        print(\"‚ùå LIDAR read failed! Aborting.\")\n",
    "        robot.home()\n",
    "        return\n",
    "    \n",
    "    print(f\"üìè LIDAR: {lidar_dist} mm\")\n",
    "    \n",
    "    # 5. Calculate Z_GRASP\n",
    "    z_grasp = Z_MEASURE - lidar_dist + LIDAR_Z_OFFSET\n",
    "    z_grasp = max(Z_FLOOR, z_grasp)\n",
    "    \n",
    "    print(f\"üìç Z_GRASP = {Z_MEASURE} - {lidar_dist} + {LIDAR_Z_OFFSET} = {z_grasp:.1f}\")\n",
    "    \n",
    "    # 6. Move Gripper to above object (‡∏¢‡πâ‡∏≤‡∏¢ Gripper ‡πÑ‡∏õ‡∏ï‡∏£‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏)\n",
    "    print(\"üéØ Moving Gripper above object...\")\n",
    "    robot.move_to_and_wait(gripper_x, gripper_y, Z_MEASURE, robot_r, 2)\n",
    "    \n",
    "    # 7. ‡∏´‡∏°‡∏∏‡∏ô‡πÑ‡∏õ‡∏°‡∏∏‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏á‡πÑ‡∏õ‡∏à‡∏±‡∏ö\n",
    "    final_r = robot.camera_angle_to_robot_r(camera_angle)\n",
    "    print(f\"üîÑ Rotating to R={final_r:.1f}¬∞ and grasping...\")\n",
    "    robot.move_to_and_wait(gripper_x, gripper_y, z_grasp, final_r, 2)\n",
    "    \n",
    "    # 8. Grip\n",
    "    gripper.grip_object(grip_w - 8.5)\n",
    "    time.sleep(4)\n",
    "\n",
    "    # 8.1 ‡∏¢‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô 50 mm ‡∏Å‡πà‡∏≠‡∏ô\n",
    "    z_lift = z_grasp + 50\n",
    "    print(f\"‚¨ÜÔ∏è Lifting to Z={z_lift:.1f}...\")\n",
    "    robot.move_to_and_wait(gripper_x, gripper_y, z_lift, final_r, 2)\n",
    "    \n",
    "    # 9. Lift and go to drop\n",
    "    robot.move_to_and_wait(*DROP_POS[:3], DROP_POS[3], 3)\n",
    "    robot.move_to_and_wait(*DROP_POS[:3], DROP_POS[3], 3)\n",
    "    \n",
    "    # 10. Release\n",
    "    gripper.release()\n",
    "    time.sleep(2)\n",
    "    robot.home()\n",
    "    print(\"‚úÖ Complete!\")\n",
    "\n",
    "def draw_grasps(frame, grasps, selected):\n",
    "    for g in grasps:\n",
    "        cx, cy = g['center']\n",
    "        angle = g['camera_angle']\n",
    "        is_sel = (selected and g == selected)\n",
    "        color = (0,0,255) if is_sel else (0,255,0)\n",
    "        thick = 3 if is_sel else 2\n",
    "        \n",
    "        length = 40\n",
    "        dx = int(length * np.cos(np.radians(angle)))\n",
    "        dy = int(length * np.sin(np.radians(angle)))\n",
    "        cv2.line(frame, (cx-dx, cy-dy), (cx+dx, cy+dy), color, thick)\n",
    "        cv2.circle(frame, (cx, cy), 5, color, -1)\n",
    "\n",
    "# Main loop\n",
    "cap = cv2.VideoCapture(CAMERA_ID)\n",
    "cv2.namedWindow('Pick v12 LIDAR')\n",
    "cv2.setMouseCallback('Pick v12 LIDAR', mouse_callback)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üéØ PICK v12 (LIDAR with Calibrated Offset)\")\n",
    "print(\"Click=Select | SPACE=Execute | H=Home | Q=Quit\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    detected_objects = detector.detect(frame)\n",
    "    \n",
    "    display = frame.copy()\n",
    "    for obj in detected_objects:\n",
    "        x,y,w,h = obj['bbox']\n",
    "        is_sel = (selected_object and obj['center'] == selected_object['center'])\n",
    "        cv2.rectangle(display, (x,y), (x+w,y+h), (0,0,255) if is_sel else (0,255,0), 2)\n",
    "    \n",
    "    if selected_object and current_grasps:\n",
    "        draw_grasps(display, current_grasps, selected_grasp)\n",
    "    \n",
    "    cv2.rectangle(display, (0,0), (640,35), (30,30,30), -1)\n",
    "    cv2.putText(display, f\"v12 LIDAR | Obj:{len(detected_objects)} | SPACE | H | Q\",\n",
    "               (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1)\n",
    "    \n",
    "    if selected_grasp:\n",
    "        cv2.putText(display, f\"[W={selected_grasp['width_mm']:.1f}mm - SPACE to pick]\",\n",
    "                   (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "    \n",
    "    cv2.imshow('Pick v12 LIDAR', display)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'): break\n",
    "    elif key == ord('r'):\n",
    "        selected_object = None\n",
    "        selected_grasp = None\n",
    "        current_grasps = []\n",
    "    elif key == ord('h'):\n",
    "        robot.home()\n",
    "    elif key == ord(' ') and selected_object and selected_grasp:\n",
    "        pick_with_lidar_v12(selected_object, selected_grasp)\n",
    "        selected_object = None\n",
    "        selected_grasp = None\n",
    "        current_grasps = []\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "gripper.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
