{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ Advanced Grasp Detection v6\n",
                "\n",
                "## Features\n",
                "| Feature | Description |\n",
                "|---------|-------------|\n",
                "| **üîç YOLO Detection** | Object detection + Grid sizing |\n",
                "| **üéØ Smart Grasp** | Auto grasp point selection |\n",
                "| **üìè Precise Sizing** | Contour-based measurements |\n",
                "| **ü¶æ Tight Grip** | No margin - grip exact size |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch: 2.9.1+cpu\n",
                        "CUDA: False\n",
                        "‚úì Imports loaded\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import cv2\n",
                "import numpy as np\n",
                "import time\n",
                "import socket\n",
                "import serial\n",
                "import torch\n",
                "from collections import deque\n",
                "from ultralytics import YOLO\n",
                "\n",
                "sys.path.append('Depth-Anything-V2')\n",
                "\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "print(\"‚úì Imports loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Hardware Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Hardware config loaded\n"
                    ]
                }
            ],
            "source": [
                "ROBOT_IP = '192.168.1.6'\n",
                "ESP32_PORT = 'COM9'\n",
                "ESP32_BAUDRATE = 115200\n",
                "CAMERA_ID = 2\n",
                "\n",
                "HOMOGRAPHY_MATRIX = np.array([\n",
                "    [0.005703976266962427, -0.3265299161278153, 88.58634169557483],\n",
                "    [-0.47704058225560797, 0.015355046930804153, 172.0941543570439],\n",
                "    [-0.00029949919510557677, 0.00018728182448344945, 1.0],\n",
                "], dtype=np.float32)\n",
                "\n",
                "print(\"‚úì Hardware config loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üîß CALIBRATION SECTION\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìê Calibration 1: PIXELS_PER_MM\n",
                "1. ‡∏ß‡∏≤‡∏á‡πÑ‡∏°‡πâ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\n",
                "2. ‡∏•‡∏≤‡∏Å‡πÄ‡∏™‡πâ‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î ENTER\n",
                "3. ‡πÉ‡∏™‡πà‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏£‡∏¥‡∏á (mm)\n",
                "4. Copy ‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ‡πÉ‡∏™‡πà Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === PIXELS_PER_MM CALIBRATION ===\n",
                "# Uncomment ‡πÅ‡∏•‡∏∞ run ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ calibrate\n",
                "\n",
                "'''\n",
                "drawing = False\n",
                "start_pt = None\n",
                "end_pt = None\n",
                "px_dist = 0\n",
                "\n",
                "def callback(event, x, y, flags, param):\n",
                "    global drawing, start_pt, end_pt, px_dist\n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        drawing = True\n",
                "        start_pt = (x, y)\n",
                "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
                "        end_pt = (x, y)\n",
                "    elif event == cv2.EVENT_LBUTTONUP:\n",
                "        drawing = False\n",
                "        end_pt = (x, y)\n",
                "        px_dist = np.sqrt((end_pt[0]-start_pt[0])**2 + (end_pt[1]-start_pt[1])**2)\n",
                "        print(f\"üìè Distance: {px_dist:.1f} px\")\n",
                "\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Pixel Calibration')\n",
                "cv2.setMouseCallback('Pixel Calibration', callback)\n",
                "\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    if start_pt and end_pt:\n",
                "        cv2.line(frame, start_pt, end_pt, (0,255,0), 2)\n",
                "    cv2.imshow('Pixel Calibration', frame)\n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'): break\n",
                "    elif key == 13 and px_dist > 0:\n",
                "        real_mm = float(input(\"üìè Real size (mm): \"))\n",
                "        ppm = px_dist / real_mm\n",
                "        print(f\"‚úÖ PIXELS_PER_MM = {ppm:.4f}\")\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()\n",
                "'''"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìè Calibration 2: DEPTH_Z_SCALE\n",
                "Run ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Load Depth Model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ü¶æ Calibration 3: Gripper Test\n",
                "Run ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Connect Gripper"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3Ô∏è‚É£ Configuration (‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà Calibrate ‡πÅ‡∏•‡πâ‡∏ß)\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Configuration loaded\n",
                        "  GRIP_MARGIN: 0mm (tight grip)\n"
                    ]
                }
            ],
            "source": [
                "# === CALIBRATED VALUES ===\n",
                "PIXELS_PER_MM = 2.2167\n",
                "DEPTH_Z_SCALE = 57.428993\n",
                "\n",
                "# === Z Heights ===\n",
                "Z_FLOOR = -64\n",
                "Z_SAFE = -40\n",
                "Z_APPROACH = -55\n",
                "\n",
                "# === Drop Position ===\n",
                "DROP_POS = (-253.07, 115.17, -17.07, -62.78)\n",
                "\n",
                "# === Gripper (NO MARGIN) ===\n",
                "GRIPPER_SERVO_OPEN_ANGLE = 22\n",
                "GRIPPER_SERVO_CLOSE_ANGLE = 96\n",
                "GRIPPER_MAX_WIDTH_MM = 54\n",
                "GRIPPER_MIN_WIDTH_MM = 0\n",
                "GRIPPER_OPEN_MARGIN_MM = 5\n",
                "GRIPPER_GRIP_MARGIN_MM = 0  # ‡∏Ñ‡∏µ‡∏ö‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏Ç‡∏ô‡∏≤‡∏î\n",
                "\n",
                "# === Detection ===\n",
                "MIN_OBJECT_AREA = 1000\n",
                "YOLO_CONFIDENCE = 0.25\n",
                "\n",
                "# === Depth Model ===\n",
                "DEPTH_MODEL_PATH = 'Depth-Anything-V2/checkpoints/depth_anything_v2_vits.pth'\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "# === Grid ===\n",
                "SHOW_GRID = True\n",
                "GRID_SIZE_MM = 20\n",
                "\n",
                "print(\"‚úì Configuration loaded\")\n",
                "print(f\"  GRIP_MARGIN: {GRIPPER_GRIP_MARGIN_MM}mm (tight grip)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Load Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "xFormers not available\n",
                        "xFormers not available\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading DepthAnything V2...\n",
                        "‚úÖ Depth model on cpu\n",
                        "Loading YOLOv8...\n",
                        "‚úÖ YOLO loaded\n"
                    ]
                }
            ],
            "source": [
                "from depth_anything_v2.dpt import DepthAnythingV2\n",
                "\n",
                "model_configs = {\n",
                "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
                "}\n",
                "\n",
                "print(\"Loading DepthAnything V2...\")\n",
                "depth_model = DepthAnythingV2(**model_configs['vits'])\n",
                "depth_model.load_state_dict(torch.load(DEPTH_MODEL_PATH, map_location='cpu'))\n",
                "depth_model = depth_model.to(DEVICE).eval()\n",
                "print(f\"‚úÖ Depth model on {DEVICE}\")\n",
                "\n",
                "print(\"Loading YOLOv8...\")\n",
                "yolo_model = YOLO('yolov8n.pt')\n",
                "print(\"‚úÖ YOLO loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Classes Definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Gripper & Robot classes loaded\n"
                    ]
                }
            ],
            "source": [
                "class SmartGripperController:\n",
                "    CALIB_ANGLES = np.array([22, 30, 40, 50, 60, 70, 80, 90, 96])\n",
                "    CALIB_WIDTHS = np.array([54.0, 52.0, 48.0, 40.0, 32.0, 23.0, 12.0, 3.0, 0.0])\n",
                "    \n",
                "    def __init__(self, port='COM9', baudrate=115200):\n",
                "        self.port = port\n",
                "        self.baudrate = baudrate\n",
                "        self.serial = None\n",
                "        self.target_width = None\n",
                "        \n",
                "    def connect(self):\n",
                "        try:\n",
                "            self.serial = serial.Serial(self.port, self.baudrate, timeout=2)\n",
                "            time.sleep(2)\n",
                "            print(f\"‚úÖ Gripper connected on {self.port}\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå Failed: {e}\")\n",
                "            return False\n",
                "    \n",
                "    def disconnect(self):\n",
                "        if self.serial: self.serial.close()\n",
                "    \n",
                "    def send_command(self, cmd):\n",
                "        if self.serial:\n",
                "            self.serial.write((cmd + '\\n').encode())\n",
                "            time.sleep(0.3)\n",
                "    \n",
                "    def mm_to_angle(self, width_mm):\n",
                "        width = max(0.0, min(54.0, width_mm))\n",
                "        return int(round(np.interp(width, self.CALIB_WIDTHS[::-1], self.CALIB_ANGLES[::-1])))\n",
                "    \n",
                "    def open_for_object(self, width_mm):\n",
                "        self.target_width = width_mm\n",
                "        open_w = min(54.0, width_mm + GRIPPER_OPEN_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(open_w)\n",
                "        print(f\"ü¶æ Open: {width_mm:.1f}mm ‚Üí {open_w:.1f}mm ({angle}¬∞)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def grip_object(self, width_mm):\n",
                "        grip_w = max(0.0, width_mm - GRIPPER_GRIP_MARGIN_MM)\n",
                "        angle = self.mm_to_angle(grip_w)\n",
                "        print(f\"ü¶æ Grip: {width_mm:.1f}mm ({angle}¬∞)\")\n",
                "        self.send_command(f'G{angle}')\n",
                "    \n",
                "    def release(self):\n",
                "        open_w = min(54.0, (self.target_width or 30) + 10)\n",
                "        self.send_command(f'G{self.mm_to_angle(open_w)}')\n",
                "        self.target_width = None\n",
                "\n",
                "\n",
                "class DobotControllerTCP:\n",
                "    def __init__(self, homography_matrix=None):\n",
                "        self.dashboard_port = 29999\n",
                "        self.sock = None\n",
                "        self.H = homography_matrix\n",
                "        \n",
                "    def connect(self, ip):\n",
                "        try:\n",
                "            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
                "            self.sock.settimeout(5)\n",
                "            self.sock.connect((ip, self.dashboard_port))\n",
                "            self.send_command(\"ClearError()\")\n",
                "            time.sleep(0.5)\n",
                "            self.send_command(\"EnableRobot()\")\n",
                "            time.sleep(4)\n",
                "            self.send_command(\"User(1)\")\n",
                "            self.send_command(\"Tool(1)\")\n",
                "            self.send_command(\"SpeedFactor(50)\")\n",
                "            print(\"‚úÖ Robot connected!\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"Error: {e}\")\n",
                "            return False\n",
                "\n",
                "    def send_command(self, cmd):\n",
                "        if self.sock:\n",
                "            self.sock.send((cmd + \"\\n\").encode(\"utf-8\"))\n",
                "            return self.sock.recv(1024).decode(\"utf-8\")\n",
                "\n",
                "    def home(self):\n",
                "        print(\"ü§ñ HOME...\")\n",
                "        self.send_command(\"MovJ(-253.07, 115.17, -17.07, -62.78)\")\n",
                "        time.sleep(4)\n",
                "\n",
                "    def move_to(self, x, y, z, r=0):\n",
                "        cmd = f\"MovJ({x},{y},{z},{r})\"\n",
                "        print(f\"   ‚Üí {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def move_to_and_wait(self, x, y, z, r=0, wait=3):\n",
                "        self.move_to(x, y, z, r)\n",
                "        time.sleep(wait)\n",
                "    \n",
                "    def joint_move(self, j1=0, j2=0, j3=0, j4=0):\n",
                "        cmd = f\"JointMovJ({j1},{j2},{j3},{j4})\"\n",
                "        print(f\"   ‚Üí {cmd}\")\n",
                "        return self.send_command(cmd)\n",
                "    \n",
                "    def joint_move_and_wait(self, j1=0, j2=0, j3=0, j4=0, wait=3):\n",
                "        self.joint_move(j1, j2, j3, j4)\n",
                "        time.sleep(wait)\n",
                "\n",
                "    def pixel_to_robot(self, u, v):\n",
                "        if self.H is None: return None, None\n",
                "        pt = np.array([u, v, 1], dtype=np.float32)\n",
                "        res = np.dot(self.H, pt)\n",
                "        return res[0]/res[2], res[1]/res[2]\n",
                "\n",
                "print(\"‚úì Gripper & Robot classes loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Detector class loaded\n"
                    ]
                }
            ],
            "source": [
                "class PreciseSizeDetector:\n",
                "    \"\"\"YOLO + Contour + Grid\"\"\"\n",
                "    \n",
                "    def __init__(self, yolo_model, pixels_per_mm):\n",
                "        self.yolo = yolo_model\n",
                "        self.ppm = pixels_per_mm\n",
                "        self.bg_gray = None\n",
                "    \n",
                "    def set_background(self, frame):\n",
                "        self.bg_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
                "        self.bg_gray = cv2.GaussianBlur(self.bg_gray, (5,5), 0)\n",
                "        print(\"‚úÖ Background set\")\n",
                "    \n",
                "    def detect(self, frame):\n",
                "        objects = []\n",
                "        results = self.yolo(frame, conf=YOLO_CONFIDENCE, verbose=False)\n",
                "        \n",
                "        for r in results:\n",
                "            for box in r.boxes:\n",
                "                x1,y1,x2,y2 = map(int, box.xyxy[0])\n",
                "                conf = float(box.conf[0])\n",
                "                \n",
                "                roi = frame[y1:y2, x1:x2]\n",
                "                if roi.size == 0: continue\n",
                "                \n",
                "                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
                "                _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
                "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "                \n",
                "                if contours:\n",
                "                    cnt = max(contours, key=cv2.contourArea)\n",
                "                    cnt += np.array([x1, y1])\n",
                "                    rect = cv2.minAreaRect(cnt)\n",
                "                    cx, cy = int(rect[0][0]), int(rect[0][1])\n",
                "                    \n",
                "                    objects.append({\n",
                "                        'bbox': (x1, y1, x2-x1, y2-y1),\n",
                "                        'center': (cx, cy),\n",
                "                        'rect': rect,\n",
                "                        'rect_size': rect[1],\n",
                "                        'rect_angle': rect[2],\n",
                "                        'contour': cnt,\n",
                "                        'conf': conf,\n",
                "                        'area': cv2.contourArea(cnt)\n",
                "                    })\n",
                "        \n",
                "        if not objects:\n",
                "            objects = self.edge_detect(frame)\n",
                "        \n",
                "        return objects\n",
                "    \n",
                "    def edge_detect(self, frame):\n",
                "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
                "        blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
                "        edges = cv2.Canny(blur, 50, 150)\n",
                "        edges = cv2.dilate(edges, np.ones((3,3), np.uint8), iterations=2)\n",
                "        \n",
                "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "        \n",
                "        objects = []\n",
                "        for cnt in contours:\n",
                "            area = cv2.contourArea(cnt)\n",
                "            if area > MIN_OBJECT_AREA:\n",
                "                hull = cv2.convexHull(cnt)\n",
                "                rect = cv2.minAreaRect(hull)\n",
                "                x,y,w,h = cv2.boundingRect(hull)\n",
                "                \n",
                "                objects.append({\n",
                "                    'bbox': (x,y,w,h),\n",
                "                    'center': (x+w//2, y+h//2),\n",
                "                    'rect': rect,\n",
                "                    'rect_size': rect[1],\n",
                "                    'rect_angle': rect[2],\n",
                "                    'contour': hull,\n",
                "                    'area': area\n",
                "                })\n",
                "        \n",
                "        return sorted(objects, key=lambda o: o['area'], reverse=True)\n",
                "    \n",
                "    def draw_grid(self, frame):\n",
                "        if not SHOW_GRID: return frame\n",
                "        h, w = frame.shape[:2]\n",
                "        grid_px = int(GRID_SIZE_MM * self.ppm)\n",
                "        for x in range(0, w, grid_px):\n",
                "            cv2.line(frame, (x,0), (x,h), (50,50,50), 1)\n",
                "        for y in range(0, h, grid_px):\n",
                "            cv2.line(frame, (0,y), (w,y), (50,50,50), 1)\n",
                "        cv2.putText(frame, f\"Grid: {GRID_SIZE_MM}mm\", (10, h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100,100,100), 1)\n",
                "        return frame\n",
                "\n",
                "print(\"‚úì Detector class loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Grasp selector loaded\n"
                    ]
                }
            ],
            "source": [
                "class SmartGraspSelector:\n",
                "    \"\"\"Auto select best grasp + alternatives\"\"\"\n",
                "    \n",
                "    def __init__(self, pixels_per_mm):\n",
                "        self.ppm = pixels_per_mm\n",
                "    \n",
                "    def analyze_object(self, obj):\n",
                "        w, h = obj['rect_size']\n",
                "        angle = obj['rect_angle']\n",
                "        cx, cy = obj['center']\n",
                "        \n",
                "        aspect = max(w,h) / (min(w,h) + 0.001)\n",
                "        is_ring = self.detect_ring(obj)\n",
                "        \n",
                "        grasps = []\n",
                "        \n",
                "        if aspect > 2.0:\n",
                "            # Long object ‚Üí narrow side\n",
                "            if w < h:\n",
                "                grip_w = w / self.ppm\n",
                "                grip_angle = angle + 90\n",
                "            else:\n",
                "                grip_w = h / self.ppm\n",
                "                grip_angle = angle\n",
                "            \n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': grip_w,\n",
                "                'angle': self.normalize_angle(grip_angle),\n",
                "                'score': 1.0,\n",
                "                'type': 'narrow_side'\n",
                "            })\n",
                "            \n",
                "            alt_angle = grip_angle + 90\n",
                "            alt_w = max(w,h) / self.ppm\n",
                "            if alt_w <= GRIPPER_MAX_WIDTH_MM:\n",
                "                grasps.append({\n",
                "                    'center': (cx, cy),\n",
                "                    'width_mm': alt_w,\n",
                "                    'angle': self.normalize_angle(alt_angle),\n",
                "                    'score': 0.5,\n",
                "                    'type': 'alternative'\n",
                "                })\n",
                "        \n",
                "        elif is_ring:\n",
                "            inner_w = self.estimate_ring_width(obj)\n",
                "            for i in range(4):\n",
                "                grasps.append({\n",
                "                    'center': (cx, cy),\n",
                "                    'width_mm': inner_w,\n",
                "                    'angle': i * 45,\n",
                "                    'score': 1.0 if i == 0 else 0.8,\n",
                "                    'type': 'ring'\n",
                "                })\n",
                "        \n",
                "        else:\n",
                "            if w < h:\n",
                "                grip_w = w / self.ppm\n",
                "                grip_angle = angle + 90\n",
                "            else:\n",
                "                grip_w = h / self.ppm\n",
                "                grip_angle = angle\n",
                "            \n",
                "            grasps.append({\n",
                "                'center': (cx, cy),\n",
                "                'width_mm': grip_w,\n",
                "                'angle': self.normalize_angle(grip_angle),\n",
                "                'score': 1.0,\n",
                "                'type': 'default'\n",
                "            })\n",
                "            \n",
                "            perp_w = max(w,h) / self.ppm\n",
                "            if perp_w <= GRIPPER_MAX_WIDTH_MM:\n",
                "                grasps.append({\n",
                "                    'center': (cx, cy),\n",
                "                    'width_mm': perp_w,\n",
                "                    'angle': self.normalize_angle(grip_angle + 90),\n",
                "                    'score': 0.6,\n",
                "                    'type': 'perpendicular'\n",
                "                })\n",
                "        \n",
                "        return grasps\n",
                "    \n",
                "    def detect_ring(self, obj):\n",
                "        cnt = obj.get('contour')\n",
                "        if cnt is None: return False\n",
                "        area = cv2.contourArea(cnt)\n",
                "        hull = cv2.convexHull(cnt)\n",
                "        hull_area = cv2.contourArea(hull)\n",
                "        return (area / (hull_area + 0.001)) < 0.7\n",
                "    \n",
                "    def estimate_ring_width(self, obj):\n",
                "        w, h = obj['rect_size']\n",
                "        return max(w, h) / self.ppm * 0.3\n",
                "    \n",
                "    def normalize_angle(self, angle):\n",
                "        while angle > 90: angle -= 180\n",
                "        while angle < -90: angle += 180\n",
                "        return angle\n",
                "\n",
                "print(\"‚úì Grasp selector loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Depth estimator loaded\n"
                    ]
                }
            ],
            "source": [
                "class RobustDepthEstimator:\n",
                "    \"\"\"Multi-sample + temporal averaging\"\"\"\n",
                "    \n",
                "    def __init__(self, model, device='cpu', history_size=5):\n",
                "        self.model = model\n",
                "        self.device = device\n",
                "        self.floor_depth = None\n",
                "        self.history = deque(maxlen=history_size)\n",
                "    \n",
                "    def estimate_depth(self, frame):\n",
                "        return self.model.infer_image(frame)\n",
                "    \n",
                "    def calibrate_floor(self, frame):\n",
                "        depth = self.estimate_depth(frame)\n",
                "        h, w = depth.shape\n",
                "        center = depth[h//3:2*h//3, w//3:2*w//3]\n",
                "        self.floor_depth = np.median(center)\n",
                "        print(f\"‚úÖ Floor depth: {self.floor_depth:.4f}\")\n",
                "        return self.floor_depth\n",
                "    \n",
                "    def get_object_height(self, depth_map, obj, scale):\n",
                "        if self.floor_depth is None: return 0\n",
                "        \n",
                "        x, y, w, h = obj['bbox']\n",
                "        region = depth_map[y:y+h, x:x+w]\n",
                "        if region.size == 0: return 0\n",
                "        \n",
                "        samples = [np.median(region)]\n",
                "        qh, qw = h//4, w//4\n",
                "        if qh > 0 and qw > 0:\n",
                "            samples.extend([\n",
                "                np.median(region[:qh, :qw]),\n",
                "                np.median(region[:qh, -qw:]),\n",
                "                np.median(region[-qh:, :qw]),\n",
                "                np.median(region[-qh:, -qw:])\n",
                "            ])\n",
                "        \n",
                "        obj_depth = np.median(samples)\n",
                "        height = max(0, (obj_depth - self.floor_depth) * scale)\n",
                "        \n",
                "        self.history.append(height)\n",
                "        return np.median(self.history)\n",
                "    \n",
                "    def calculate_z(self, height_mm):\n",
                "        z = Z_FLOOR + (height_mm * 0.5)\n",
                "        return max(Z_FLOOR, min(Z_SAFE, z))\n",
                "\n",
                "print(\"‚úì Depth estimator loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Initialize & Connect"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Components initialized\n"
                    ]
                }
            ],
            "source": [
                "gripper = SmartGripperController(port=ESP32_PORT, baudrate=ESP32_BAUDRATE)\n",
                "robot = DobotControllerTCP(homography_matrix=HOMOGRAPHY_MATRIX)\n",
                "detector = PreciseSizeDetector(yolo_model, PIXELS_PER_MM)\n",
                "grasp_selector = SmartGraspSelector(PIXELS_PER_MM)\n",
                "depth_estimator = RobustDepthEstimator(depth_model, device=DEVICE)\n",
                "print(\"‚úì Components initialized\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Gripper connected on COM9\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "gripper.connect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Robot connected!\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "robot.connect(ROBOT_IP)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì∑ Capture Background (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üì∑ BACKGROUND CALIBRATION\n",
                        "SPACE = Capture | Q = Skip\n",
                        "‚úÖ Background set\n",
                        "‚úÖ Floor depth: 3.0468\n"
                    ]
                }
            ],
            "source": [
                "print(\"üì∑ BACKGROUND CALIBRATION\")\n",
                "print(\"SPACE = Capture | Q = Skip\")\n",
                "\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    cv2.putText(frame, \"SPACE=Capture | Q=Skip\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
                "    cv2.imshow('Background', frame)\n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord(' '):\n",
                "        detector.set_background(frame)\n",
                "        depth_estimator.calibrate_floor(frame)\n",
                "        break\n",
                "    elif key == ord('q'):\n",
                "        print(\"Skipped\")\n",
                "        break\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üéØ MAIN PICK-AND-PLACE\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==================================================\n",
                        "üéØ PICK v6\n",
                        "Click=Select | SPACE=Execute | G=Grid | Q=Quit\n",
                        "==================================================\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=206.6mm A=90.0¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=206.6mm A=90.0¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=206.6mm A=90.0¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=206.6mm A=90.0¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=206.6mm A=90.0¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=206.6mm A=90.0¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=206.6mm A=90.0¬∞\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=206.6mm A=90.0¬∞\n",
                        "\n",
                        "ü§ñ Pick: W=206.6mm R=-90.0¬∞ Z=-64.0\n",
                        "üîÑ Safe position...\n",
                        "   ‚Üí JointMovJ(0,0,0,0)\n",
                        "ü¶æ Open: 206.6mm ‚Üí 54.0mm (22¬∞)\n",
                        "   ‚Üí MovJ(11.467768669128418,68.15058135986328,-55,-90.0)\n",
                        "   ‚Üí MovJ(11.467768669128418,68.15058135986328,-64,-90.0)\n",
                        "ü¶æ Grip: 206.6mm (22¬∞)\n",
                        "   ‚Üí MovJ(11.467768669128418,68.15058135986328,-40,-90.0)\n",
                        "   ‚Üí MovJ(-253.07,115.17,-17.07,-62.78)\n",
                        "ü§ñ HOME...\n",
                        "‚úÖ Complete!\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=206.6mm A=90.0¬∞\n",
                        "\n",
                        "ü§ñ Pick: W=206.6mm R=-90.0¬∞ Z=-64.0\n",
                        "üîÑ Safe position...\n",
                        "   ‚Üí JointMovJ(0,0,0,0)\n",
                        "ü¶æ Open: 206.6mm ‚Üí 54.0mm (22¬∞)\n",
                        "   ‚Üí MovJ(11.467768669128418,68.15058135986328,-55,-90.0)\n",
                        "   ‚Üí MovJ(11.467768669128418,68.15058135986328,-64,-90.0)\n",
                        "ü¶æ Grip: 206.6mm (22¬∞)\n",
                        "   ‚Üí MovJ(11.467768669128418,68.15058135986328,-40,-90.0)\n",
                        "   ‚Üí MovJ(-253.07,115.17,-17.07,-62.78)\n",
                        "ü§ñ HOME...\n",
                        "‚úÖ Complete!\n",
                        "\n",
                        "üì¶ Object: 1 grasps\n",
                        "   Best: W=206.6mm A=90.0¬∞\n"
                    ]
                }
            ],
            "source": [
                "# =============================================================================\n",
                "# üéØ PICK-AND-PLACE v6\n",
                "# =============================================================================\n",
                "selected_object = None\n",
                "selected_grasp = None\n",
                "detected_objects = []\n",
                "current_grasps = []\n",
                "current_depth = None\n",
                "\n",
                "def mouse_callback(event, x, y, flags, param):\n",
                "    global selected_object, selected_grasp, current_grasps\n",
                "    \n",
                "    if event == cv2.EVENT_LBUTTONDOWN:\n",
                "        for g in current_grasps:\n",
                "            gx, gy = g['center']\n",
                "            if abs(x - gx) < 20 and abs(y - gy) < 20:\n",
                "                selected_grasp = g\n",
                "                print(f\"\\nüéØ Grasp: W={g['width_mm']:.1f}mm A={g['angle']:.1f}¬∞ ({g['type']})\")\n",
                "                return\n",
                "        \n",
                "        for obj in detected_objects:\n",
                "            bx, by, bw, bh = obj['bbox']\n",
                "            if bx <= x <= bx+bw and by <= y <= by+bh:\n",
                "                selected_object = obj\n",
                "                current_grasps = grasp_selector.analyze_object(obj)\n",
                "                selected_grasp = current_grasps[0] if current_grasps else None\n",
                "                if selected_grasp:\n",
                "                    print(f\"\\nüì¶ Object: {len(current_grasps)} grasps\")\n",
                "                    print(f\"   Best: W={selected_grasp['width_mm']:.1f}mm A={selected_grasp['angle']:.1f}¬∞\")\n",
                "                break\n",
                "\n",
                "def draw_grasps(frame, grasps, selected):\n",
                "    for g in grasps:\n",
                "        cx, cy = g['center']\n",
                "        angle = g['angle']\n",
                "        is_sel = (selected and g == selected)\n",
                "        \n",
                "        if is_sel:\n",
                "            color = (0, 0, 255)\n",
                "            thick = 3\n",
                "        elif g['score'] >= 1.0:\n",
                "            color = (0, 255, 0)\n",
                "            thick = 2\n",
                "        else:\n",
                "            color = (0, 255, 255)\n",
                "            thick = 1\n",
                "        \n",
                "        dx = int(30 * np.cos(np.radians(angle)))\n",
                "        dy = int(30 * np.sin(np.radians(angle)))\n",
                "        cv2.line(frame, (cx-dx, cy-dy), (cx+dx, cy+dy), color, thick)\n",
                "        cv2.circle(frame, (cx, cy), 5, color, -1)\n",
                "\n",
                "def pick_with_grasp(obj, grasp):\n",
                "    cx, cy = grasp['center']\n",
                "    grip_w = grasp['width_mm']\n",
                "    robot_r = -grasp['angle']\n",
                "    \n",
                "    robot_x, robot_y = robot.pixel_to_robot(cx, cy)\n",
                "    height = depth_estimator.get_object_height(current_depth, obj, DEPTH_Z_SCALE) if current_depth is not None else 0\n",
                "    z_grasp = depth_estimator.calculate_z(height)\n",
                "    \n",
                "    print(f\"\\nü§ñ Pick: W={grip_w:.1f}mm R={robot_r:.1f}¬∞ Z={z_grasp:.1f}\")\n",
                "    \n",
                "    print(\"üîÑ Safe position...\")\n",
                "    robot.joint_move_and_wait(0, 0, 0, 0, 3)\n",
                "    \n",
                "    gripper.open_for_object(grip_w)\n",
                "    time.sleep(1)\n",
                "    \n",
                "    robot.move_to_and_wait(robot_x, robot_y, Z_APPROACH, robot_r, 3)\n",
                "    robot.move_to_and_wait(robot_x, robot_y, z_grasp, robot_r, 2)\n",
                "    \n",
                "    gripper.grip_object(grip_w)\n",
                "    time.sleep(1.5)\n",
                "    \n",
                "    robot.move_to_and_wait(robot_x, robot_y, Z_SAFE, robot_r, 2)\n",
                "    robot.move_to_and_wait(*DROP_POS[:3], DROP_POS[3], 3)\n",
                "    \n",
                "    gripper.release()\n",
                "    time.sleep(1)\n",
                "    robot.home()\n",
                "    print(\"‚úÖ Complete!\")\n",
                "\n",
                "# Main loop\n",
                "cap = cv2.VideoCapture(CAMERA_ID)\n",
                "cv2.namedWindow('Pick v6')\n",
                "cv2.setMouseCallback('Pick v6', mouse_callback)\n",
                "\n",
                "frame_count = 0\n",
                "print(\"=\"*50)\n",
                "print(\"üéØ PICK v6\")\n",
                "print(\"Click=Select | SPACE=Execute | G=Grid | Q=Quit\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "while cap.isOpened():\n",
                "    ret, frame = cap.read()\n",
                "    if not ret: break\n",
                "    \n",
                "    frame = detector.draw_grid(frame)\n",
                "    \n",
                "    frame_count += 1\n",
                "    if frame_count % 10 == 0:\n",
                "        current_depth = depth_estimator.estimate_depth(frame)\n",
                "    \n",
                "    detected_objects = detector.detect(frame)\n",
                "    \n",
                "    for obj in detected_objects:\n",
                "        x, y, w, h = obj['bbox']\n",
                "        is_sel = (selected_object and obj['center'] == selected_object['center'])\n",
                "        color = (0, 0, 255) if is_sel else (0, 255, 0)\n",
                "        \n",
                "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
                "        if 'rect' in obj:\n",
                "            box = cv2.boxPoints(obj['rect'])\n",
                "            cv2.drawContours(frame, [np.int32(box)], 0, color, 1)\n",
                "        \n",
                "        rect_w, rect_h = obj['rect_size']\n",
                "        w_mm = min(rect_w, rect_h) / PIXELS_PER_MM\n",
                "        cv2.putText(frame, f\"W:{w_mm:.0f}mm\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
                "    \n",
                "    if selected_object and current_grasps:\n",
                "        draw_grasps(frame, current_grasps, selected_grasp)\n",
                "    \n",
                "    cv2.rectangle(frame, (0, 0), (640, 35), (30, 30, 30), -1)\n",
                "    cv2.putText(frame, f\"Objects:{len(detected_objects)} | Click | SPACE=Pick | G=Grid | Q=Quit\",\n",
                "               (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1)\n",
                "    \n",
                "    if selected_grasp:\n",
                "        cv2.putText(frame, f\"[GRASP: W={selected_grasp['width_mm']:.1f}mm - SPACE]\",\n",
                "                   (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
                "    \n",
                "    cv2.imshow('Pick v6', frame)\n",
                "    \n",
                "    key = cv2.waitKey(1) & 0xFF\n",
                "    if key == ord('q'):\n",
                "        break\n",
                "    elif key == ord('r'):\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "    elif key == ord('g'):\n",
                "        SHOW_GRID = not SHOW_GRID\n",
                "    elif key == ord('h'):\n",
                "        robot.home()\n",
                "    elif key == ord(' ') and selected_object and selected_grasp:\n",
                "        pick_with_grasp(selected_object, selected_grasp)\n",
                "        selected_object = None\n",
                "        selected_grasp = None\n",
                "        current_grasps = []\n",
                "\n",
                "cap.release()\n",
                "cv2.destroyAllWindows()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ü§ñ HOME...\n"
                    ]
                },
                {
                    "ename": "ConnectionResetError",
                    "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mConnectionResetError\u001b[39m                      Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrobot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhome\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mDobotControllerTCP.home\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhome\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mü§ñ HOME...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMovJ(-253.07, 115.17, -17.07, -62.78)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     time.sleep(\u001b[32m4\u001b[39m)\n",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mDobotControllerTCP.send_command\u001b[39m\u001b[34m(self, cmd)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, cmd):\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sock:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sock.recv(\u001b[32m1024\u001b[39m).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mConnectionResetError\u001b[39m: [WinError 10054] An existing connection was forcibly closed by the remote host"
                    ]
                }
            ],
            "source": [
                "robot.home()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gripper.disconnect()\n",
                "print(\"‚úÖ Done\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
