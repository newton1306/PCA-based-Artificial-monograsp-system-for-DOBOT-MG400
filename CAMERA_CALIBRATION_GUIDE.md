# üì∏ Camera Calibration Guide

**‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Camera Calibration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Dobot MG400**

---

## üìã ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

1. [‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á Calibrate?](#‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á-calibrate)
2. [‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°](#‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°)
3. [‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: 4-Point Method (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)](#‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà-1-4-point-method-‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
4. [‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Checkerboard Method (‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏ß‡πà‡∏≤)](#‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà-2-checkerboard-method-‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏ß‡πà‡∏≤)
5. [‡∏ô‡∏≥‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î](#‡∏ô‡∏≥‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î)
6. [‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á](#‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)
7. [Troubleshooting](#troubleshooting)

---

## ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á Calibrate?

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤:
- Camera ‡πÄ‡∏´‡πá‡∏ô‡πÇ‡∏•‡∏Å‡πÄ‡∏õ‡πá‡∏ô **pixel** (‡πÄ‡∏ä‡πà‡∏ô x=320, y=240)
- Robot ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ **millimeters** (‡πÄ‡∏ä‡πà‡∏ô X=300mm, Y=150mm)
- ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á **pixel coordinates ‚Üí robot coordinates**

### ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà Calibrate:
```
‚ùå Camera ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà pixel (320, 240)
‚ùå Robot ‡∏à‡∏∞‡πÑ‡∏õ‡∏ó‡∏µ‡πà (320mm, 240mm)??? ‚Üê ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î!
‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô (280mm, 120mm) ‚Üê ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
```

### Homography Matrix ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
‡πÄ‡∏õ‡πá‡∏ô matrix 3x3 ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏õ‡∏•‡∏á pixel ‚Üí robot coordinates:

```python
[robot_x]   [h11  h12  h13]   [pixel_x]
[robot_y] = [h21  h22  h23] √ó [pixel_y]
[   1   ]   [h31  h32  h33]   [   1   ]
```

---

## ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°

### Hardware:
- ‚úÖ Camera ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ workspace ‡πÅ‡∏•‡πâ‡∏ß (‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà)
- ‚úÖ Dobot MG400 ‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÅ‡∏•‡πâ‡∏ß
- ‚úÖ Marker 4 ‡∏ï‡∏±‡∏ß (‡∏à‡∏∏‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô)
  - ‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç, ‡∏™‡∏ï‡∏¥‡πä‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå‡∏Å‡∏•‡∏°, ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏ö‡∏ô‡∏Å‡∏£‡∏∞‡∏î‡∏≤‡∏©
  - ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏û‡∏≠‡πÉ‡∏´‡πâ‡∏à‡∏¥‡πâ‡∏°‡∏î‡πâ‡∏ß‡∏¢ robot ‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥

### Software:
- ‚úÖ Dobot Studio (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° robot manual)
- ‚úÖ Jupyter Notebook
- ‚úÖ Python libraries: cv2, numpy, matplotlib

---

## ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: 4-Point Method (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:** ‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ò‡∏µ‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡πá‡∏ß

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Workspace

1. **‡∏ß‡∏≤‡∏á marker 4 ‡∏à‡∏∏‡∏î** ‡∏ö‡∏ô workspace ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°:

```
    A ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè B
      ‚îÇ            ‚îÇ
      ‚îÇ            ‚îÇ
      ‚îÇ  Workspace ‚îÇ
      ‚îÇ            ‚îÇ
      ‚îÇ            ‚îÇ
    C ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè D
```

**‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**
- ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏∏‡∏î: ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 15-20 cm
- ‡πÉ‡∏´‡πâ 4 ‡∏à‡∏∏‡∏î‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á robot
- ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏Ç‡∏≠‡∏á camera ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

---

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Pixel Coordinates

‡πÉ‡∏ä‡πâ Python notebook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏≤ pixel coordinates ‡∏Ç‡∏≠‡∏á marker ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏∏‡∏î:

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Capture image
cap = cv2.VideoCapture(1)  # ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô camera ID ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
ret, frame = cap.read()
cap.release()

if not ret:
    print("Error: Cannot capture frame")
else:
    # ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û
    plt.figure(figsize=(10, 8))
    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    plt.title("Click on 4 markers: A (Top-Left) ‚Üí B (Top-Right) ‚Üí C (Bottom-Left) ‚Üí D (Bottom-Right)")
    plt.axis('off')
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ coordinates
    coords = []
    
    def onclick(event):
        if event.xdata is not None and event.ydata is not None:
            x, y = int(event.xdata), int(event.ydata)
            coords.append([x, y])
            plt.plot(x, y, 'ro', markersize=10)
            plt.text(x+10, y-10, f'({x},{y})', color='red', fontsize=12)
            plt.draw()
            print(f"Point {len(coords)}: ({x}, {y})")
    
    cid = plt.gcf().canvas.mpl_connect('button_press_event', onclick)
    plt.show()
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤
    if len(coords) == 4:
        pixel_points = np.array(coords, dtype=np.float32)
        print("\n‚úì Pixel coordinates saved:")
        print(pixel_points)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
        np.save('calibration_pixels.npy', pixel_points)
    else:
        print(f"Error: Need 4 points, got {len(coords)}")
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```
Point 1: (145, 98)   ‚Üê Marker A (Top-Left)
Point 2: (512, 95)   ‚Üê Marker B (Top-Right)
Point 3: (138, 387)  ‚Üê Marker C (Bottom-Left)
Point 4: (518, 390)  ‚Üê Marker D (Bottom-Right)
```

---

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Robot Coordinates

‡πÉ‡∏ä‡πâ **Dobot Studio** ‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô robot ‡πÑ‡∏õ‡πÅ‡∏ï‡∏∞‡∏ó‡∏µ‡πà marker ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏∏‡∏î:

1. **‡πÄ‡∏õ‡∏¥‡∏î Dobot Studio**
2. **Home robot** ‡∏Å‡πà‡∏≠‡∏ô
3. **‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô robot ‡πÑ‡∏õ‡πÅ‡∏ï‡∏∞‡∏ó‡∏µ‡πà marker A** (Top-Left)
   - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å **X, Y** (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏ô‡πÉ‡∏à Z)
   - ‡πÄ‡∏ä‡πà‡∏ô: X=220, Y=180
4. **‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö B, C, D**

**‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô Python:**

```python
# Robot coordinates (mm) ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö A, B, C, D
robot_points = np.array([
    [220, 180],   # A: Top-Left (X, Y)
    [420, 185],   # B: Top-Right
    [215, -120],  # C: Bottom-Left
    [425, -115],  # D: Bottom-Right
], dtype=np.float32)

print("Robot coordinates:")
print(robot_points)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
np.save('calibration_robot.npy', robot_points)
```

**üí° Tips:**
- ‡πÉ‡∏ä‡πâ jog mode ‡πÉ‡∏ô Dobot Studio ‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ä‡πâ‡∏≤‡πÜ
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ gripper/‡∏õ‡∏•‡∏≤‡∏¢ end-effector ‡πÅ‡∏ï‡∏∞‡∏à‡∏∏‡∏î‡∏û‡∏≠‡∏î‡∏µ
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å panel ‡∏Ç‡∏≠‡∏á Dobot Studio

---

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Homography Matrix

```python
import cv2
import numpy as np

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ
pixel_points = np.load('calibration_pixels.npy')
robot_points = np.load('calibration_robot.npy')

print("Pixel points:")
print(pixel_points)
print("\nRobot points:")
print(robot_points)

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Homography Matrix
H, status = cv2.findHomography(pixel_points, robot_points)

print("\n" + "="*60)
print("‚úì HOMOGRAPHY MATRIX (‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î)")
print("="*60)
print(H)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
np.save('homography_matrix.npy', H)

# ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏á‡πà‡∏≤‡∏¢
print("\n" + "="*60)
print("üìã Copy ‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÉ‡∏ô notebook:")
print("="*60)
print(f"HOMOGRAPHY_MATRIX = np.array({H.tolist()}, dtype=np.float32)")
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
HOMOGRAPHY_MATRIX = np.array([
    [0.5423, 0.0156, 141.23],
    [0.0089, 0.6234, -45.67],
    [0.00001, 0.00002, 1.0]
], dtype=np.float32)
```

---

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á

```python
import cv2
import numpy as np

# ‡πÇ‡∏´‡∏•‡∏î Homography Matrix
H = np.load('homography_matrix.npy')

def pixel_to_robot(pixel_x, pixel_y, H):
    """‡πÅ‡∏õ‡∏•‡∏á pixel ‚Üí robot coordinates"""
    pixel_point = np.array([[pixel_x, pixel_y]], dtype=np.float32)
    pixel_point = pixel_point.reshape(-1, 1, 2)
    robot_point = cv2.perspectiveTransform(pixel_point, H)
    robot_x = robot_point[0][0][0]
    robot_y = robot_point[0][0][1]
    return robot_x, robot_y

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û
test_pixel_x = 320
test_pixel_y = 240

robot_x, robot_y = pixel_to_robot(test_pixel_x, test_pixel_y, H)

print(f"Pixel ({test_pixel_x}, {test_pixel_y}) ‚Üí Robot ({robot_x:.1f}, {robot_y:.1f}) mm")

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö marker points ‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏Ñ‡πà‡∏≤
print("\nVerification:")
for i, (px, py) in enumerate(pixel_points):
    rx, ry = pixel_to_robot(px, py, H)
    expected_x, expected_y = robot_points[i]
    error_x = abs(rx - expected_x)
    error_y = abs(ry - expected_y)
    print(f"Point {i+1}: Error X={error_x:.1f}mm, Y={error_y:.1f}mm")
    
print("\n‚úì Error ‡∏Ñ‡∏ß‡∏£‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 5mm")
```

---

## ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Checkerboard Method (‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏ß‡πà‡∏≤)

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:** ‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏û‡∏¥‡∏°‡∏û‡πå Checkerboard Pattern

1. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î checkerboard pattern:
   - ‡∏Ç‡∏ô‡∏≤‡∏î: 7√ó7 ‡∏´‡∏£‡∏∑‡∏≠ 9√ó6 squares
   - ‡∏Ç‡∏ô‡∏≤‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á: 25mm √ó 25mm
   - ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á‡πÉ‡∏ô Word/PowerPoint

2. **‡∏û‡∏¥‡∏°‡∏û‡πå‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡∏ö‡∏ô workspace**
   - ‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ú‡∏¥‡∏ß‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡∏ô (‡πÑ‡∏°‡πà‡πÇ‡∏Ñ‡πâ‡∏á‡∏á‡∏≠)
   - ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏Ç‡∏≠‡∏á camera

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: Capture ‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏û

```python
import cv2
import numpy as np

# Pattern size (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏∏‡∏°‡∏†‡∏≤‡∏¢‡πÉ‡∏ô)
pattern_size = (6, 8)  # 7√ó9 squares = 6√ó8 corners
square_size = 25  # mm

# Capture multiple images
cap = cv2.VideoCapture(1)
images = []

print("Press SPACE to capture, Q to finish")
while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    cv2.imshow('Calibration', frame)
    key = cv2.waitKey(1) & 0xFF
    
    if key == ord(' '):  # SPACE
        images.append(frame.copy())
        print(f"Captured {len(images)} images")
    elif key == ord('q'):  # Q
        break

cap.release()
cv2.destroyAllWindows()
print(f"\n‚úì Captured {len(images)} images")
```

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: Camera Calibration

```python
import cv2
import numpy as np

# Prepare object points
objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)
objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)
objp *= square_size

objpoints = []  # 3D points in real world
imgpoints = []  # 2D points in image

# Find corners in each image
for img in images:
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)
    
    if ret:
        objpoints.append(objp)
        imgpoints.append(corners)

# Calibrate
ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(
    objpoints, imgpoints, gray.shape[::-1], None, None
)

print("Camera Matrix:")
print(camera_matrix)
print("\nDistortion Coefficients:")
print(dist_coeffs)

# Save
np.save('camera_matrix.npy', camera_matrix)
np.save('dist_coeffs.npy', dist_coeffs)
```

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ä‡πâ 4-Point Method ‡∏Å‡πà‡∏≠‡∏ô

---

## ‡∏ô‡∏≥‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î

### üìç ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ: `robot_deployment.ipynb`

‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå [`robot_deployment.ipynb`](file:///c:/Users/CPE%20KMUTT/Music/Artificial_MonoGrasp/notebook_v3/robot_deployment.ipynb)

‡πÑ‡∏õ‡∏ó‡∏µ‡πà **Cell: "Configure Robot Connection"** (Section 2Ô∏è‚É£)

**‡πÅ‡∏Å‡πâ‡∏à‡∏≤‡∏Å:**
```python
# 2. Homography Matrix (‡∏à‡∏≤‡∏Å camera calibration)
# ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ calibration ‡∏Å‡πà‡∏≠‡∏ô!
HOMOGRAPHY_MATRIX = np.array([
    [1.2,  0.01, -150],   # ‚Üê ‡∏Ñ‡πà‡∏≤‡∏õ‡∏•‡∏≠‡∏°! ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô
    [0.02, 1.3,   200],
    [0.0001, 0.0002, 1]
], dtype=np.float32)
```

**‡πÄ‡∏õ‡πá‡∏ô:** (‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á)
```python
# 2. Homography Matrix (‡∏à‡∏≤‡∏Å camera calibration)
HOMOGRAPHY_MATRIX = np.array([
    [0.5423, 0.0156, 141.23],   # ‚Üê ‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ calibrate ‡∏à‡∏£‡∏¥‡∏á
    [0.0089, 0.6234, -45.67],
    [0.00001, 0.00002, 1.0]
], dtype=np.float32)
```

**‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå:**
```python
# 2. Homography Matrix (‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå)
HOMOGRAPHY_MATRIX = np.load('homography_matrix.npy')
print("‚úì Loaded Homography Matrix:")
print(HOMOGRAPHY_MATRIX)
```

---

## ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏Ñ‡πà‡∏≤

1. **‡∏ß‡∏≤‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ** (‡πÄ‡∏ä‡πà‡∏ô X=300mm, Y=100mm)
2. **‡πÉ‡∏ä‡πâ vision system detect**
3. **‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô robot coordinates ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà**

```python
# ‡πÉ‡∏ô notebook cell ‡πÉ‡∏´‡∏°‡πà
# ‡∏™‡∏°‡∏°‡∏ï‡∏¥ detect ‡πÑ‡∏î‡πâ pixel (350, 220)
test_pixel_x = 350
test_pixel_y = 220

# ‡πÅ‡∏õ‡∏•‡∏á‡∏î‡πâ‡∏ß‡∏¢ homography
H = HOMOGRAPHY_MATRIX
pixel_point = np.array([[test_pixel_x, test_pixel_y]], dtype=np.float32).reshape(-1, 1, 2)
robot_point = cv2.perspectiveTransform(pixel_point, H)
robot_x = robot_point[0][0][0]
robot_y = robot_point[0][0][1]

print(f"Pixel: ({test_pixel_x}, {test_pixel_y})")
print(f"Robot: ({robot_x:.1f}, {robot_y:.1f}) mm")
print(f"Expected: (300.0, 100.0) mm")
print(f"Error: X={abs(robot_x-300):.1f}mm, Y={abs(robot_y-100):.1f}mm")

# Error ‡∏Ñ‡∏ß‡∏£ < 10mm
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ Robot ‡∏à‡∏£‡∏¥‡∏á

```python
# ‡πÉ‡∏ô robot_deployment.ipynb
# ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å connect robot ‡πÅ‡∏•‡πâ‡∏ß

# 1. ‡∏ß‡∏≤‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î
# 2. Detect ‡πÅ‡∏•‡∏∞‡∏´‡∏≤ best grasp
result = pipeline.process_frame(frame, detect_objects=True)
best_grasp = pipeline.get_best_grasp(result)

# 3. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô robot coordinates
cy, cx = best_grasp.center
robot_x, robot_y = robot.pixel_to_robot(cx, cy)

print(f"Vision detected at pixel ({cx:.0f}, {cy:.0f})")
print(f"Will move robot to ({robot_x:.1f}, {robot_y:.1f}) mm")

# 4. ‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ä‡πâ‡∏≤‡πÜ ‡πÑ‡∏õ‡∏î‡∏π (‡πÑ‡∏°‡πà‡∏à‡∏±‡∏ö ‡πÅ‡∏Ñ‡πà‡∏ä‡∏µ‡πâ)
confirm = input("Move robot to check position? (y/n): ")
if confirm == 'y':
    robot.move_to(robot_x, robot_y, 150, 0)  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á 150mm (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢)
    print("Check if robot is pointing at the object!")
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á:**
- ‚úÖ Robot ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ (error < 10mm)
- ‚ùå Robot ‡∏ä‡∏µ‡πâ‡∏ú‡∏¥‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ calibration ‡πÉ‡∏´‡∏°‡πà

---

## Troubleshooting

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Error ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å (> 20mm)

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:**
1. ‚ùå Marker 4 ‡∏à‡∏∏‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ß‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏ó‡∏µ‡πà‡∏î‡∏µ
2. ‚ùå Camera ‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á calibration
3. ‚ùå ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å robot coordinates ‡∏ú‡∏¥‡∏î

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
- ‡∏ß‡∏≤‡∏á marker ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
- ‡∏ï‡∏£‡∏∂‡∏á camera ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡∏ô
- ‡∏ó‡∏≥ calibration ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

---

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Error ‡πÑ‡∏°‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ (‡∏ö‡∏≤‡∏á‡∏à‡∏∏‡∏î‡∏ñ‡∏π‡∏Å ‡∏ö‡∏≤‡∏á‡∏à‡∏∏‡∏î‡∏ú‡∏¥‡∏î)

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:**
- Lens distortion ‡∏Ç‡∏≠‡∏á camera

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
- ‡πÉ‡∏ä‡πâ Checkerboard Method ‡πÅ‡∏ó‡∏ô
- ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î workspace ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏Ç‡∏≠‡∏ö‡πÜ)

---

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Camera ‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏±‡∏á calibrate

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
- ‚ö†Ô∏è **‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ calibration ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡∏ô‡∏ó‡∏µ!**
- ‡∏ï‡∏£‡∏∂‡∏á camera ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°

---

## üìù Checklist

‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤:

- [ ] ‡∏ß‡∏≤‡∏á marker 4 ‡∏à‡∏∏‡∏î‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° workspace
- [ ] Capture ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å pixel coordinates
- [ ] ‡πÉ‡∏ä‡πâ robot ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å robot coordinates ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏∏‡∏î
- [ ] ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Homography Matrix ‡∏î‡πâ‡∏ß‡∏¢ `cv2.findHomography()`
- [ ] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å matrix ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå `homography_matrix.npy`
- [ ] ‡∏ô‡∏≥‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÉ‡∏ô `robot_deployment.ipynb` ‚Üí Cell "Configure Robot Connection"
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (error < 10mm)
- [ ] ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏¢‡πâ‡∏≤‡∏¢ camera ‡∏´‡∏•‡∏±‡∏á calibration!

---

## üéØ ‡∏™‡∏£‡∏∏‡∏õ

### 4-Point Method (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥):
```
1. ‡∏ß‡∏≤‡∏á marker 4 ‡∏à‡∏∏‡∏î
2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å pixel coords (‡πÉ‡∏ä‡πâ matplotlib click)
3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å robot coords (‡πÉ‡∏ä‡πâ Dobot Studio)
4. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì H = cv2.findHomography()
5. ‡πÉ‡∏™‡πà‡πÉ‡∏ô notebook ‚Üí HOMOGRAPHY_MATRIX
```

### ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ:
- üìç **‡∏´‡∏•‡∏±‡∏Å:** `robot_deployment.ipynb` ‚Üí Section 2Ô∏è‚É£ ‚Üí `HOMOGRAPHY_MATRIX`
- üìç **‡∏†‡∏≤‡∏¢‡πÉ‡∏ô:** `robot_control.py` ‚Üí `pixel_to_robot()` function (‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)

### Accuracy Goal:
- ‚úÖ Error < 5mm = ‡∏î‡∏µ‡∏°‡∏≤‡∏Å
- ‚ö†Ô∏è Error 5-10mm = ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
- ‚ùå Error > 10mm = ‡∏ï‡πâ‡∏≠‡∏á calibrate ‡πÉ‡∏´‡∏°‡πà

---

**Good luck! üöÄ**

‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å:
- [ROBOT_DEPLOYMENT_GUIDE.md](file:///c:/Users/CPE%20KMUTT/Music/Artificial_MonoGrasp/notebook_v3/ROBOT_DEPLOYMENT_GUIDE.md) (‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)
- [robot_deployment.ipynb](file:///c:/Users/CPE%20KMUTT/Music/Artificial_MonoGrasp/notebook_v3/robot_deployment.ipynb) (Notebook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô robot)
